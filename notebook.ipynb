{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Idalen/enem-score-predictor/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmKTip2JOeEd"
      },
      "source": [
        "# Trabalho De ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LcGn6s_bOawi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "\n",
        "import plotly.express as px\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error as RMSE\n",
        "\n",
        "from pathlib import Path\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faX4OUlFbSNi"
      },
      "source": [
        "# Redução do uso da memória"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMpx4whrjNr1"
      },
      "source": [
        "Devido ao consumo de memória do nosso dataset, decidimos aplicar algumas estratégias para a redução do uso pelo Pandas.\n",
        "Primeiro, mudamos o tipo de dado utilizado pelas colunas para formatos que ocupam menos bytes e transformamos o arquivo para o formato *.parquet, que tem melhor suporte à compressão de dados. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLDhQx3AtAWF"
      },
      "outputs": [],
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ1FqdNpjSwM"
      },
      "source": [
        "# Leitura dos arquivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHNyqFcOOdJz",
        "outputId": "e496fbef-5847-4314-ad35-e379dad44b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content//drive; to attempt to forcibly remount, call drive.mount(\"/content//drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "path = Path(\"/content/drive/MyDrive/datasets/dados-enem/\")\n",
        "drive.mount('/content//drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Stj3HCcV5Od"
      },
      "source": [
        "## Anotações:\n",
        "* Testar: se vale a pena eliminar quem está ausente plotando o gráfico pra ver a nota desse grupo de pessoas\n",
        "* Como fazer a conexão do jupyther com o SSH\n",
        "* https://python.plainenglish.io/how-to-create-a-interative-map-using-plotly-express-geojson-to-brazil-in-python-fb5527ae38fc\n",
        "\n",
        "## 1) Tratar dados\n",
        "* EDA Inicial\n",
        "* Tratar nulos (lembre-se de discutir e avaliar as melhores estratégias)\n",
        "* Mapear os valores e OneHotEncoding \n",
        "\n",
        "## 2) Preprocessamento\n",
        "* Remover colunas (correlacionadas [>80%], baixa variância, semântica)\n",
        "* (Opcional) Aplicar PCA \n",
        "* (Opcional) Feature Engineering\n",
        "* Standardize/Normalize\n",
        "* Tratar dados desbalanceados\n",
        "\n",
        "## 3) Modelo\n",
        "* Regressão linear<br>\n",
        "a. Realizar análise dos pesos<br>\n",
        "b. Aplicar técnicas de regularização<br> \n",
        "\n",
        "* Árvore de Decisão <br>\n",
        "a. Profundidade <br>\n",
        "b. Avaliar os cortes (impureza de gini / entropia) <br>\n",
        "\n",
        "* Naive Bayes <br>\n",
        "a. Quais features afetam significativamente P(nota|feature)<br>\n",
        "b. GaussianNaiveBayes x BernoulliNaiveBayes<br>\n",
        "\n",
        "* SVM<br>\n",
        "a. Avaliar o hiperplano gerado/ onde o corte é realizado <br>\n",
        "b. avaliar diferentes kernels <br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "\n",
        "\n",
        "  _algorithms = {\n",
        "      \n",
        "      'ElasticNet': {\n",
        "          'estimator':ElasticNet(),\n",
        "          'parameters':{\n",
        "              'alpha':[0.001, 0.5, 1.0],\n",
        "              'l1_ratio': [0, 0.5, 1.0]\n",
        "          }},\n",
        "\n",
        "      'DecisionTree': {\n",
        "          'estimator':DecisionTreeRegressor(),\n",
        "          'parameters':{\n",
        "              'max_depth':[100, 90, 80, 70],\n",
        "              'min_samples_leaf':[1, 10, 20, 50, 100]\n",
        "          }},\n",
        "\n",
        "      # 'RandomForest': {\n",
        "      #     'estimator':RandomForestRegressor(),\n",
        "      #     'parameters':{\n",
        "      #         'n_estimators':[11, 31, 51],\n",
        "      #         'max_depth':[100, 90, 80,],\n",
        "      #         'min_samples_leaf':[1, 20, 100],\n",
        "      #     }},\n",
        "\n",
        "      # 'KNN': {\n",
        "      #     'estimator':KNeighborsRegressor(),\n",
        "      #     'parameters':{\n",
        "      #         'n_neighbors':[5, 23, 47, 83],\n",
        "      #         'weights':['uniform', 'distance'],\n",
        "      #         'p':[1, 1.5, 2]\n",
        "      #     }},\n",
        "\n",
        "      # 'SVM': {\n",
        "      #     'estimator':SVR(),\n",
        "      #     'parameters':{\n",
        "      #         'kernel':['rbf', 'poly'],\n",
        "      #         'gamma':[0.01, 0.5, 1.0],\n",
        "      #         'C':[10, 100, 1000]\n",
        "      #     }}\n",
        "\n",
        "  }\n",
        "\n",
        "  def __init__(self, verbose=True):\n",
        "    pass\n",
        "\n",
        "  def load(self, path, verbose=True):\n",
        "\n",
        "    self.train_df = pd.read_parquet(path/'train.parquet').sample(40000)\n",
        "    self.test_df = pd.read_parquet(path/'test.parquet').sample(10000)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Quantidade inicial de elementos no treino:\", len(self.train_df))\n",
        "      print(\"Quantidade inicial de elementos no teste:\", len(self.test_df))\n",
        "        \n",
        "    self.train_df.set_index(\"NU_INSCRICAO\", inplace=True)\n",
        "    self.test_df.set_index(\"NU_INSCRICAO\", inplace=True)\n",
        "\n",
        "    self._targets = [col for col in self.train_df.columns if \"NU_NOTA\" in col]\n",
        "\n",
        "\n",
        "\n",
        "  def prepare(self,verbose=True):\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Mapeando valores...\")    \n",
        "    self._map_values(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Criando novas colunas...\")\n",
        "    self._create_features(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Eliminando colunas...\")\n",
        "    self._clear_cols(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Aplicando get dummies...\")\n",
        "    self._create_dummies(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Selecionando features mais importantes\")\n",
        "    self._feature_selection(verbose)\n",
        "\n",
        "\n",
        "  def tune(self, random_state=0, verbose=True):\n",
        "\n",
        "\n",
        "    X, Y = self.train_df.drop(columns=self._targets), self.train_df[self._targets] \n",
        "\n",
        "    self._results = {}\n",
        "\n",
        "    gscv = None\n",
        "\n",
        "    for name, algorithm in self._algorithms.items():\n",
        "      if verbose:\n",
        "        print(name)\n",
        "\n",
        "      self._results[name] = {} \n",
        "\n",
        "      for target in self._targets:\n",
        "        \n",
        "        gscv = GridSearchCV(algorithm['estimator'], algorithm['parameters'], verbose = 3,\n",
        "                             scoring='neg_root_mean_squared_error', return_train_score=True)\n",
        "        gscv.fit(X, Y[target])\n",
        "\n",
        "        self._results[name][target] = {}\n",
        "        self._results[name][target]['best_params'] = gscv.best_params_\n",
        "        self._results[name][target]['best_score'] = gscv.best_score_\n",
        "  \n",
        "    return gscv\n",
        "\n",
        "  def _to_json(self):\n",
        "\n",
        "    with open('results.json', 'w') as fp:\n",
        "      json.dump(self._results, fp)\n",
        "    fp.close()\n",
        "\n",
        "    with open('ranking.json', 'w') as fp:\n",
        "      json.dump(self._ranking, fp)\n",
        "\n",
        "  def ranking(self, verbose=True):\n",
        "\n",
        "    self._selecteds = {}\n",
        "\n",
        "    for algoritmo in self._results:\n",
        "\n",
        "      for target in self._targets:\n",
        "\n",
        "        if target not in self._selecteds:\n",
        "          if verbose:\n",
        "            print(\"Chave\", target, \"estava vazia, vamos colocar o algoritmo\", algoritmo)\n",
        "          self._selecteds[target] = algoritmo\n",
        "        \n",
        "        else:\n",
        "          if self._results[algoritmo][target]['best_score'] > self._results[self._selecteds[target]][target]['best_score']:\n",
        "            if verbose:\n",
        "              print(\"O algoritmo\", algoritmo, \"se mostrou mais eficiente que o\", self._selecteds[target])\n",
        "            self._selecteds[target] = algoritmo\n",
        "\n",
        "    self._to_json()\n",
        "\n",
        "\n",
        "  def predict(self):\n",
        "    for target in self._targets:\n",
        "      print(\"Vamos prever\", target, \"com o algoritmo\", self._selecteds[target], \"e hiperparâmetros\", self._results[self._selecteds[target]][target]['best_params'])\n",
        "      # Aplicar o treinamento\n",
        "\n",
        "  def correlation(self, save=False, plot=True):\n",
        "    \n",
        "    fig = px.imshow(self.train_df.corr())\n",
        "    \n",
        "    if plot:\n",
        "      fig.show()\n",
        "\n",
        "    if save:\n",
        "      pass\n",
        "\n",
        "\n",
        "  def plot(self, column):\n",
        "    \n",
        "    tmp = self.train_df[column].value_counts()\n",
        "    fig = px.bar(x=tmp.index, y=tmp.values)\n",
        "    fig.show()\n",
        "    \n",
        "    melted = pd.melt(self.train_df, id_vars=[column], value_vars=self._targets, var_name='TP_NOTA', value_name='NU_NOTA')\n",
        "    fig=px.box(melted.sample(1000000), x='TP_NOTA', y='NU_NOTA', color=column)\n",
        "    fig.show()\n",
        "\n",
        "  def null_analysis(self, plot=True, save=False, verbose=True):\n",
        "    \n",
        "    null_count = self.train_df.isna().apply(np.sum, axis=0)/self.train_df.shape[0]\n",
        "    null_percentage_train = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "    fig_train = px.bar(x=null_percentage_train.index, y=null_percentage_train.values, title=\"Porcentagem de valores nulos nos dados de treino\")\n",
        "\n",
        "    null_count = self.test_df.isna().apply(np.sum, axis=0)/self.test_df.shape[0]\n",
        "    null_percentage_test = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "    fig_test = px.bar(x=null_percentage_test.index, y=null_percentage_test.values, title=\"Porcentagem de valores nulos nos dados de teste\")\n",
        "\n",
        "    if plot:\n",
        "      fig_train.show()\n",
        "      fig_test.show()\n",
        "\n",
        "    if save:\n",
        "      pass\n",
        "\n",
        "  def _feature_selection(self, verbose):\n",
        "    \n",
        "    to_drop = []\n",
        "    treshold = 0.05\n",
        "    for col in self.train_df.columns[1:]:\n",
        "       if self.train_df[col].std() < treshold:\n",
        "         to_drop.append(col)\n",
        "    \n",
        "    self.train_df.drop(columns=to_drop, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop, inplace=True)\n",
        "    if verbose:\n",
        "      print(\"[VARIANCE TRESHOLD] Removendo colunas:\", to_drop)\n",
        "\n",
        "    #################################################################################\n",
        "\n",
        "    correlation = self.train_df.corr().abs()\n",
        "\n",
        "    upper_triangle = correlation.where(np.triu(np.ones(correlation.shape), k=1).astype(bool))\n",
        "\n",
        "    # Considera apenas colunas de correlação mínima de 0.85\n",
        "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\n",
        "    \n",
        "    self.train_df.drop(columns=to_drop, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print('[HIGH CORRELATION] Eliminando colunas redundantes:', to_drop)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def _clear_cols(self, verbose):\n",
        "    \n",
        "    null_count = self.train_df.isna().apply(np.sum, axis=0)/self.train_df.shape[0]\n",
        "    null_percentage_train = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "\n",
        "    null_count = self.test_df.isna().apply(np.sum, axis=0)/self.test_df.shape[0]\n",
        "    null_percentage_test = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "\n",
        "    to_drop_columns_train = list(null_percentage_train[null_percentage_train > 30].index)\n",
        "    to_drop_columns_test = list(null_percentage_test[null_percentage_test > 30].index)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"[NULLS] Colunas dropadas no treino:\", sorted(to_drop_columns_train))\n",
        "      print(\"[NULLS] Colunas dropadas no teste:\", sorted(to_drop_columns_test))\n",
        "\n",
        "    self.train_df.drop(columns=to_drop_columns_train, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop_columns_test, inplace=True)\n",
        "\n",
        "    ###################################################################################################################\n",
        "\n",
        "    to_drop = ['CO_MUNICIPIO_RESIDENCIA', 'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'CO_MUNICIPIO_NASCIMENTO', 'NO_MUNICIPIO_NASCIMENTO',\n",
        "    'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO', 'TP_ANO_CONCLUIU', 'IN_TREINEIRO', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA',\n",
        "    'SG_UF_PROVA']\n",
        "\n",
        "    self.train_df.drop(columns=to_drop, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print(f'[DROP COLUMNS] Colunas retiradas por falta de relevânica:{[to_drop]}')\n",
        "\n",
        "    ##################################################################################################################\n",
        "\n",
        "    to_drop = self.train_df[(self.train_df['TP_STATUS_REDACAO'].isna()) & (self.train_df['TP_PRESENCA_CH']=='Presente')].index\n",
        "    self.train_df.drop(to_drop, inplace=True)\n",
        "\n",
        "    to_drop = self.test_df[(self.test_df['TP_STATUS_REDACAO'].isna()) & (self.test_df['TP_PRESENCA_CH']=='Presente')].index\n",
        "    self.test_df.drop(to_drop, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print(f'[INCONSISTENCY] Removendo inconsistências.')\n",
        "\n",
        "    ##################################################################################################################\n",
        "    \n",
        "\n",
        "    to_drop = ['NU_NOTA_MT', 'NU_NOTA_CH', 'NU_NOTA_CN', 'NU_NOTA_LC', 'NU_NOTA_REDACAO', 'TP_STATUS_REDACAO']\n",
        "    self.train_df.dropna(subset=to_drop, inplace=True)\n",
        "\n",
        "    try:\n",
        "      self.test_df.dropna(subset=to_drop, inplace=True)\n",
        "    except KeyError:\n",
        "      pass #\n",
        "\n",
        "    if verbose:\n",
        "      print('[NULL TARGETS] Removendo valores nulos nas colunas-alvo')\n",
        "\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    self.train_df.drop(self.train_df[self.train_df['TP_STATUS_REDACAO'] != 'Sem problemas'].index, inplace=True)\n",
        "    self.test_df.drop(self.test_df[self.test_df['TP_STATUS_REDACAO'] != 'Sem problemas'].index, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print('[::] Removendo redações que tiraram nota 0')\n",
        "\n",
        "\n",
        "  def _create_dummies(self, verbose):\n",
        "\n",
        "    cols = [col for col in self.train_df.columns if ((self.train_df[col].dtype == 'object') or (self.train_df[col].dtype.name == 'category'))]\n",
        "\n",
        "    self.train_df = pd.get_dummies(self.train_df, columns=cols)\n",
        "    self.test_df = pd.get_dummies(self.test_df, columns=cols)\n",
        "\n",
        "    if verbose:\n",
        "      print(f\"[GET DUMMIES] Colunas categóricas convertidas: {cols}\")\n",
        "\n",
        "\n",
        "  def _create_features(self, verbose):\n",
        "\n",
        "    new_columns = []\n",
        "    filled_columns = []\n",
        "    ############################################################################################\n",
        "\n",
        "    uf_regiao = {\n",
        "      'RR':'Norte', 'AP':'Norte', 'AM':'Norte', 'PA':'Norte', 'AC':'Norte', 'RO':'Norte', 'TO':'Norte', 'MA':'Nordeste',\n",
        "      'PI':'Nordeste', 'CE':'Nordeste', 'RN':'Nordeste', 'PB':'Nordeste', 'PE':'Nordeste', 'AL':'Nordeste', 'SE':'Nordeste',\n",
        "      'BA':'Nordeste', 'MT':'Centro-oeste', 'DF':'Centro-oeste', 'GO':'Centro-oeste', 'MS':'Centro-oeste', 'MG':'Sudeste',\n",
        "      'ES':'Sudeste', 'RJ':'Sudeste', 'SP':'Sudeste', 'PR':'Sul', 'SC':'Sul', 'RS':'Sul', \n",
        "      }\n",
        "\n",
        "    self.train_df['NO_REGIAO_RESIDENCIA'] = self.train_df['SG_UF_RESIDENCIA'].map(uf_regiao)\n",
        "    self.test_df['NO_REGIAO_RESIDENCIA'] = self.test_df['SG_UF_RESIDENCIA'].map(uf_regiao)\n",
        "\n",
        "    new_columns.append('NO_REGIAO_RESIDENCIA')\n",
        "\n",
        "    ############################################################################################\n",
        "\n",
        "    mean_score_per_reg = self.train_df.groupby(\"NO_REGIAO_RESIDENCIA\")[self._targets].mean()\n",
        "    for col in self._targets:\n",
        "      self.train_df[\"REG_NOTA_\"+col.split(\"_\")[2]+\"_MEDIA\"] = self.train_df['NO_REGIAO_RESIDENCIA'].apply(\n",
        "          lambda row: mean_score_per_reg[col][row]) \n",
        "      self.test_df[\"REG_NOTA_\"+col.split(\"_\")[2]+\"_MEDIA\"] = self.test_df['NO_REGIAO_RESIDENCIA'].apply(\n",
        "          lambda row: mean_score_per_reg[col][row]) \n",
        "\n",
        "      new_columns.append(\"REG_NOTA_\"+col.split(\"_\")[2]+\"_MEDIA\")\n",
        "    ############################################################################################\n",
        "  \n",
        "    \n",
        "    self.train_df['TP_MINORIA_RACIAL'] = ((self.train_df['TP_COR_RACA'] != 'Branca').astype(int) + (self.train_df['TP_COR_RACA'] != 'Amarela').astype(int)) -1\n",
        "    self.test_df['TP_MINORIA_RACIAL'] = ((self.test_df['TP_COR_RACA'] != 'Branca').astype(int) + (self.test_df['TP_COR_RACA'] != 'Amarela').astype(int)) -1\n",
        "\n",
        "    new_columns.append('TP_MINORIA_RACIAL')\n",
        "    ############################################################################################\n",
        "\n",
        "    cols = [col for col in self.train_df.columns if ((\"IN_\" in col) and ('TREINEIRO' not in col))]\n",
        "\n",
        "    self.train_df['TP_SITUACAO_ESPECIAL'] = self.train_df[cols].any(axis=1)\n",
        "    self.test_df['TP_SITUACAO_ESPECIAL'] = self.test_df[cols].any(axis=1)\n",
        "\n",
        "    new_columns.append('TP_SITUACAO_ESPECIAL')\n",
        "\n",
        "    #############################################################################################\n",
        "\n",
        "\n",
        "    self.train_df['TP_SOLTEIRO'] = self.train_df['TP_ESTADO_CIVIL'] == 'Solteiro(a)'\n",
        "    self.test_df['TP_SOLTEIRO'] = self.test_df['TP_ESTADO_CIVIL'] == 'Solteiro(a)'\n",
        "\n",
        "    new_columns.append('TP_SOLTEIRO')\n",
        "\n",
        "    #############################################################################################\n",
        "\n",
        "    median_train = self.train_df.loc[self.train_df['NU_IDADE'].notnull(), 'NU_IDADE'].median()\n",
        "    \n",
        "    self.train_df['NU_IDADE'] = self.train_df['NU_IDADE'].fillna(median_train)\n",
        "    self.test_df['NU_IDADE'] = self.test_df['NU_IDADE'].fillna(median_train)\n",
        "  \n",
        "    filled_columns.append(\"NU_IDADE\")\n",
        "    #############################################################################################\n",
        "\n",
        "    if verbose:\n",
        "      print(f'[FEATURE ENGINEERING] Novas colunas: {new_columns}')\n",
        "      print(f'[INPUTATION] Colunas com valores nulos preenchidos: {filled_columns}')\n",
        "      \n",
        "\n",
        "\n",
        "  \n",
        "  def _map_values(self, verbose):\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"Solteiro(a)\",\n",
        "      2:\"Casado(a)/Mora com companheiro(a)\",\n",
        "      3:\"Divorciado(a)/Desquitado(a)/Separado(a)\",\n",
        "      4:\"Viúvo(a)\"}\n",
        "\n",
        "    self.train_df['TP_ESTADO_CIVIL'] = self.train_df['TP_ESTADO_CIVIL'].map(rename)\n",
        "    self.test_df['TP_ESTADO_CIVIL'] = self.test_df['TP_ESTADO_CIVIL'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"Branca\",\n",
        "      2:\"Preta\",\n",
        "      3:\"Parda\",\n",
        "      4:\"Amarela\",\n",
        "      5:\"Indígena\"}\n",
        "\n",
        "    self.train_df['TP_COR_RACA'] = self.train_df['TP_COR_RACA'].map(rename)\n",
        "    self.test_df['TP_COR_RACA'] = self.test_df['TP_COR_RACA'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"Brasileiro(a)\",\n",
        "      2:\"Brasileiro(a) Naturalizado(a)\",\n",
        "      3:\"Estrangeiro(a)\",\n",
        "      4:\"Brasileiro(a) Nato(a), nascido(a) no exterior\"\n",
        "      }\n",
        "\n",
        "    self.train_df['TP_NACIONALIDADE'] = self.train_df['TP_NACIONALIDADE'].map(rename)\n",
        "    self.test_df['TP_NACIONALIDADE'] = self.test_df['TP_NACIONALIDADE'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"Já concluí o Ensino Médio\",\n",
        "      2:\"Estou cursando e concluirei o Ensino Médio no ano corrente\",\n",
        "      3:\"Estou cursando e concluirei o Ensino Médio após o ano corrente\",\n",
        "      4:\"Não concluí e não estou cursando o Ensino Médio\"\n",
        "      }\n",
        "\n",
        "    self.train_df['TP_ST_CONCLUSAO'] = self.train_df['TP_ST_CONCLUSAO'].map(rename)\n",
        "    self.test_df['TP_ST_CONCLUSAO'] = self.test_df['TP_ST_CONCLUSAO'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"2018\",\n",
        "      2:\"2017\",\n",
        "      3:\"2016\",\n",
        "      4:\"2015\",\n",
        "      5:\"2014\",\n",
        "      6:\"2013\",\n",
        "      7:\"2012\",\n",
        "      8:\"2011\",\n",
        "      9:\"2010\",\n",
        "      10:\"2009\",\n",
        "      11:\"2008\",\n",
        "      12:\"2007\",\n",
        "      13:\"Antes de 2007\"}\n",
        "\n",
        "    self.train_df['TP_ANO_CONCLUIU'] = self.train_df['TP_ANO_CONCLUIU'].map(rename)\n",
        "    self.test_df['TP_ANO_CONCLUIU'] = self.test_df['TP_ANO_CONCLUIU'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"0\",#np.NaN,\n",
        "      2:\"Pública\",\n",
        "      3:\"Privada\",\n",
        "      4:\"Exterior\"}\n",
        "\n",
        "    self.train_df['TP_ESCOLA'] = self.train_df['TP_ESCOLA'].map(rename)\n",
        "    self.test_df['TP_ESCOLA'] = self.test_df['TP_ESCOLA'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"Federal\",\n",
        "      2:\"Estadual\",\n",
        "      3:\"Municipal\",\n",
        "      4:\"Privada\"}\n",
        "\n",
        "    self.train_df['TP_DEPENDENCIA_ADM_ESC'] = self.train_df['TP_DEPENDENCIA_ADM_ESC'].map(rename)\n",
        "    self.test_df['TP_DEPENDENCIA_ADM_ESC'] = self.test_df['TP_DEPENDENCIA_ADM_ESC'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"Ensino Regular\",\n",
        "      2:\"Educação Especial - Modalidade Substitutiva\",\n",
        "      3:\"Educação de Jovens e Adultos\"}\n",
        "\n",
        "    self.train_df['TP_ENSINO'] = self.train_df['TP_ENSINO'].map(rename)\n",
        "    self.test_df['TP_ENSINO'] = self.test_df['TP_ENSINO'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"Ausente\",\n",
        "      1:\"Presente\",\n",
        "      2:\"Eliminado\"}\n",
        "\n",
        "    for c in [col for col in self.train_df.columns if \"TP_PRESENCA\" in col]:\n",
        "      self.train_df[c] = self.train_df[c].map(rename)\n",
        "      self.test_df[c] = self.test_df[c].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        1:\"Sem problemas\",\n",
        "        2:\"Anulada\",\n",
        "        3:\"Copiou texto motivador\",\n",
        "        4:\"Em branco\",\n",
        "        6:\"Fuga ao tema\",\n",
        "        7:\"Não atende tipo textual\",\n",
        "        8:\"Texto insuficiente\",\n",
        "        9:\"Parte desconectada\"\n",
        "      }\n",
        "\n",
        "    self.train_df['TP_STATUS_REDACAO'] = self.train_df['TP_STATUS_REDACAO'].map(rename)\n",
        "    self.test_df['TP_STATUS_REDACAO'] = self.test_df['TP_STATUS_REDACAO'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':6,\n",
        "        'G':7,\n",
        "        'H':0\n",
        "    }\n",
        "\n",
        "    self.train_df['Q001'] = self.train_df['Q001'].map(rename).astype(int)\n",
        "    self.test_df['Q001'] = self.test_df['Q001'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':6,\n",
        "        'G':7,\n",
        "        'H':0\n",
        "    }\n",
        "\n",
        "    self.train_df['Q002'] = self.train_df['Q002'].map(rename).astype(int)\n",
        "    self.test_df['Q002'] = self.test_df['Q002'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':0,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q003'] = self.train_df['Q003'].map(rename).astype(int)\n",
        "    self.test_df['Q003'] = self.test_df['Q003'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':0,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q004'] = self.train_df['Q004'].map(rename).astype(int)\n",
        "    self.test_df['Q004'] = self.test_df['Q004'].map(rename).astype(int)\n",
        "\n",
        "    #Q005 já é numérica\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':6,\n",
        "        'G':7,\n",
        "        'H':8,\n",
        "        'I':9,\n",
        "        'J':10,\n",
        "        'K':11,\n",
        "        'L':12,\n",
        "        'M':13,\n",
        "        'N':14,\n",
        "        'O':15,\n",
        "        'P':16,\n",
        "        'Q':17\n",
        "    }\n",
        "\n",
        "    self.train_df['Q006'] = self.train_df['Q006'].map(rename).astype(int)\n",
        "    self.test_df['Q006'] = self.test_df['Q006'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q007'] = self.train_df['Q007'].map(rename).astype(int)\n",
        "    self.test_df['Q007'] = self.test_df['Q007'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q008'] = self.train_df['Q008'].map(rename).astype(int)\n",
        "    self.test_df['Q008'] = self.test_df['Q008'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q009'] = self.train_df['Q009'].map(rename).astype(int)\n",
        "    self.test_df['Q009'] = self.test_df['Q009'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q010'] = self.train_df['Q010'].map(rename).astype(int)\n",
        "    self.test_df['Q010'] = self.test_df['Q010'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q011'] = self.train_df['Q011'].map(rename).astype(int)\n",
        "    self.test_df['Q011'] = self.test_df['Q011'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q012'] = self.train_df['Q012'].map(rename).astype(int)\n",
        "    self.test_df['Q012'] = self.test_df['Q012'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q013'] = self.train_df['Q013'].map(rename).astype(int)\n",
        "    self.test_df['Q013'] = self.test_df['Q013'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q014'] = self.train_df['Q014'].map(rename).astype(int)\n",
        "    self.test_df['Q014'] = self.test_df['Q014'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q015'] = self.train_df['Q015'].map(rename).astype(int)\n",
        "    self.test_df['Q015'] = self.test_df['Q015'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q016'] = self.train_df['Q016'].map(rename).astype(int)\n",
        "    self.test_df['Q016'] = self.test_df['Q016'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q017'] = self.train_df['Q017'].map(rename).astype(int)\n",
        "    self.test_df['Q017'] = self.test_df['Q017'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q018'] = self.train_df['Q018'].map(rename).astype(int)\n",
        "    self.test_df['Q018'] = self.test_df['Q018'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q019'] = self.train_df['Q019'].map(rename).astype(int)\n",
        "    self.test_df['Q019'] = self.test_df['Q019'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q020'] = self.train_df['Q020'].map(rename).astype(int)\n",
        "    self.test_df['Q020'] = self.test_df['Q020'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q021'] = self.train_df['Q021'].map(rename).astype(int)\n",
        "    self.test_df['Q021'] = self.test_df['Q021'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q022'] = self.train_df['Q022'].map(rename).astype(int)\n",
        "    self.test_df['Q022'] = self.test_df['Q022'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q023'] = self.train_df['Q023'].map(rename).astype(int)\n",
        "    self.test_df['Q023'] = self.test_df['Q023'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q024'] = self.train_df['Q024'].map(rename).astype(int)\n",
        "    self.test_df['Q024'] = self.test_df['Q024'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q025'] = self.train_df['Q025'].map(rename).astype(int)\n",
        "    self.test_df['Q025'] = self.test_df['Q025'].map(rename).astype(int)"
      ],
      "metadata": {
        "id": "monL-6iYH2lL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.load(path)"
      ],
      "metadata": {
        "id": "OdCHx9nx79Rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22c166d-c5c9-4077-aea9-8ff9e49ebe46"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade inicial de elementos no treino: 40000\n",
            "Quantidade inicial de elementos no teste: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.prepare()"
      ],
      "metadata": {
        "id": "tRA3Key2O2af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d55b65-341b-4932-e4c4-4a14f53ad80b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapeando valores...\n",
            "Criando novas colunas...\n",
            "[FEATURE ENGINEERING] Novas colunas: ['NO_REGIAO_RESIDENCIA', 'REG_NOTA_CN_MEDIA', 'REG_NOTA_CH_MEDIA', 'REG_NOTA_LC_MEDIA', 'REG_NOTA_MT_MEDIA', 'REG_NOTA_REDACAO_MEDIA', 'TP_MINORIA_RACIAL', 'TP_SITUACAO_ESPECIAL', 'TP_SOLTEIRO']\n",
            "[INPUTATION] Colunas com valores nulos preenchidos: ['NU_IDADE']\n",
            "Eliminando colunas...\n",
            "[NULLS] Colunas dropadas no treino: ['CO_ESCOLA', 'CO_MUNICIPIO_ESC', 'CO_UF_ESC', 'NO_MUNICIPIO_ESC', 'SG_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC']\n",
            "[NULLS] Colunas dropadas no teste: ['CO_ESCOLA', 'CO_MUNICIPIO_ESC', 'CO_UF_ESC', 'NO_MUNICIPIO_ESC', 'SG_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC']\n",
            "[DROP COLUMNS] Colunas retiradas por falta de relevânica:[['CO_MUNICIPIO_RESIDENCIA', 'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'CO_MUNICIPIO_NASCIMENTO', 'NO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO', 'TP_ANO_CONCLUIU', 'IN_TREINEIRO', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA']]\n",
            "[INCONSISTENCY] Removendo inconsistências.\n",
            "[NULL TARGETS] Removendo valores nulos nas colunas-alvo\n",
            "[::] Removendo redações que tiraram nota 0\n",
            "Aplicando get dummies...\n",
            "[GET DUMMIES] Colunas categóricas convertidas: ['SG_UF_RESIDENCIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ESCOLA', 'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT', 'TP_STATUS_REDACAO', 'NO_REGIAO_RESIDENCIA']\n",
            "Selecionando features mais importantes\n",
            "[VARIANCE TRESHOLD] Removendo colunas: ['IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_SURDEZ', 'IN_DEFICIENCIA_AUDITIVA', 'IN_SURDO_CEGUEIRA', 'IN_DEFICIENCIA_FISICA', 'IN_DEFICIENCIA_MENTAL', 'IN_DEFICIT_ATENCAO', 'IN_DISLEXIA', 'IN_DISCALCULIA', 'IN_AUTISMO', 'IN_VISAO_MONOCULAR', 'IN_OUTRA_DEF', 'IN_GESTANTE', 'IN_LACTANTE', 'IN_IDOSO', 'IN_ESTUDA_CLASSE_HOSPITALAR', 'IN_SEM_RECURSO', 'IN_BRAILLE', 'IN_AMPLIADA_24', 'IN_AMPLIADA_18', 'IN_LEDOR', 'IN_ACESSO', 'IN_TRANSCRICAO', 'IN_LIBRAS', 'IN_LEITURA_LABIAL', 'IN_MESA_CADEIRA_RODAS', 'IN_MESA_CADEIRA_SEPARADA', 'IN_APOIO_PERNA', 'IN_GUIA_INTERPRETE', 'IN_COMPUTADOR', 'IN_CADEIRA_ESPECIAL', 'IN_CADEIRA_CANHOTO', 'IN_CADEIRA_ACOLCHOADA', 'IN_PROVA_DEITADO', 'IN_MOBILIARIO_OBESO', 'IN_LAMINA_OVERLAY', 'IN_PROTETOR_AURICULAR', 'IN_MEDIDOR_GLICOSE', 'IN_MAQUINA_BRAILE', 'IN_SOROBAN', 'IN_MARCA_PASSO', 'IN_SONDA', 'IN_MEDICAMENTOS', 'IN_SALA_INDIVIDUAL', 'IN_SALA_ESPECIAL', 'IN_SALA_ACOMPANHANTE', 'IN_MOBILIARIO_ESPECIFICO', 'IN_MATERIAL_ESPECIFICO', 'IN_NOME_SOCIAL', 'SG_UF_RESIDENCIA_RR', 'TP_ESTADO_CIVIL_Viúvo(a)', 'TP_NACIONALIDADE_0', 'TP_NACIONALIDADE_Brasileiro(a) Nato(a), nascido(a) no exterior', 'TP_NACIONALIDADE_Estrangeiro(a)', 'TP_PRESENCA_CN_Presente', 'TP_PRESENCA_CH_Presente', 'TP_PRESENCA_LC_Presente', 'TP_PRESENCA_MT_Presente', 'TP_STATUS_REDACAO_Sem problemas']\n",
            "[HIGH CORRELATION] Eliminando colunas redundantes: ['REG_NOTA_CH_MEDIA', 'REG_NOTA_LC_MEDIA', 'REG_NOTA_MT_MEDIA', 'REG_NOTA_REDACAO_MEDIA', 'TP_SEXO_M', 'TP_ESTADO_CIVIL_Solteiro(a)', 'TP_COR_RACA_Branca', 'TP_NACIONALIDADE_Brasileiro(a) Naturalizado(a)', 'TP_ESCOLA_0', 'NO_REGIAO_RESIDENCIA_Sudeste']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = model.tune()"
      ],
      "metadata": {
        "id": "cdr-0BdVPAbq",
        "outputId": "e40a28f2-b6f5-4816-ec2c-1f4550a3e3b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ElasticNet\n",
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.791e+07, tolerance: 1.327e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-65.040, test=-64.246) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.770e+07, tolerance: 1.319e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.905, test=-64.787) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.733e+07, tolerance: 1.306e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.646, test=-65.804) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.730e+07, tolerance: 1.314e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.626, test=-65.849) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.780e+07, tolerance: 1.328e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.968, test=-64.511) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.754e+05, tolerance: 1.327e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-65.038, test=-64.248) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.890e+05, tolerance: 1.319e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.903, test=-64.786) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.756e+06, tolerance: 1.306e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.644, test=-65.805) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.722e+05, tolerance: 1.314e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.624, test=-65.850) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.156e+05, tolerance: 1.328e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.966, test=-64.512) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.111e+05, tolerance: 1.327e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-65.037, test=-64.250) total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.255e+05, tolerance: 1.319e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.901, test=-64.789) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.118e+07, tolerance: 1.306e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.641, test=-65.813) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.083e+05, tolerance: 1.314e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.622, test=-65.853) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.471e+07, tolerance: 1.328e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.964, test=-64.518) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.050e+07, tolerance: 1.327e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-66.127, test=-65.291) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.028e+07, tolerance: 1.319e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.983, test=-65.915) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.993e+07, tolerance: 1.306e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.737, test=-66.826) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.993e+07, tolerance: 1.314e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.729, test=-66.788) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.054e+07, tolerance: 1.328e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-66.116, test=-65.156) total time=   2.0s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.943, test=-65.076) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.794, test=-65.700) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.544, test=-66.629) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.530, test=-66.625) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.912, test=-64.995) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.520, test=-64.596) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.379, test=-65.232) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.128, test=-66.236) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.102, test=-66.294) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.466, test=-64.649) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.128e+07, tolerance: 1.327e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.504, test=-65.684) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.104e+07, tolerance: 1.319e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.359, test=-66.342) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.070e+07, tolerance: 1.306e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.121, test=-67.206) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.072e+07, tolerance: 1.314e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.120, test=-67.138) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.135e+07, tolerance: 1.328e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.520, test=-65.464) total time=   2.0s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-66.361, test=-65.525) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-66.214, test=-66.174) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-65.968, test=-67.045) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-65.956, test=-66.998) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-66.359, test=-65.335) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.916, test=-65.012) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.747, test=-65.635) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.476, test=-66.584) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.447, test=-66.564) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.856, test=-64.903) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.955e+07, tolerance: 1.649e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.359e+07, tolerance: 1.448e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-68.791, test=-69.427) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.395e+07, tolerance: 1.442e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.029, test=-68.473) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.402e+07, tolerance: 1.449e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.067, test=-68.291) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.345e+07, tolerance: 1.442e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-68.705, test=-69.789) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.359e+07, tolerance: 1.446e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-68.793, test=-69.404) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.122e+05, tolerance: 1.448e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-68.789, test=-69.429) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.369e+05, tolerance: 1.442e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.027, test=-68.471) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.706e+05, tolerance: 1.449e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.065, test=-68.296) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.133e+05, tolerance: 1.442e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-68.702, test=-69.793) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.686e+05, tolerance: 1.446e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-68.791, test=-69.403) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+06, tolerance: 1.448e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-68.787, test=-69.431) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.348e+05, tolerance: 1.442e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.026, test=-68.470) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+06, tolerance: 1.449e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.062, test=-68.304) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+06, tolerance: 1.442e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-68.700, test=-69.799) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.786e+05, tolerance: 1.446e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-68.788, test=-69.405) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.619e+07, tolerance: 1.448e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-69.804, test=-70.381) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.649e+07, tolerance: 1.442e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.009, test=-69.637) total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.672e+07, tolerance: 1.449e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.121, test=-69.015) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.610e+07, tolerance: 1.442e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-69.724, test=-70.583) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.628e+07, tolerance: 1.446e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-69.828, test=-70.126) total time=   2.0s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-69.612, test=-70.178) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-69.827, test=-69.404) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-69.927, test=-68.813) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-69.528, test=-70.427) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-69.623, test=-69.970) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.227, test=-69.777) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.455, test=-68.895) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.521, test=-68.446) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.154, test=-70.135) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.215, test=-69.683) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.698e+07, tolerance: 1.448e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-70.166, test=-70.764) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.727e+07, tolerance: 1.442e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-70.368, test=-70.082) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.753e+07, tolerance: 1.449e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-70.497, test=-69.364) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.692e+07, tolerance: 1.442e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-70.105, test=-70.903) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.711e+07, tolerance: 1.446e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-70.214, test=-70.427) total time=   2.0s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.009, test=-70.603) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.215, test=-69.881) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.339, test=-69.193) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-69.933, test=-70.776) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.042, test=-70.293) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-69.571, test=-70.166) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-69.799, test=-69.288) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-69.893, test=-68.728) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-69.459, test=-70.400) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-69.575, test=-69.961) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.719e+07, tolerance: 1.807e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.080e+07, tolerance: 8.549e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.145, test=-53.370) total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.148e+07, tolerance: 8.667e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.721, test=-51.046) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.106e+07, tolerance: 8.545e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.372, test=-52.483) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+07, tolerance: 8.566e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.257, test=-52.967) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.100e+07, tolerance: 8.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.315, test=-52.717) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.890e+05, tolerance: 8.549e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.142, test=-53.374) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.588e+05, tolerance: 8.667e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.719, test=-51.046) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.645e+05, tolerance: 8.545e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.369, test=-52.484) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.835e+05, tolerance: 8.566e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.254, test=-52.965) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.329e+05, tolerance: 8.556e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.313, test=-52.717) total time=   1.7s\n",
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.138, test=-53.384) total time=   1.7s\n",
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.717, test=-51.046) total time=   1.7s\n",
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.364, test=-52.496) total time=   1.6s\n",
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.251, test=-52.963) total time=   1.6s\n",
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.311, test=-52.716) total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.267e+07, tolerance: 8.549e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.125, test=-54.179) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+07, tolerance: 8.667e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.686, test=-51.900) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.292e+07, tolerance: 8.545e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.337, test=-53.355) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.275e+07, tolerance: 8.566e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.189, test=-53.932) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.289e+07, tolerance: 8.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.296, test=-53.463) total time=   1.9s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-52.958, test=-54.029) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.524, test=-51.744) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.180, test=-53.165) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.028, test=-53.786) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.132, test=-53.311) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-52.601, test=-53.741) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-53.185, test=-51.418) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-52.838, test=-52.776) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-52.706, test=-53.426) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-52.777, test=-53.016) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.322e+07, tolerance: 8.549e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-53.488, test=-54.532) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.390e+07, tolerance: 8.667e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-54.050, test=-52.266) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.346e+07, tolerance: 8.545e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-53.696, test=-53.725) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.330e+07, tolerance: 8.566e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-53.547, test=-54.268) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.344e+07, tolerance: 8.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-53.665, test=-53.797) total time=   2.0s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.370, test=-54.425) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.931, test=-52.153) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.589, test=-53.581) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.430, test=-54.172) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.547, test=-53.693) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-52.958, test=-54.074) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.515, test=-51.758) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.194, test=-53.118) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.039, test=-53.790) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.132, test=-53.301) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.884e+07, tolerance: 1.072e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.111e+07, tolerance: 2.716e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-89.694, test=-89.485) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.055e+07, tolerance: 2.695e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-89.418, test=-90.636) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.119e+07, tolerance: 2.709e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-89.729, test=-89.359) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.049e+07, tolerance: 2.704e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-89.385, test=-90.723) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.131e+07, tolerance: 2.728e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-89.790, test=-89.105) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+06, tolerance: 2.716e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-89.692, test=-89.487) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.701e+07, tolerance: 2.695e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-89.416, test=-90.634) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+06, tolerance: 2.709e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-89.727, test=-89.366) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.082e+06, tolerance: 2.704e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-89.383, test=-90.725) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e+06, tolerance: 2.728e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-89.787, test=-89.113) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.689e+07, tolerance: 2.716e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-89.691, test=-89.490) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.563e+07, tolerance: 2.695e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-89.416, test=-90.635) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.708e+07, tolerance: 2.709e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-89.724, test=-89.379) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.557e+07, tolerance: 2.704e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-89.381, test=-90.731) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.643e+07, tolerance: 2.728e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-89.784, test=-89.133) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.802e+07, tolerance: 2.716e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-91.827, test=-91.574) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.732e+07, tolerance: 2.695e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-91.510, test=-92.946) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.810e+07, tolerance: 2.709e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-91.858, test=-91.402) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.747e+07, tolerance: 2.704e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-91.544, test=-92.602) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.854e+07, tolerance: 2.728e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-92.029, test=-90.529) total time=   1.9s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-91.296, test=-91.021) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-90.980, test=-92.363) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-91.326, test=-90.853) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-90.995, test=-92.100) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-91.469, test=-90.064) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-90.235, test=-89.923) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-89.900, test=-91.171) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-90.272, test=-89.740) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-89.908, test=-91.126) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-90.335, test=-89.203) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.992e+07, tolerance: 2.716e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-92.575, test=-92.345) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.919e+07, tolerance: 2.695e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-92.252, test=-93.766) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.000e+08, tolerance: 2.709e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-92.612, test=-92.138) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.940e+07, tolerance: 2.704e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-92.309, test=-93.315) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+08, tolerance: 2.728e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-92.812, test=-91.191) total time=   1.9s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-92.118, test=-91.874) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-91.806, test=-93.259) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-92.154, test=-91.667) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-91.838, test=-92.884) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-92.331, test=-90.787) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-90.723, test=-90.411) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-90.433, test=-91.718) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-90.753, test=-90.232) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-90.416, test=-91.588) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-90.866, test=-89.557) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+08, tolerance: 3.388e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.109e+08, tolerance: 5.475e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-136.438, test=-139.652) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+08, tolerance: 5.486e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-136.953, test=-137.667) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.122e+08, tolerance: 5.488e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-136.879, test=-137.968) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.140e+08, tolerance: 5.536e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-137.439, test=-135.644) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e+08, tolerance: 5.525e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-137.326, test=-136.128) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+08, tolerance: 5.475e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-136.432, test=-139.656) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.736e+08, tolerance: 5.486e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-136.947, test=-137.668) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+08, tolerance: 5.488e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-136.873, test=-137.967) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+08, tolerance: 5.536e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-137.433, test=-135.644) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.991e+07, tolerance: 5.525e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-137.320, test=-136.125) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.983e+08, tolerance: 5.475e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-136.429, test=-139.661) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.998e+08, tolerance: 5.486e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-136.942, test=-137.675) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.801e+08, tolerance: 5.488e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-136.867, test=-137.980) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.894e+08, tolerance: 5.536e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-137.429, test=-135.647) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e+08, tolerance: 5.525e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-137.315, test=-136.129) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+08, tolerance: 5.475e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-139.479, test=-142.466) total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+08, tolerance: 5.486e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-139.947, test=-140.728) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.259e+08, tolerance: 5.488e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-139.970, test=-140.421) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.275e+08, tolerance: 5.536e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-140.506, test=-138.319) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.271e+08, tolerance: 5.525e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-140.374, test=-138.824) total time=   2.0s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-138.812, test=-141.811) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-139.291, test=-140.015) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-139.271, test=-139.819) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-139.840, test=-137.656) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-139.698, test=-138.202) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-137.094, test=-140.082) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-137.585, test=-138.151) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-137.473, test=-138.519) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-138.067, test=-136.026) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-137.943, test=-136.607) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.272e+08, tolerance: 5.475e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-140.312, test=-143.264) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.285e+08, tolerance: 5.486e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-140.767, test=-141.605) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.288e+08, tolerance: 5.488e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-140.826, test=-141.196) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.305e+08, tolerance: 5.536e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-141.339, test=-139.115) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.301e+08, tolerance: 5.525e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-141.216, test=-139.613) total time=   1.9s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-139.790, test=-142.759) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-140.257, test=-141.032) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-140.276, test=-140.699) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-140.820, test=-138.608) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-140.679, test=-139.131) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-137.695, test=-140.649) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-138.178, test=-138.682) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-138.080, test=-138.949) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-138.715, test=-136.588) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-138.552, test=-137.144) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.660e+08, tolerance: 6.878e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTree\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-93.116) total time=   0.5s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.363, test=-93.688) total time=   0.5s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.363, test=-93.944) total time=   0.5s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.363, test=-92.888) total time=   0.5s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-92.878) total time=   0.5s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-55.363, test=-72.150) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-55.463, test=-72.940) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-54.944, test=-74.296) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-55.240, test=-73.202) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-55.349, test=-72.312) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-60.284, test=-68.905) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-60.363, test=-68.554) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-59.938, test=-69.965) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-60.028, test=-69.759) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-60.311, test=-68.717) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-63.493, test=-66.380) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-63.386, test=-66.589) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-63.040, test=-67.952) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-63.141, test=-67.346) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-63.512, test=-66.265) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.720, test=-65.924) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.700, test=-65.873) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.391, test=-67.418) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.374, test=-67.125) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.738, test=-65.661) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-93.362) total time=   0.5s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.363, test=-94.056) total time=   0.5s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.363, test=-94.668) total time=   0.5s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.363, test=-93.188) total time=   0.5s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-93.503) total time=   0.5s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-55.363, test=-72.178) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-55.463, test=-72.940) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-54.944, test=-74.322) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-55.240, test=-73.202) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-55.349, test=-72.310) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-60.284, test=-68.905) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-60.363, test=-68.553) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-59.938, test=-69.965) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-60.028, test=-69.759) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-60.311, test=-68.717) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-63.493, test=-66.380) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-63.386, test=-66.591) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-63.040, test=-67.952) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-63.141, test=-67.346) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-63.512, test=-66.265) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.720, test=-65.924) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.700, test=-65.873) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.391, test=-67.418) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.374, test=-67.125) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.738, test=-65.661) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-92.936) total time=   0.5s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.363, test=-94.353) total time=   0.5s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.363, test=-94.263) total time=   0.5s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.363, test=-93.233) total time=   0.5s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-93.096) total time=   0.5s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-55.363, test=-72.146) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-55.463, test=-72.940) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-54.944, test=-74.322) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-55.240, test=-73.202) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-55.349, test=-72.262) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-60.284, test=-68.913) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-60.363, test=-68.554) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-59.938, test=-69.948) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-60.028, test=-69.759) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-60.311, test=-68.710) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-63.493, test=-66.380) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-63.386, test=-66.591) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-63.040, test=-67.952) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-63.141, test=-67.346) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-63.512, test=-66.265) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.720, test=-65.924) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.700, test=-65.873) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.391, test=-67.418) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.374, test=-67.125) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.738, test=-65.661) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-93.386) total time=   0.5s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.363, test=-93.586) total time=   0.5s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.363, test=-94.440) total time=   0.5s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.363, test=-93.587) total time=   0.5s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-92.667) total time=   0.5s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-55.363, test=-72.164) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-55.463, test=-72.950) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-54.944, test=-74.296) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-55.240, test=-73.186) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-55.349, test=-72.305) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-60.284, test=-68.911) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-60.363, test=-68.554) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-59.938, test=-69.965) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-60.028, test=-69.759) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-60.311, test=-68.711) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-63.493, test=-66.380) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-63.386, test=-66.589) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-63.040, test=-67.952) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-63.141, test=-67.346) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-63.512, test=-66.265) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.720, test=-65.924) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.700, test=-65.873) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.391, test=-67.418) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.374, test=-67.125) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.738, test=-65.661) total time=   0.2s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-98.925) total time=   0.5s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.509, test=-99.480) total time=   0.5s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.509, test=-98.203) total time=   0.5s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.509, test=-99.088) total time=   0.5s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-100.285) total time=   0.5s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-58.762, test=-77.508) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-58.988, test=-76.257) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-58.960, test=-75.442) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-58.607, test=-77.627) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-58.790, test=-77.719) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-63.671, test=-74.372) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-64.137, test=-72.777) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-64.002, test=-72.098) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-63.647, test=-74.031) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-63.780, test=-74.078) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-67.116, test=-71.531) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-67.421, test=-70.457) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-67.252, test=-70.067) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-66.868, test=-71.715) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-66.978, test=-71.409) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-68.408, test=-70.952) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-68.656, test=-70.036) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-68.711, test=-69.826) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-68.296, test=-70.938) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-68.443, test=-70.926) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-98.485) total time=   0.5s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.509, test=-98.006) total time=   0.5s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.509, test=-98.816) total time=   0.5s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.509, test=-98.968) total time=   0.5s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-99.689) total time=   0.5s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-58.762, test=-77.529) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-58.988, test=-76.259) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-58.960, test=-75.442) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-58.607, test=-77.617) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-58.790, test=-77.719) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-63.671, test=-74.372) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-64.137, test=-72.777) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-64.002, test=-72.098) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-63.647, test=-74.031) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-63.780, test=-74.078) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-67.116, test=-71.536) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-67.421, test=-70.457) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-67.252, test=-70.067) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-66.868, test=-71.715) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-66.978, test=-71.409) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-68.408, test=-70.952) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-68.656, test=-70.036) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-68.711, test=-69.826) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-68.296, test=-70.938) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-68.443, test=-70.926) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-99.245) total time=   0.5s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.509, test=-99.547) total time=   0.5s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.509, test=-97.850) total time=   0.5s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.509, test=-99.557) total time=   0.5s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-100.222) total time=   0.5s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-58.762, test=-77.529) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-58.988, test=-76.261) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-58.960, test=-75.442) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-58.607, test=-77.617) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-58.790, test=-77.710) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-63.671, test=-74.372) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-64.137, test=-72.777) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-64.002, test=-72.098) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-63.647, test=-74.031) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-63.780, test=-74.078) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-67.116, test=-71.531) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-67.421, test=-70.457) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-67.252, test=-70.067) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-66.868, test=-71.715) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-66.978, test=-71.409) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-68.408, test=-70.952) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-68.656, test=-70.036) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-68.711, test=-69.826) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-68.296, test=-70.938) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-68.443, test=-70.926) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-99.031) total time=   0.5s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.509, test=-98.378) total time=   0.5s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.509, test=-97.727) total time=   0.5s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.509, test=-98.747) total time=   0.5s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-99.859) total time=   0.5s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-58.762, test=-77.515) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-58.988, test=-76.265) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-58.960, test=-75.442) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-58.607, test=-77.625) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-58.790, test=-77.718) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-63.671, test=-74.372) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-64.137, test=-72.777) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-64.002, test=-72.098) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-63.647, test=-74.031) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-63.780, test=-74.078) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-67.116, test=-71.531) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-67.421, test=-70.457) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-67.252, test=-70.067) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-66.868, test=-71.715) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-66.978, test=-71.409) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-68.408, test=-70.952) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-68.656, test=-70.036) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-68.711, test=-69.826) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-68.296, test=-70.938) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-68.443, test=-70.926) total time=   0.2s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-76.564) total time=   0.4s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.334, test=-75.777) total time=   0.5s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.334, test=-75.068) total time=   0.5s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.334, test=-76.062) total time=   0.5s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-76.077) total time=   0.5s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-44.783, test=-59.485) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-45.449, test=-57.303) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-45.110, test=-58.439) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-44.665, test=-59.968) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-44.718, test=-59.483) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-48.610, test=-56.584) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-49.198, test=-54.787) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-48.851, test=-55.632) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-48.514, test=-56.964) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-48.681, test=-56.312) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-51.115, test=-54.938) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-51.776, test=-52.609) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-51.241, test=-54.186) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-51.011, test=-55.000) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-51.169, test=-54.607) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-52.138, test=-54.491) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-52.678, test=-52.115) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-52.217, test=-53.710) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-52.064, test=-54.638) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-52.188, test=-54.320) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-76.833) total time=   0.5s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.334, test=-74.519) total time=   0.5s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.334, test=-74.825) total time=   0.5s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.334, test=-76.031) total time=   0.5s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-76.766) total time=   0.5s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-44.783, test=-59.490) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-45.449, test=-57.303) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-45.110, test=-58.451) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-44.665, test=-59.968) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-44.718, test=-59.491) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-48.610, test=-56.589) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-49.198, test=-54.787) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-48.851, test=-55.632) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-48.514, test=-56.964) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-48.681, test=-56.313) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-51.115, test=-54.940) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-51.776, test=-52.609) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-51.241, test=-54.184) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-51.011, test=-55.000) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-51.169, test=-54.607) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-52.138, test=-54.495) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-52.678, test=-52.115) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-52.217, test=-53.710) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-52.064, test=-54.638) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-52.188, test=-54.320) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-77.359) total time=   0.5s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.334, test=-75.934) total time=   0.5s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.334, test=-75.125) total time=   0.5s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.334, test=-75.552) total time=   0.5s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-76.457) total time=   0.5s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-44.783, test=-59.489) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-45.449, test=-57.303) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-45.110, test=-58.443) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-44.665, test=-59.987) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-44.718, test=-59.483) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-48.610, test=-56.589) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-49.198, test=-54.787) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-48.851, test=-55.632) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-48.514, test=-56.964) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-48.681, test=-56.313) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-51.115, test=-54.938) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-51.776, test=-52.609) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-51.241, test=-54.186) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-51.011, test=-55.000) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-51.169, test=-54.607) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-52.138, test=-54.495) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-52.678, test=-52.115) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-52.217, test=-53.710) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-52.064, test=-54.638) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-52.188, test=-54.320) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-76.951) total time=   0.4s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.334, test=-74.478) total time=   0.5s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.334, test=-74.552) total time=   0.5s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.334, test=-75.452) total time=   0.5s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-76.638) total time=   0.5s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-44.783, test=-59.485) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-45.449, test=-57.303) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-45.110, test=-58.452) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-44.665, test=-59.987) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-44.718, test=-59.485) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-48.610, test=-56.584) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-49.198, test=-54.787) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-48.851, test=-55.625) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-48.514, test=-56.964) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-48.681, test=-56.312) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-51.115, test=-54.940) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-51.776, test=-52.609) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-51.241, test=-54.186) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-51.011, test=-55.000) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-51.169, test=-54.607) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-52.138, test=-54.491) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-52.678, test=-52.115) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-52.217, test=-53.710) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-52.064, test=-54.638) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-52.188, test=-54.320) total time=   0.2s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-128.143) total time=   0.5s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.295, test=-129.674) total time=   0.5s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.295, test=-130.274) total time=   0.5s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.295, test=-128.778) total time=   0.5s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-126.375) total time=   0.5s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-76.326, test=-101.464) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-76.755, test=-103.019) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-76.760, test=-101.688) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-76.731, test=-101.291) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-77.205, test=-99.889) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-83.336, test=-96.613) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-83.539, test=-96.959) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-83.511, test=-95.547) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-83.482, test=-96.420) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-83.966, test=-94.678) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-88.033, test=-92.714) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-88.209, test=-93.954) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-88.078, test=-93.499) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-87.986, test=-93.660) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-88.365, test=-92.221) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-89.897, test=-91.972) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-89.808, test=-93.401) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-89.985, test=-92.849) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-89.786, test=-93.242) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-90.262, test=-91.201) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-128.400) total time=   0.5s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.295, test=-129.117) total time=   0.5s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.295, test=-131.140) total time=   0.5s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.295, test=-128.406) total time=   0.5s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-127.099) total time=   0.5s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-76.326, test=-101.464) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-76.755, test=-103.020) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-76.760, test=-101.682) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-76.731, test=-101.315) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-77.205, test=-99.887) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-83.336, test=-96.616) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-83.539, test=-96.961) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-83.511, test=-95.546) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-83.482, test=-96.420) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-83.966, test=-94.683) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-88.033, test=-92.714) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-88.209, test=-93.954) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-88.078, test=-93.499) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-87.986, test=-93.660) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-88.365, test=-92.221) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-89.897, test=-91.972) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-89.808, test=-93.401) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-89.985, test=-92.849) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-89.786, test=-93.242) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-90.262, test=-91.201) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-127.981) total time=   0.5s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.295, test=-129.765) total time=   0.5s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.295, test=-130.472) total time=   0.5s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.295, test=-128.268) total time=   0.5s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-127.292) total time=   0.5s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-76.326, test=-101.463) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-76.755, test=-103.043) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-76.760, test=-101.685) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-76.731, test=-101.291) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-77.205, test=-99.903) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-83.336, test=-96.613) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-83.539, test=-96.959) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-83.511, test=-95.546) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-83.482, test=-96.420) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-83.966, test=-94.678) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-88.033, test=-92.714) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-88.209, test=-93.954) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-88.078, test=-93.499) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-87.986, test=-93.660) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-88.365, test=-92.221) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-89.897, test=-91.972) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-89.808, test=-93.401) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-89.985, test=-92.849) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-89.786, test=-93.242) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-90.262, test=-91.201) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-128.081) total time=   0.5s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.295, test=-129.717) total time=   0.5s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.295, test=-130.124) total time=   0.5s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.295, test=-128.602) total time=   0.5s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-127.232) total time=   0.5s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-76.326, test=-101.449) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-76.755, test=-103.021) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-76.760, test=-101.680) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-76.731, test=-101.291) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-77.205, test=-99.903) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-83.336, test=-96.613) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-83.539, test=-96.959) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-83.511, test=-95.547) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-83.482, test=-96.420) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-83.966, test=-94.678) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-88.033, test=-92.714) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-88.209, test=-93.954) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-88.078, test=-93.499) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-87.986, test=-93.660) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-88.365, test=-92.221) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-89.897, test=-91.972) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-89.808, test=-93.401) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-89.985, test=-92.849) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-89.786, test=-93.242) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-90.262, test=-91.201) total time=   0.2s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-200.813) total time=   0.5s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.222, test=-198.557) total time=   0.5s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.222, test=-197.114) total time=   0.5s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.222, test=-196.250) total time=   0.5s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-197.455) total time=   0.5s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-117.152, test=-157.154) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-117.448, test=-155.000) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-116.959, test=-155.615) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-117.781, test=-153.858) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-118.018, test=-152.726) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-127.343, test=-148.753) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-127.695, test=-147.143) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-127.595, test=-148.146) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-127.889, test=-145.792) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-128.441, test=-144.286) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-134.122, test=-145.202) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-134.409, test=-143.203) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-134.394, test=-143.069) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-134.542, test=-140.794) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-135.116, test=-141.437) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-136.775, test=-144.403) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-137.091, test=-142.083) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-137.146, test=-142.495) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-137.636, test=-139.434) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-137.959, test=-140.790) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-199.461) total time=   0.4s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.222, test=-197.655) total time=   0.5s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.222, test=-198.366) total time=   0.5s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.222, test=-195.633) total time=   0.5s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-196.610) total time=   0.5s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-117.152, test=-157.116) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-117.441, test=-155.062) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-116.959, test=-155.649) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-117.781, test=-153.815) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-118.005, test=-152.654) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-127.343, test=-148.753) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-127.695, test=-147.140) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-127.595, test=-148.146) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-127.889, test=-145.813) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-128.441, test=-144.318) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-134.122, test=-145.202) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-134.409, test=-143.203) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-134.394, test=-143.069) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-134.542, test=-140.794) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-135.116, test=-141.437) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-136.775, test=-144.403) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-137.091, test=-142.083) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-137.146, test=-142.495) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-137.636, test=-139.434) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-137.959, test=-140.790) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-200.992) total time=   0.5s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.222, test=-197.877) total time=   0.5s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.222, test=-197.744) total time=   0.5s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.222, test=-196.288) total time=   0.5s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-195.298) total time=   0.4s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-117.152, test=-157.086) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-117.441, test=-155.065) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-116.960, test=-155.609) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-117.781, test=-153.845) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-118.005, test=-152.737) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-127.343, test=-148.753) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-127.695, test=-147.140) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-127.595, test=-148.149) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-127.889, test=-145.792) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-128.438, test=-144.454) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-134.122, test=-145.202) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-134.409, test=-143.212) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-134.394, test=-143.069) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-134.542, test=-140.794) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-135.116, test=-141.437) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-136.775, test=-144.403) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-137.091, test=-142.083) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-137.146, test=-142.495) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-137.636, test=-139.434) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-137.959, test=-140.790) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-200.824) total time=   0.5s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.222, test=-198.137) total time=   0.5s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.222, test=-197.807) total time=   0.5s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.222, test=-195.620) total time=   0.5s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-196.604) total time=   0.4s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-117.152, test=-157.109) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-117.441, test=-155.059) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-116.960, test=-155.642) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-117.781, test=-153.816) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-118.005, test=-152.717) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-127.343, test=-148.753) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-127.695, test=-147.143) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-127.595, test=-148.149) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-127.889, test=-145.786) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-128.441, test=-144.286) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-134.122, test=-145.202) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-134.409, test=-143.203) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-134.394, test=-143.069) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-134.542, test=-140.794) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-135.116, test=-141.437) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-136.775, test=-144.403) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-137.091, test=-142.083) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-137.146, test=-142.495) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-137.636, test=-139.434) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-137.959, test=-140.790) total time=   0.2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.ranking()\n",
        "model.predict()"
      ],
      "metadata": {
        "id": "59hTOzUXtKPK",
        "outputId": "e9c9a47e-19fb-48e9-ec3e-0b5b8890f6cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chave NU_NOTA_CN estava vazia, vamos colocar o algoritmo ElasticNet\n",
            "Chave NU_NOTA_CH estava vazia, vamos colocar o algoritmo ElasticNet\n",
            "Chave NU_NOTA_LC estava vazia, vamos colocar o algoritmo ElasticNet\n",
            "Chave NU_NOTA_MT estava vazia, vamos colocar o algoritmo ElasticNet\n",
            "Chave NU_NOTA_REDACAO estava vazia, vamos colocar o algoritmo ElasticNet\n",
            "{'NU_NOTA_CN': 'ElasticNet', 'NU_NOTA_CH': 'ElasticNet', 'NU_NOTA_LC': 'ElasticNet', 'NU_NOTA_MT': 'ElasticNet', 'NU_NOTA_REDACAO': 'ElasticNet'}\n",
            "Vamos prever NU_NOTA_CN com o algoritmo ElasticNet e hiperparâmetros {'alpha': 0.001, 'l1_ratio': 0}\n",
            "Vamos prever NU_NOTA_CH com o algoritmo ElasticNet e hiperparâmetros {'alpha': 0.001, 'l1_ratio': 0}\n",
            "Vamos prever NU_NOTA_LC com o algoritmo ElasticNet e hiperparâmetros {'alpha': 0.001, 'l1_ratio': 0}\n",
            "Vamos prever NU_NOTA_MT com o algoritmo ElasticNet e hiperparâmetros {'alpha': 0.001, 'l1_ratio': 0}\n",
            "Vamos prever NU_NOTA_REDACAO com o algoritmo ElasticNet e hiperparâmetros {'alpha': 0.001, 'l1_ratio': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model._results"
      ],
      "metadata": {
        "id": "PsSQ7CidpHYD",
        "outputId": "34d88623-4929-4dad-f8d5-d4774666c89f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DecisionTree': {'NU_NOTA_CH': {'best_params': {'max_depth': 70,\n",
              "    'min_samples_leaf': 100},\n",
              "   'best_score': -71.36979527895173},\n",
              "  'NU_NOTA_CN': {'best_params': {'max_depth': 100, 'min_samples_leaf': 100},\n",
              "   'best_score': -66.06008092254851},\n",
              "  'NU_NOTA_LC': {'best_params': {'max_depth': 100, 'min_samples_leaf': 100},\n",
              "   'best_score': -54.38656482726235},\n",
              "  'NU_NOTA_MT': {'best_params': {'max_depth': 100, 'min_samples_leaf': 100},\n",
              "   'best_score': -93.01160204110991},\n",
              "  'NU_NOTA_REDACAO': {'best_params': {'max_depth': 90,\n",
              "    'min_samples_leaf': 100},\n",
              "   'best_score': -140.58504289884291}},\n",
              " 'ElasticNet': {'NU_NOTA_CH': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -69.47536198096927},\n",
              "  'NU_NOTA_CN': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -64.47326888352583},\n",
              "  'NU_NOTA_LC': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -52.89958269748065},\n",
              "  'NU_NOTA_MT': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -90.19288974586475},\n",
              "  'NU_NOTA_REDACAO': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -136.10150095423154}}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dtnvOzngsrSF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ML-Entrega2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}