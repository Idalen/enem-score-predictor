{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Idalen/enem-score-predictor/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmKTip2JOeEd"
      },
      "source": [
        "# Trabalho De ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LcGn6s_bOawi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "\n",
        "import plotly.express as px\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error as RMSE\n",
        "\n",
        "from pathlib import Path\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faX4OUlFbSNi"
      },
      "source": [
        "# Redução do uso da memória"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMpx4whrjNr1"
      },
      "source": [
        "Devido ao consumo de memória do nosso dataset, decidimos aplicar algumas estratégias para a redução do uso pelo Pandas.\n",
        "Primeiro, mudamos o tipo de dado utilizado pelas colunas para formatos que ocupam menos bytes e transformamos o arquivo para o formato *.parquet, que tem melhor suporte à compressão de dados. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLDhQx3AtAWF"
      },
      "outputs": [],
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ1FqdNpjSwM"
      },
      "source": [
        "# Leitura dos arquivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHNyqFcOOdJz",
        "outputId": "e496fbef-5847-4314-ad35-e379dad44b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content//drive; to attempt to forcibly remount, call drive.mount(\"/content//drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "path = Path(\"/content/drive/MyDrive/datasets/dados-enem/\")\n",
        "drive.mount('/content//drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Stj3HCcV5Od"
      },
      "source": [
        "## Anotações:\n",
        "* Testar: se vale a pena eliminar quem está ausente plotando o gráfico pra ver a nota desse grupo de pessoas\n",
        "* Como fazer a conexão do jupyther com o SSH\n",
        "* https://python.plainenglish.io/how-to-create-a-interative-map-using-plotly-express-geojson-to-brazil-in-python-fb5527ae38fc\n",
        "\n",
        "## 1) Tratar dados\n",
        "* EDA Inicial\n",
        "* Tratar nulos (lembre-se de discutir e avaliar as melhores estratégias)\n",
        "* Mapear os valores e OneHotEncoding \n",
        "\n",
        "## 2) Preprocessamento\n",
        "* Remover colunas (correlacionadas [>80%], baixa variância, semântica)\n",
        "* (Opcional) Aplicar PCA \n",
        "* (Opcional) Feature Engineering\n",
        "* Standardize/Normalize\n",
        "* Tratar dados desbalanceados\n",
        "\n",
        "## 3) Modelo\n",
        "* Regressão linear<br>\n",
        "a. Realizar análise dos pesos<br>\n",
        "b. Aplicar técnicas de regularização<br> \n",
        "\n",
        "* Árvore de Decisão <br>\n",
        "a. Profundidade <br>\n",
        "b. Avaliar os cortes (impureza de gini / entropia) <br>\n",
        "\n",
        "* Naive Bayes <br>\n",
        "a. Quais features afetam significativamente P(nota|feature)<br>\n",
        "b. GaussianNaiveBayes x BernoulliNaiveBayes<br>\n",
        "\n",
        "* SVM<br>\n",
        "a. Avaliar o hiperplano gerado/ onde o corte é realizado <br>\n",
        "b. avaliar diferentes kernels <br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "\n",
        "\n",
        "  _algorithms = {\n",
        "      \n",
        "      'ElasticNet': {\n",
        "          'estimator':ElasticNet(),\n",
        "          'parameters':{\n",
        "              'alpha':[0.001, 0.5, 1.0],\n",
        "              'l1_ratio': [0, 0.5, 1.0]\n",
        "          }},\n",
        "\n",
        "      'DecisionTree': {\n",
        "          'estimator':DecisionTreeRegressor(),\n",
        "          'parameters':{\n",
        "              'max_depth':[100, 90, 80, 70],\n",
        "              'min_samples_leaf':[1, 10, 20, 50, 100]\n",
        "          }},\n",
        "\n",
        "      # 'RandomForest': {\n",
        "      #     'estimator':RandomForestRegressor(),\n",
        "      #     'parameters':{\n",
        "      #         'n_estimators':[11, 31, 51],\n",
        "      #         'max_depth':[100, 90, 80,],\n",
        "      #         'min_samples_leaf':[1, 20, 100],\n",
        "      #     }},\n",
        "\n",
        "      # 'KNN': {\n",
        "      #     'estimator':KNeighborsRegressor(),\n",
        "      #     'parameters':{\n",
        "      #         'n_neighbors':[5, 23, 47, 83],\n",
        "      #         'weights':['uniform', 'distance'],\n",
        "      #         'p':[1, 1.5, 2]\n",
        "      #     }},\n",
        "\n",
        "      # 'SVM': {\n",
        "      #     'estimator':SVR(),\n",
        "      #     'parameters':{\n",
        "      #         'kernel':['rbf', 'poly'],\n",
        "      #         'gamma':[0.01, 0.5, 1.0],\n",
        "      #         'C':[10, 100, 1000]\n",
        "      #     }}\n",
        "\n",
        "  }\n",
        "\n",
        "  def __init__(self, verbose=True):\n",
        "    pass\n",
        "\n",
        "  def load(self, path, verbose=True):\n",
        "\n",
        "    self.train_df = pd.read_parquet(path/'train.parquet').sample(40000)\n",
        "    self.test_df = pd.read_parquet(path/'test.parquet').sample(10000)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Quantidade inicial de elementos no treino:\", len(self.train_df))\n",
        "      print(\"Quantidade inicial de elementos no teste:\", len(self.test_df))\n",
        "        \n",
        "    self.train_df.set_index(\"NU_INSCRICAO\", inplace=True)\n",
        "    self.test_df.set_index(\"NU_INSCRICAO\", inplace=True)\n",
        "\n",
        "    self._targets = [col for col in self.train_df.columns if \"NU_NOTA\" in col]\n",
        "\n",
        "\n",
        "\n",
        "  def prepare(self,verbose=True):\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Mapeando valores...\")    \n",
        "    self._map_values(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Criando novas colunas...\")\n",
        "    self._create_features(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Eliminando colunas...\")\n",
        "    self._clear_cols(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Aplicando get dummies...\")\n",
        "    self._create_dummies(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Selecionando features mais importantes\")\n",
        "    self._feature_selection(verbose)\n",
        "\n",
        "\n",
        "  def tune(self, random_state=0, verbose=True):\n",
        "\n",
        "\n",
        "    X, Y = self.train_df.drop(columns=self._targets), self.train_df[self._targets] \n",
        "\n",
        "    self._results = {}\n",
        "\n",
        "    gscv = None\n",
        "\n",
        "    for name, algorithm in self._algorithms.items():\n",
        "      if verbose:\n",
        "        print(name)\n",
        "\n",
        "      self._results[name] = {} \n",
        "\n",
        "      for target in self._targets:\n",
        "        \n",
        "        gscv = GridSearchCV(algorithm['estimator'], algorithm['parameters'], verbose = 3,\n",
        "                             scoring='neg_root_mean_squared_error', return_train_score=True)\n",
        "        gscv.fit(X, Y[target])\n",
        "\n",
        "        self._results[name][target] = {}\n",
        "        self._results[name][target]['best_params'] = gscv.best_params_\n",
        "        self._results[name][target]['best_score'] = gscv.best_score_\n",
        "  \n",
        "    return gscv\n",
        "\n",
        "  def _to_json(self):\n",
        "\n",
        "    with open('results.json', 'w') as fp:\n",
        "      json.dump(self._results, fp)\n",
        "    fp.close()\n",
        "\n",
        "    with open('selecteds.json', 'w') as fp:\n",
        "      json.dump(self._selecteds, fp)\n",
        "\n",
        "  def ranking(self, verbose=True):\n",
        "\n",
        "    self._selecteds = {}\n",
        "\n",
        "    for algoritmo in self._results:\n",
        "\n",
        "      for target in self._targets:\n",
        "\n",
        "        if target not in self._selecteds:\n",
        "          if verbose:\n",
        "            print(\"Chave\", target, \"estava vazia, vamos colocar o algoritmo\", algoritmo)\n",
        "          self._selecteds[target] = algoritmo\n",
        "        \n",
        "        else:\n",
        "          if self._results[algoritmo][target]['best_score'] > self._results[self._selecteds[target]][target]['best_score']:\n",
        "            if verbose:\n",
        "              print(\"O algoritmo\", algoritmo, \"se mostrou mais eficiente que o\", self._selecteds[target])\n",
        "            self._selecteds[target] = algoritmo\n",
        "\n",
        "    self._to_json()\n",
        "\n",
        "\n",
        "  def predict(self):\n",
        "    for target in self._targets:\n",
        "      print(\"Vamos prever\", target, \"com o algoritmo\", self._selecteds[target], \"e hiperparâmetros\", self._results[self._selecteds[target]][target]['best_params'])\n",
        "      # Aplicar o treinamento\n",
        "\n",
        "  def correlation(self, save=False, plot=True):\n",
        "    \n",
        "    fig = px.imshow(self.train_df.corr())\n",
        "    \n",
        "    if plot:\n",
        "      fig.show()\n",
        "\n",
        "    if save:\n",
        "      pass\n",
        "\n",
        "\n",
        "  def plot(self, column):\n",
        "    \n",
        "    tmp = self.train_df[column].value_counts()\n",
        "    fig = px.bar(x=tmp.index, y=tmp.values)\n",
        "    fig.show()\n",
        "    \n",
        "    melted = pd.melt(self.train_df, id_vars=[column], value_vars=self._targets, var_name='TP_NOTA', value_name='NU_NOTA')\n",
        "    fig=px.box(melted.sample(1000000), x='TP_NOTA', y='NU_NOTA', color=column)\n",
        "    fig.show()\n",
        "\n",
        "  def null_analysis(self, plot=True, save=False, verbose=True):\n",
        "    \n",
        "    null_count = self.train_df.isna().apply(np.sum, axis=0)/self.train_df.shape[0]\n",
        "    null_percentage_train = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "    fig_train = px.bar(x=null_percentage_train.index, y=null_percentage_train.values, title=\"Porcentagem de valores nulos nos dados de treino\")\n",
        "\n",
        "    null_count = self.test_df.isna().apply(np.sum, axis=0)/self.test_df.shape[0]\n",
        "    null_percentage_test = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "    fig_test = px.bar(x=null_percentage_test.index, y=null_percentage_test.values, title=\"Porcentagem de valores nulos nos dados de teste\")\n",
        "\n",
        "    if plot:\n",
        "      fig_train.show()\n",
        "      fig_test.show()\n",
        "\n",
        "    if save:\n",
        "      pass\n",
        "\n",
        "  def _feature_selection(self, verbose):\n",
        "    \n",
        "    to_drop = []\n",
        "    treshold = 0.05\n",
        "    for col in self.train_df.columns[1:]:\n",
        "       if self.train_df[col].std() < treshold:\n",
        "         to_drop.append(col)\n",
        "    \n",
        "    self.train_df.drop(columns=to_drop, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop, inplace=True)\n",
        "    if verbose:\n",
        "      print(\"[VARIANCE TRESHOLD] Removendo colunas:\", to_drop)\n",
        "\n",
        "    #################################################################################\n",
        "\n",
        "    correlation = self.train_df.corr().abs()\n",
        "\n",
        "    upper_triangle = correlation.where(np.triu(np.ones(correlation.shape), k=1).astype(bool))\n",
        "\n",
        "    # Considera apenas colunas de correlação mínima de 0.85\n",
        "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\n",
        "    \n",
        "    self.train_df.drop(columns=to_drop, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print('[HIGH CORRELATION] Eliminando colunas redundantes:', to_drop)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def _clear_cols(self, verbose):\n",
        "    \n",
        "    null_count = self.train_df.isna().apply(np.sum, axis=0)/self.train_df.shape[0]\n",
        "    null_percentage_train = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "\n",
        "    null_count = self.test_df.isna().apply(np.sum, axis=0)/self.test_df.shape[0]\n",
        "    null_percentage_test = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "\n",
        "    to_drop_columns_train = list(null_percentage_train[null_percentage_train > 30].index)\n",
        "    to_drop_columns_test = list(null_percentage_test[null_percentage_test > 30].index)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"[NULLS] Colunas dropadas no treino:\", sorted(to_drop_columns_train))\n",
        "      print(\"[NULLS] Colunas dropadas no teste:\", sorted(to_drop_columns_test))\n",
        "\n",
        "    self.train_df.drop(columns=to_drop_columns_train, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop_columns_test, inplace=True)\n",
        "\n",
        "    ###################################################################################################################\n",
        "\n",
        "    to_drop = ['CO_MUNICIPIO_RESIDENCIA', 'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'CO_MUNICIPIO_NASCIMENTO', 'NO_MUNICIPIO_NASCIMENTO',\n",
        "    'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO', 'TP_ANO_CONCLUIU', 'IN_TREINEIRO', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA',\n",
        "    'SG_UF_PROVA']\n",
        "\n",
        "    self.train_df.drop(columns=to_drop, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print(f'[DROP COLUMNS] Colunas retiradas por falta de relevânica:{[to_drop]}')\n",
        "\n",
        "    ##################################################################################################################\n",
        "\n",
        "    to_drop = self.train_df[(self.train_df['TP_STATUS_REDACAO'].isna()) & (self.train_df['TP_PRESENCA_CH']=='Presente')].index\n",
        "    self.train_df.drop(to_drop, inplace=True)\n",
        "\n",
        "    to_drop = self.test_df[(self.test_df['TP_STATUS_REDACAO'].isna()) & (self.test_df['TP_PRESENCA_CH']=='Presente')].index\n",
        "    self.test_df.drop(to_drop, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print(f'[INCONSISTENCY] Removendo inconsistências.')\n",
        "\n",
        "    ##################################################################################################################\n",
        "    \n",
        "\n",
        "    to_drop = ['NU_NOTA_MT', 'NU_NOTA_CH', 'NU_NOTA_CN', 'NU_NOTA_LC', 'NU_NOTA_REDACAO', 'TP_STATUS_REDACAO']\n",
        "    self.train_df.dropna(subset=to_drop, inplace=True)\n",
        "\n",
        "    try:\n",
        "      self.test_df.dropna(subset=to_drop, inplace=True)\n",
        "    except KeyError:\n",
        "      pass #\n",
        "\n",
        "    if verbose:\n",
        "      print('[NULL TARGETS] Removendo valores nulos nas colunas-alvo')\n",
        "\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    self.train_df.drop(self.train_df[self.train_df['TP_STATUS_REDACAO'] != 'Sem problemas'].index, inplace=True)\n",
        "    self.test_df.drop(self.test_df[self.test_df['TP_STATUS_REDACAO'] != 'Sem problemas'].index, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print('[::] Removendo redações que tiraram nota 0')\n",
        "\n",
        "\n",
        "  def _create_dummies(self, verbose):\n",
        "\n",
        "    cols = [col for col in self.train_df.columns if ((self.train_df[col].dtype == 'object') or (self.train_df[col].dtype.name == 'category'))]\n",
        "\n",
        "    self.train_df = pd.get_dummies(self.train_df, columns=cols)\n",
        "    self.test_df = pd.get_dummies(self.test_df, columns=cols)\n",
        "\n",
        "    if verbose:\n",
        "      print(f\"[GET DUMMIES] Colunas categóricas convertidas: {cols}\")\n",
        "\n",
        "\n",
        "  def _create_features(self, verbose):\n",
        "\n",
        "    new_columns = []\n",
        "    filled_columns = []\n",
        "    ############################################################################################\n",
        "\n",
        "    uf_regiao = {\n",
        "      'RR':'Norte', 'AP':'Norte', 'AM':'Norte', 'PA':'Norte', 'AC':'Norte', 'RO':'Norte', 'TO':'Norte', 'MA':'Nordeste',\n",
        "      'PI':'Nordeste', 'CE':'Nordeste', 'RN':'Nordeste', 'PB':'Nordeste', 'PE':'Nordeste', 'AL':'Nordeste', 'SE':'Nordeste',\n",
        "      'BA':'Nordeste', 'MT':'Centro-oeste', 'DF':'Centro-oeste', 'GO':'Centro-oeste', 'MS':'Centro-oeste', 'MG':'Sudeste',\n",
        "      'ES':'Sudeste', 'RJ':'Sudeste', 'SP':'Sudeste', 'PR':'Sul', 'SC':'Sul', 'RS':'Sul', \n",
        "      }\n",
        "\n",
        "    self.train_df['NO_REGIAO_RESIDENCIA'] = self.train_df['SG_UF_RESIDENCIA'].map(uf_regiao)\n",
        "    self.test_df['NO_REGIAO_RESIDENCIA'] = self.test_df['SG_UF_RESIDENCIA'].map(uf_regiao)\n",
        "\n",
        "    new_columns.append('NO_REGIAO_RESIDENCIA')\n",
        "\n",
        "    ############################################################################################\n",
        "\n",
        "    mean_score_per_reg = self.train_df.groupby(\"NO_REGIAO_RESIDENCIA\")[self._targets].mean()\n",
        "    for col in self._targets:\n",
        "      self.train_df[\"REG_NOTA_\"+col.split(\"_\")[2]+\"_MEDIA\"] = self.train_df['NO_REGIAO_RESIDENCIA'].apply(\n",
        "          lambda row: mean_score_per_reg[col][row]) \n",
        "      self.test_df[\"REG_NOTA_\"+col.split(\"_\")[2]+\"_MEDIA\"] = self.test_df['NO_REGIAO_RESIDENCIA'].apply(\n",
        "          lambda row: mean_score_per_reg[col][row]) \n",
        "\n",
        "      new_columns.append(\"REG_NOTA_\"+col.split(\"_\")[2]+\"_MEDIA\")\n",
        "    ############################################################################################\n",
        "  \n",
        "    \n",
        "    self.train_df['TP_MINORIA_RACIAL'] = ((self.train_df['TP_COR_RACA'] != 'Branca').astype(int) + (self.train_df['TP_COR_RACA'] != 'Amarela').astype(int)) -1\n",
        "    self.test_df['TP_MINORIA_RACIAL'] = ((self.test_df['TP_COR_RACA'] != 'Branca').astype(int) + (self.test_df['TP_COR_RACA'] != 'Amarela').astype(int)) -1\n",
        "\n",
        "    new_columns.append('TP_MINORIA_RACIAL')\n",
        "    ############################################################################################\n",
        "\n",
        "    cols = [col for col in self.train_df.columns if ((\"IN_\" in col) and ('TREINEIRO' not in col))]\n",
        "\n",
        "    self.train_df['TP_SITUACAO_ESPECIAL'] = self.train_df[cols].any(axis=1)\n",
        "    self.test_df['TP_SITUACAO_ESPECIAL'] = self.test_df[cols].any(axis=1)\n",
        "\n",
        "    new_columns.append('TP_SITUACAO_ESPECIAL')\n",
        "\n",
        "    #############################################################################################\n",
        "\n",
        "\n",
        "    self.train_df['TP_SOLTEIRO'] = self.train_df['TP_ESTADO_CIVIL'] == 'Solteiro(a)'\n",
        "    self.test_df['TP_SOLTEIRO'] = self.test_df['TP_ESTADO_CIVIL'] == 'Solteiro(a)'\n",
        "\n",
        "    new_columns.append('TP_SOLTEIRO')\n",
        "\n",
        "    #############################################################################################\n",
        "\n",
        "    median_train = self.train_df.loc[self.train_df['NU_IDADE'].notnull(), 'NU_IDADE'].median()\n",
        "    \n",
        "    self.train_df['NU_IDADE'] = self.train_df['NU_IDADE'].fillna(median_train)\n",
        "    self.test_df['NU_IDADE'] = self.test_df['NU_IDADE'].fillna(median_train)\n",
        "  \n",
        "    filled_columns.append(\"NU_IDADE\")\n",
        "    #############################################################################################\n",
        "\n",
        "    if verbose:\n",
        "      print(f'[FEATURE ENGINEERING] Novas colunas: {new_columns}')\n",
        "      print(f'[INPUTATION] Colunas com valores nulos preenchidos: {filled_columns}')\n",
        "      \n",
        "\n",
        "\n",
        "  \n",
        "  def _map_values(self, verbose):\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"Solteiro(a)\",\n",
        "      2:\"Casado(a)/Mora com companheiro(a)\",\n",
        "      3:\"Divorciado(a)/Desquitado(a)/Separado(a)\",\n",
        "      4:\"Viúvo(a)\"}\n",
        "\n",
        "    self.train_df['TP_ESTADO_CIVIL'] = self.train_df['TP_ESTADO_CIVIL'].map(rename)\n",
        "    self.test_df['TP_ESTADO_CIVIL'] = self.test_df['TP_ESTADO_CIVIL'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"Branca\",\n",
        "      2:\"Preta\",\n",
        "      3:\"Parda\",\n",
        "      4:\"Amarela\",\n",
        "      5:\"Indígena\"}\n",
        "\n",
        "    self.train_df['TP_COR_RACA'] = self.train_df['TP_COR_RACA'].map(rename)\n",
        "    self.test_df['TP_COR_RACA'] = self.test_df['TP_COR_RACA'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"Brasileiro(a)\",\n",
        "      2:\"Brasileiro(a) Naturalizado(a)\",\n",
        "      3:\"Estrangeiro(a)\",\n",
        "      4:\"Brasileiro(a) Nato(a), nascido(a) no exterior\"\n",
        "      }\n",
        "\n",
        "    self.train_df['TP_NACIONALIDADE'] = self.train_df['TP_NACIONALIDADE'].map(rename)\n",
        "    self.test_df['TP_NACIONALIDADE'] = self.test_df['TP_NACIONALIDADE'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"Já concluí o Ensino Médio\",\n",
        "      2:\"Estou cursando e concluirei o Ensino Médio no ano corrente\",\n",
        "      3:\"Estou cursando e concluirei o Ensino Médio após o ano corrente\",\n",
        "      4:\"Não concluí e não estou cursando o Ensino Médio\"\n",
        "      }\n",
        "\n",
        "    self.train_df['TP_ST_CONCLUSAO'] = self.train_df['TP_ST_CONCLUSAO'].map(rename)\n",
        "    self.test_df['TP_ST_CONCLUSAO'] = self.test_df['TP_ST_CONCLUSAO'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"2018\",\n",
        "      2:\"2017\",\n",
        "      3:\"2016\",\n",
        "      4:\"2015\",\n",
        "      5:\"2014\",\n",
        "      6:\"2013\",\n",
        "      7:\"2012\",\n",
        "      8:\"2011\",\n",
        "      9:\"2010\",\n",
        "      10:\"2009\",\n",
        "      11:\"2008\",\n",
        "      12:\"2007\",\n",
        "      13:\"Antes de 2007\"}\n",
        "\n",
        "    self.train_df['TP_ANO_CONCLUIU'] = self.train_df['TP_ANO_CONCLUIU'].map(rename)\n",
        "    self.test_df['TP_ANO_CONCLUIU'] = self.test_df['TP_ANO_CONCLUIU'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"0\",#np.NaN,\n",
        "      2:\"Pública\",\n",
        "      3:\"Privada\",\n",
        "      4:\"Exterior\"}\n",
        "\n",
        "    self.train_df['TP_ESCOLA'] = self.train_df['TP_ESCOLA'].map(rename)\n",
        "    self.test_df['TP_ESCOLA'] = self.test_df['TP_ESCOLA'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"Federal\",\n",
        "      2:\"Estadual\",\n",
        "      3:\"Municipal\",\n",
        "      4:\"Privada\"}\n",
        "\n",
        "    self.train_df['TP_DEPENDENCIA_ADM_ESC'] = self.train_df['TP_DEPENDENCIA_ADM_ESC'].map(rename)\n",
        "    self.test_df['TP_DEPENDENCIA_ADM_ESC'] = self.test_df['TP_DEPENDENCIA_ADM_ESC'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"Ensino Regular\",\n",
        "      2:\"Educação Especial - Modalidade Substitutiva\",\n",
        "      3:\"Educação de Jovens e Adultos\"}\n",
        "\n",
        "    self.train_df['TP_ENSINO'] = self.train_df['TP_ENSINO'].map(rename)\n",
        "    self.test_df['TP_ENSINO'] = self.test_df['TP_ENSINO'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"Ausente\",\n",
        "      1:\"Presente\",\n",
        "      2:\"Eliminado\"}\n",
        "\n",
        "    for c in [col for col in self.train_df.columns if \"TP_PRESENCA\" in col]:\n",
        "      self.train_df[c] = self.train_df[c].map(rename)\n",
        "      self.test_df[c] = self.test_df[c].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        1:\"Sem problemas\",\n",
        "        2:\"Anulada\",\n",
        "        3:\"Copiou texto motivador\",\n",
        "        4:\"Em branco\",\n",
        "        6:\"Fuga ao tema\",\n",
        "        7:\"Não atende tipo textual\",\n",
        "        8:\"Texto insuficiente\",\n",
        "        9:\"Parte desconectada\"\n",
        "      }\n",
        "\n",
        "    self.train_df['TP_STATUS_REDACAO'] = self.train_df['TP_STATUS_REDACAO'].map(rename)\n",
        "    self.test_df['TP_STATUS_REDACAO'] = self.test_df['TP_STATUS_REDACAO'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':6,\n",
        "        'G':7,\n",
        "        'H':0\n",
        "    }\n",
        "\n",
        "    self.train_df['Q001'] = self.train_df['Q001'].map(rename).astype(int)\n",
        "    self.test_df['Q001'] = self.test_df['Q001'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':6,\n",
        "        'G':7,\n",
        "        'H':0\n",
        "    }\n",
        "\n",
        "    self.train_df['Q002'] = self.train_df['Q002'].map(rename).astype(int)\n",
        "    self.test_df['Q002'] = self.test_df['Q002'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':0,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q003'] = self.train_df['Q003'].map(rename).astype(int)\n",
        "    self.test_df['Q003'] = self.test_df['Q003'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':0,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q004'] = self.train_df['Q004'].map(rename).astype(int)\n",
        "    self.test_df['Q004'] = self.test_df['Q004'].map(rename).astype(int)\n",
        "\n",
        "    #Q005 já é numérica\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':6,\n",
        "        'G':7,\n",
        "        'H':8,\n",
        "        'I':9,\n",
        "        'J':10,\n",
        "        'K':11,\n",
        "        'L':12,\n",
        "        'M':13,\n",
        "        'N':14,\n",
        "        'O':15,\n",
        "        'P':16,\n",
        "        'Q':17\n",
        "    }\n",
        "\n",
        "    self.train_df['Q006'] = self.train_df['Q006'].map(rename).astype(int)\n",
        "    self.test_df['Q006'] = self.test_df['Q006'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q007'] = self.train_df['Q007'].map(rename).astype(int)\n",
        "    self.test_df['Q007'] = self.test_df['Q007'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q008'] = self.train_df['Q008'].map(rename).astype(int)\n",
        "    self.test_df['Q008'] = self.test_df['Q008'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q009'] = self.train_df['Q009'].map(rename).astype(int)\n",
        "    self.test_df['Q009'] = self.test_df['Q009'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q010'] = self.train_df['Q010'].map(rename).astype(int)\n",
        "    self.test_df['Q010'] = self.test_df['Q010'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q011'] = self.train_df['Q011'].map(rename).astype(int)\n",
        "    self.test_df['Q011'] = self.test_df['Q011'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q012'] = self.train_df['Q012'].map(rename).astype(int)\n",
        "    self.test_df['Q012'] = self.test_df['Q012'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q013'] = self.train_df['Q013'].map(rename).astype(int)\n",
        "    self.test_df['Q013'] = self.test_df['Q013'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q014'] = self.train_df['Q014'].map(rename).astype(int)\n",
        "    self.test_df['Q014'] = self.test_df['Q014'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q015'] = self.train_df['Q015'].map(rename).astype(int)\n",
        "    self.test_df['Q015'] = self.test_df['Q015'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q016'] = self.train_df['Q016'].map(rename).astype(int)\n",
        "    self.test_df['Q016'] = self.test_df['Q016'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q017'] = self.train_df['Q017'].map(rename).astype(int)\n",
        "    self.test_df['Q017'] = self.test_df['Q017'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q018'] = self.train_df['Q018'].map(rename).astype(int)\n",
        "    self.test_df['Q018'] = self.test_df['Q018'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q019'] = self.train_df['Q019'].map(rename).astype(int)\n",
        "    self.test_df['Q019'] = self.test_df['Q019'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q020'] = self.train_df['Q020'].map(rename).astype(int)\n",
        "    self.test_df['Q020'] = self.test_df['Q020'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q021'] = self.train_df['Q021'].map(rename).astype(int)\n",
        "    self.test_df['Q021'] = self.test_df['Q021'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q022'] = self.train_df['Q022'].map(rename).astype(int)\n",
        "    self.test_df['Q022'] = self.test_df['Q022'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q023'] = self.train_df['Q023'].map(rename).astype(int)\n",
        "    self.test_df['Q023'] = self.test_df['Q023'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q024'] = self.train_df['Q024'].map(rename).astype(int)\n",
        "    self.test_df['Q024'] = self.test_df['Q024'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q025'] = self.train_df['Q025'].map(rename).astype(int)\n",
        "    self.test_df['Q025'] = self.test_df['Q025'].map(rename).astype(int)"
      ],
      "metadata": {
        "id": "monL-6iYH2lL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.load(path)"
      ],
      "metadata": {
        "id": "OdCHx9nx79Rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf88a7f-9989-4080-b1f8-9b2296231b59"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade inicial de elementos no treino: 40000\n",
            "Quantidade inicial de elementos no teste: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.prepare()"
      ],
      "metadata": {
        "id": "tRA3Key2O2af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c99288b-8618-4bf7-dea6-91296ad4dedd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapeando valores...\n",
            "Criando novas colunas...\n",
            "[FEATURE ENGINEERING] Novas colunas: ['NO_REGIAO_RESIDENCIA', 'REG_NOTA_CN_MEDIA', 'REG_NOTA_CH_MEDIA', 'REG_NOTA_LC_MEDIA', 'REG_NOTA_MT_MEDIA', 'REG_NOTA_REDACAO_MEDIA', 'TP_MINORIA_RACIAL', 'TP_SITUACAO_ESPECIAL', 'TP_SOLTEIRO']\n",
            "[INPUTATION] Colunas com valores nulos preenchidos: ['NU_IDADE']\n",
            "Eliminando colunas...\n",
            "[NULLS] Colunas dropadas no treino: ['CO_ESCOLA', 'CO_MUNICIPIO_ESC', 'CO_UF_ESC', 'NO_MUNICIPIO_ESC', 'SG_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC']\n",
            "[NULLS] Colunas dropadas no teste: ['CO_ESCOLA', 'CO_MUNICIPIO_ESC', 'CO_UF_ESC', 'NO_MUNICIPIO_ESC', 'SG_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC']\n",
            "[DROP COLUMNS] Colunas retiradas por falta de relevânica:[['CO_MUNICIPIO_RESIDENCIA', 'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'CO_MUNICIPIO_NASCIMENTO', 'NO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO', 'TP_ANO_CONCLUIU', 'IN_TREINEIRO', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA']]\n",
            "[INCONSISTENCY] Removendo inconsistências.\n",
            "[NULL TARGETS] Removendo valores nulos nas colunas-alvo\n",
            "[::] Removendo redações que tiraram nota 0\n",
            "Aplicando get dummies...\n",
            "[GET DUMMIES] Colunas categóricas convertidas: ['SG_UF_RESIDENCIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ESCOLA', 'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT', 'TP_STATUS_REDACAO', 'NO_REGIAO_RESIDENCIA']\n",
            "Selecionando features mais importantes\n",
            "[VARIANCE TRESHOLD] Removendo colunas: ['IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_SURDEZ', 'IN_DEFICIENCIA_AUDITIVA', 'IN_SURDO_CEGUEIRA', 'IN_DEFICIENCIA_FISICA', 'IN_DEFICIENCIA_MENTAL', 'IN_DEFICIT_ATENCAO', 'IN_DISLEXIA', 'IN_DISCALCULIA', 'IN_AUTISMO', 'IN_VISAO_MONOCULAR', 'IN_OUTRA_DEF', 'IN_GESTANTE', 'IN_LACTANTE', 'IN_IDOSO', 'IN_ESTUDA_CLASSE_HOSPITALAR', 'IN_SEM_RECURSO', 'IN_BRAILLE', 'IN_AMPLIADA_24', 'IN_AMPLIADA_18', 'IN_LEDOR', 'IN_ACESSO', 'IN_TRANSCRICAO', 'IN_LIBRAS', 'IN_LEITURA_LABIAL', 'IN_MESA_CADEIRA_RODAS', 'IN_MESA_CADEIRA_SEPARADA', 'IN_APOIO_PERNA', 'IN_GUIA_INTERPRETE', 'IN_COMPUTADOR', 'IN_CADEIRA_ESPECIAL', 'IN_CADEIRA_CANHOTO', 'IN_CADEIRA_ACOLCHOADA', 'IN_PROVA_DEITADO', 'IN_MOBILIARIO_OBESO', 'IN_LAMINA_OVERLAY', 'IN_PROTETOR_AURICULAR', 'IN_MEDIDOR_GLICOSE', 'IN_MAQUINA_BRAILE', 'IN_SOROBAN', 'IN_MARCA_PASSO', 'IN_SONDA', 'IN_MEDICAMENTOS', 'IN_SALA_INDIVIDUAL', 'IN_SALA_ESPECIAL', 'IN_SALA_ACOMPANHANTE', 'IN_MOBILIARIO_ESPECIFICO', 'IN_MATERIAL_ESPECIFICO', 'IN_NOME_SOCIAL', 'TP_ESTADO_CIVIL_Viúvo(a)', 'TP_NACIONALIDADE_0', 'TP_NACIONALIDADE_Brasileiro(a) Nato(a), nascido(a) no exterior', 'TP_NACIONALIDADE_Estrangeiro(a)', 'TP_PRESENCA_CN_Presente', 'TP_PRESENCA_CH_Presente', 'TP_PRESENCA_LC_Presente', 'TP_PRESENCA_MT_Presente', 'TP_STATUS_REDACAO_Sem problemas']\n",
            "[HIGH CORRELATION] Eliminando colunas redundantes: ['REG_NOTA_CH_MEDIA', 'REG_NOTA_LC_MEDIA', 'REG_NOTA_MT_MEDIA', 'REG_NOTA_REDACAO_MEDIA', 'TP_SEXO_M', 'TP_ESTADO_CIVIL_Solteiro(a)', 'TP_COR_RACA_Branca', 'TP_NACIONALIDADE_Brasileiro(a) Naturalizado(a)', 'TP_ESCOLA_0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = model.tune()"
      ],
      "metadata": {
        "id": "cdr-0BdVPAbq",
        "outputId": "164665d9-5107-4c51-b421-127d3a0af0eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ElasticNet\n",
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.711e+07, tolerance: 1.300e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.531, test=-64.730) total time=   2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.752e+07, tolerance: 1.309e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.809, test=-63.566) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.727e+07, tolerance: 1.300e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.634, test=-64.278) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.659e+07, tolerance: 1.295e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.172, test=-66.101) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.702e+07, tolerance: 1.303e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.468, test=-64.959) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.652e+07, tolerance: 1.300e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.528, test=-64.730) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.071e+07, tolerance: 1.309e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.806, test=-63.572) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.990e+07, tolerance: 1.300e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.632, test=-64.278) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.459e+07, tolerance: 1.295e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.170, test=-66.101) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.875e+07, tolerance: 1.303e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.466, test=-64.962) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.953e+05, tolerance: 1.300e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.524, test=-64.744) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.131e+07, tolerance: 1.309e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.803, test=-63.588) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.133e+07, tolerance: 1.300e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.630, test=-64.277) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.075e+07, tolerance: 1.295e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.168, test=-66.099) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.120e+07, tolerance: 1.303e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.464, test=-64.965) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.980e+07, tolerance: 1.300e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.656, test=-66.093) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.024e+07, tolerance: 1.309e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.935, test=-64.902) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.010e+07, tolerance: 1.300e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.832, test=-65.276) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.949e+07, tolerance: 1.295e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.396, test=-66.879) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.996e+07, tolerance: 1.303e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.717, test=-65.628) total time=   2.0s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.454, test=-65.849) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.733, test=-64.651) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.617, test=-65.049) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.163, test=-66.720) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.487, test=-65.460) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.043, test=-65.265) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.328, test=-64.119) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.186, test=-64.590) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-64.692, test=-66.473) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.035, test=-65.179) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.061e+07, tolerance: 1.300e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.062, test=-66.557) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.105e+07, tolerance: 1.309e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.351, test=-65.345) total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.092e+07, tolerance: 1.300e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.258, test=-65.705) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.034e+07, tolerance: 1.295e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-65.844, test=-67.231) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.080e+07, tolerance: 1.303e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.164, test=-66.009) total time=   2.0s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-65.895, test=-66.358) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-66.184, test=-65.143) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-66.084, test=-65.519) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-65.646, test=-67.080) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-65.971, test=-65.856) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.403, test=-65.703) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.688, test=-64.553) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.553, test=-64.943) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.034, test=-66.640) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.397, test=-65.495) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.892e+07, tolerance: 1.627e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.552e+07, tolerance: 1.471e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-70.056, test=-69.434) total time=   2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.545e+07, tolerance: 1.466e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-70.015, test=-69.586) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.542e+07, tolerance: 1.462e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.988, test=-69.710) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.475e+07, tolerance: 1.461e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.562, test=-71.373) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.515e+07, tolerance: 1.465e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.819, test=-70.391) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.846e+06, tolerance: 1.471e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-70.052, test=-69.436) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e+07, tolerance: 1.466e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-70.013, test=-69.580) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.083e+06, tolerance: 1.462e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.985, test=-69.709) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.688e+07, tolerance: 1.461e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.559, test=-71.378) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.072e+07, tolerance: 1.465e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.817, test=-70.394) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+06, tolerance: 1.471e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-70.046, test=-69.458) total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+06, tolerance: 1.466e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-70.010, test=-69.573) total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+06, tolerance: 1.462e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.983, test=-69.709) total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.410e+05, tolerance: 1.461e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.556, test=-71.385) total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.955e+07, tolerance: 1.465e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.816, test=-70.396) total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.807e+07, tolerance: 1.471e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-71.044, test=-70.719) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.803e+07, tolerance: 1.466e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-71.006, test=-70.801) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.819e+07, tolerance: 1.462e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-71.070, test=-70.364) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.752e+07, tolerance: 1.461e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.650, test=-72.044) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.793e+07, tolerance: 1.465e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.916, test=-71.041) total time=   1.9s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.874, test=-70.489) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.824, test=-70.580) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.866, test=-70.210) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.455, test=-71.891) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.720, test=-70.866) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-70.508, test=-69.934) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-70.473, test=-70.140) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-70.451, test=-69.938) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-70.055, test=-71.599) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-70.317, test=-70.579) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.884e+07, tolerance: 1.471e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-71.387, test=-71.134) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.880e+07, tolerance: 1.466e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-71.365, test=-71.210) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.901e+07, tolerance: 1.462e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-71.459, test=-70.688) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.834e+07, tolerance: 1.461e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-71.031, test=-72.336) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.873e+07, tolerance: 1.465e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-71.300, test=-71.391) total time=   2.0s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-71.246, test=-70.966) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-71.217, test=-71.025) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-71.288, test=-70.534) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.866, test=-72.214) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-71.137, test=-71.236) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.826, test=-70.314) total time=   0.2s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.776, test=-70.532) total time=   0.2s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.802, test=-70.142) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.379, test=-71.855) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.647, test=-70.870) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.911e+07, tolerance: 1.831e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.243e+07, tolerance: 8.795e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-53.542, test=-52.669) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.251e+07, tolerance: 8.760e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-53.605, test=-52.394) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.221e+07, tolerance: 8.656e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-53.354, test=-53.425) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.180e+07, tolerance: 8.646e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-53.011, test=-54.733) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.195e+07, tolerance: 8.689e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-53.146, test=-54.232) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.845e+05, tolerance: 8.795e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-53.539, test=-52.672) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+07, tolerance: 8.760e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-53.603, test=-52.397) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e+07, tolerance: 8.656e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-53.352, test=-53.424) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.137e+05, tolerance: 8.646e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-53.009, test=-54.735) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.981e+06, tolerance: 8.689e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-53.145, test=-54.231) total time=   1.8s\n",
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-53.536, test=-52.683) total time=   1.6s\n",
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-53.601, test=-52.404) total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.858e+05, tolerance: 8.656e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-53.351, test=-53.424) total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e+07, tolerance: 8.646e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-53.008, test=-54.738) total time=   1.7s\n",
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-53.144, test=-54.228) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.419e+07, tolerance: 8.795e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-54.423, test=-53.636) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.430e+07, tolerance: 8.760e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-54.514, test=-53.249) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.402e+07, tolerance: 8.656e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-54.272, test=-54.188) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.361e+07, tolerance: 8.646e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.936, test=-55.500) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.381e+07, tolerance: 8.689e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-54.093, test=-54.851) total time=   2.0s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-54.275, test=-53.468) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-54.360, test=-53.084) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-54.120, test=-54.017) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.779, test=-55.376) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.929, test=-54.712) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-53.994, test=-53.096) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-54.059, test=-52.802) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-53.820, test=-53.705) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-53.472, test=-55.124) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-53.615, test=-54.486) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.471e+07, tolerance: 8.795e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-54.758, test=-53.980) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.482e+07, tolerance: 8.760e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-54.856, test=-53.620) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.455e+07, tolerance: 8.656e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-54.622, test=-54.525) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.414e+07, tolerance: 8.646e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-54.285, test=-55.817) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.434e+07, tolerance: 8.689e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-54.452, test=-55.169) total time=   1.9s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-54.658, test=-53.880) total time=   0.2s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-54.748, test=-53.494) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-54.518, test=-54.395) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-54.171, test=-55.744) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-54.338, test=-55.056) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-54.292, test=-53.429) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-54.347, test=-53.088) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-54.121, test=-53.958) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.781, test=-55.448) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.933, test=-54.730) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.025e+07, tolerance: 1.089e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.261e+07, tolerance: 2.691e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-90.469, test=-90.587) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.252e+07, tolerance: 2.696e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-90.426, test=-90.719) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.244e+07, tolerance: 2.664e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-90.387, test=-90.906) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.240e+07, tolerance: 2.685e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-90.370, test=-90.987) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.268e+07, tolerance: 2.692e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-90.506, test=-90.448) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.979e+07, tolerance: 2.691e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-90.464, test=-90.598) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.260e+07, tolerance: 2.696e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-90.422, test=-90.724) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.292e+07, tolerance: 2.664e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-90.383, test=-90.907) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.123e+07, tolerance: 2.685e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-90.367, test=-90.980) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.403e+07, tolerance: 2.692e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-90.504, test=-90.447) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.236e+07, tolerance: 2.691e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-90.460, test=-90.621) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.127e+07, tolerance: 2.696e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-90.419, test=-90.735) total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.122e+07, tolerance: 2.664e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-90.381, test=-90.911) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.119e+07, tolerance: 2.685e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-90.366, test=-90.972) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.142e+07, tolerance: 2.692e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-90.503, test=-90.444) total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.949e+07, tolerance: 2.691e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-92.597, test=-92.448) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.940e+07, tolerance: 2.696e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-92.537, test=-92.616) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.929e+07, tolerance: 2.664e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-92.491, test=-92.860) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.925e+07, tolerance: 2.685e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-92.451, test=-92.894) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.958e+07, tolerance: 2.692e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-92.629, test=-92.284) total time=   1.9s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-92.056, test=-91.885) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-91.993, test=-92.073) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-91.956, test=-92.302) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-91.896, test=-92.416) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-92.086, test=-91.757) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-90.976, test=-90.808) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-90.924, test=-91.061) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-90.886, test=-91.187) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-90.826, test=-91.507) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-91.018, test=-90.739) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+08, tolerance: 2.691e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-93.342, test=-93.207) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+08, tolerance: 2.696e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-93.294, test=-93.336) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+08, tolerance: 2.664e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-93.244, test=-93.618) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+08, tolerance: 2.685e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-93.220, test=-93.577) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+08, tolerance: 2.692e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-93.386, test=-93.037) total time=   2.0s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-92.878, test=-92.724) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-92.822, test=-92.857) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-92.779, test=-93.137) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-92.728, test=-93.150) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-92.909, test=-92.571) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-91.487, test=-91.270) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-91.415, test=-91.512) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-91.398, test=-91.676) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-91.301, test=-91.899) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-91.510, test=-91.208) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+08, tolerance: 3.357e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+08, tolerance: 5.475e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-137.246, test=-136.103) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.120e+08, tolerance: 5.447e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-136.851, test=-137.655) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e+08, tolerance: 5.407e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-136.733, test=-138.198) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+08, tolerance: 5.427e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-136.235, test=-140.146) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e+08, tolerance: 5.485e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-137.627, test=-134.618) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e+08, tolerance: 5.475e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-137.233, test=-136.117) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e+08, tolerance: 5.447e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-136.841, test=-137.650) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.033e+08, tolerance: 5.407e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-136.723, test=-138.187) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.006e+08, tolerance: 5.427e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-136.226, test=-140.145) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.056e+08, tolerance: 5.485e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-137.620, test=-134.609) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.091e+07, tolerance: 5.475e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-137.223, test=-136.162) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+08, tolerance: 5.447e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-136.835, test=-137.653) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.372e+07, tolerance: 5.407e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-136.716, test=-138.187) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.127e+07, tolerance: 5.427e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-136.221, test=-140.145) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.628e+08, tolerance: 5.485e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-137.616, test=-134.592) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.270e+08, tolerance: 5.475e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-140.427, test=-139.378) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+08, tolerance: 5.447e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-140.026, test=-140.919) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e+08, tolerance: 5.407e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-139.876, test=-141.467) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.244e+08, tolerance: 5.427e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-139.560, test=-142.574) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.288e+08, tolerance: 5.485e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-140.957, test=-137.047) total time=   2.0s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-139.765, test=-138.640) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-139.356, test=-140.224) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-139.191, test=-140.825) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-138.850, test=-141.980) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-140.246, test=-136.382) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-137.917, test=-136.522) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-137.514, test=-138.260) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-137.362, test=-138.984) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-136.917, test=-140.513) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-138.301, test=-134.826) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.299e+08, tolerance: 5.475e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-141.256, test=-140.238) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.286e+08, tolerance: 5.447e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-140.868, test=-141.771) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.282e+08, tolerance: 5.407e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-140.731, test=-142.292) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.274e+08, tolerance: 5.427e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-140.438, test=-143.317) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.317e+08, tolerance: 5.485e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-141.827, test=-137.909) total time=   1.9s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-140.748, test=-139.686) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-140.342, test=-141.236) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-140.191, test=-141.796) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-139.886, test=-142.854) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-141.286, test=-137.346) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-138.639, test=-137.184) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-138.161, test=-138.926) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-137.996, test=-139.650) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-137.590, test=-141.055) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-139.002, test=-135.316) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.544e+08, tolerance: 6.810e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTree\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.349, test=-93.131) total time=   0.5s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.457, test=-91.870) total time=   0.5s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.457, test=-93.427) total time=   0.5s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-92.353) total time=   0.5s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.294, test=-91.871) total time=   0.5s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-55.136, test=-72.654) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-55.364, test=-72.190) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-55.292, test=-73.234) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-54.866, test=-73.229) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-55.261, test=-72.132) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-60.031, test=-69.414) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-60.360, test=-67.980) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-60.082, test=-69.218) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-59.635, test=-70.154) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-59.996, test=-68.911) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-63.191, test=-67.146) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-63.404, test=-66.111) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-63.221, test=-66.638) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-62.890, test=-67.996) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-63.124, test=-66.579) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.338, test=-66.524) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.609, test=-65.500) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.473, test=-66.080) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.165, test=-67.381) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.353, test=-66.210) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.349, test=-93.002) total time=   0.5s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.457, test=-92.223) total time=   0.5s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.457, test=-94.117) total time=   0.5s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-92.825) total time=   0.5s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.294, test=-92.193) total time=   0.5s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-55.136, test=-72.658) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-55.364, test=-72.195) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-55.292, test=-73.239) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-54.866, test=-73.223) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-55.261, test=-72.132) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-60.031, test=-69.414) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-60.360, test=-67.980) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-60.082, test=-69.224) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-59.635, test=-70.164) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-59.996, test=-68.911) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-63.191, test=-67.146) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-63.404, test=-66.111) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-63.221, test=-66.638) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-62.890, test=-67.996) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-63.124, test=-66.579) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.338, test=-66.524) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.609, test=-65.500) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.473, test=-66.080) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.165, test=-67.381) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.353, test=-66.210) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.349, test=-92.776) total time=   0.5s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.457, test=-91.713) total time=   0.5s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.457, test=-93.118) total time=   0.5s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-93.183) total time=   0.5s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.294, test=-92.409) total time=   0.5s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-55.136, test=-72.656) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-55.364, test=-72.220) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-55.292, test=-73.236) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-54.866, test=-73.230) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-55.261, test=-72.152) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-60.031, test=-69.414) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-60.360, test=-67.980) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-60.082, test=-69.224) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-59.635, test=-70.156) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-59.996, test=-68.911) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-63.191, test=-67.146) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-63.404, test=-66.111) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-63.221, test=-66.638) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-62.890, test=-67.996) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-63.124, test=-66.579) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.338, test=-66.524) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.609, test=-65.500) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.473, test=-66.080) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.165, test=-67.381) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.353, test=-66.210) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.349, test=-92.968) total time=   0.5s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.457, test=-91.241) total time=   0.5s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.457, test=-93.935) total time=   0.5s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-92.907) total time=   0.5s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.294, test=-92.099) total time=   0.5s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-55.136, test=-72.661) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-55.364, test=-72.217) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-55.292, test=-73.236) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-54.866, test=-73.238) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-55.261, test=-72.151) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-60.031, test=-69.414) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-60.360, test=-67.980) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-60.082, test=-69.224) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-59.635, test=-70.156) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-59.996, test=-68.910) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-63.191, test=-67.146) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-63.404, test=-66.111) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-63.221, test=-66.638) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-62.890, test=-67.996) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-63.124, test=-66.579) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.338, test=-66.524) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.609, test=-65.500) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.473, test=-66.080) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.165, test=-67.381) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.353, test=-66.210) total time=   0.2s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.566, test=-101.425) total time=   0.5s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.576, test=-101.237) total time=   0.5s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.576, test=-100.931) total time=   0.5s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-102.230) total time=   0.5s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.104, test=-101.376) total time=   0.5s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-59.824, test=-78.428) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-59.825, test=-78.016) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-59.910, test=-77.525) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-59.480, test=-80.238) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-59.763, test=-78.657) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-64.943, test=-74.880) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-64.916, test=-74.249) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-64.869, test=-74.112) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-64.516, test=-75.805) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-64.919, test=-74.846) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-68.287, test=-71.889) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-68.093, test=-71.741) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-68.293, test=-72.323) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-67.947, test=-73.667) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-68.182, test=-72.573) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-69.597, test=-71.102) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-69.447, test=-70.969) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-69.513, test=-71.422) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-69.134, test=-72.643) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-69.510, test=-71.651) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.566, test=-100.395) total time=   0.5s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.576, test=-101.541) total time=   0.5s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.576, test=-100.689) total time=   0.5s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-103.084) total time=   0.5s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.104, test=-99.898) total time=   0.5s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-59.824, test=-78.432) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-59.825, test=-78.014) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-59.910, test=-77.515) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-59.480, test=-80.216) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-59.763, test=-78.657) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-64.943, test=-74.880) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-64.916, test=-74.249) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-64.869, test=-74.112) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-64.516, test=-75.816) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-64.919, test=-74.846) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-68.287, test=-71.889) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-68.093, test=-71.741) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-68.293, test=-72.323) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-67.947, test=-73.667) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-68.182, test=-72.573) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-69.597, test=-71.102) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-69.447, test=-70.969) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-69.513, test=-71.422) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-69.134, test=-72.643) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-69.510, test=-71.651) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.566, test=-101.219) total time=   0.5s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.576, test=-101.958) total time=   0.5s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.576, test=-100.841) total time=   0.5s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-102.765) total time=   0.5s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.104, test=-101.183) total time=   0.5s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-59.824, test=-78.428) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-59.825, test=-78.016) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-59.910, test=-77.544) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-59.480, test=-80.234) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-59.763, test=-78.657) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-64.943, test=-74.880) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-64.916, test=-74.240) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-64.869, test=-74.112) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-64.516, test=-75.805) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-64.919, test=-74.846) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-68.287, test=-71.878) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-68.093, test=-71.741) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-68.293, test=-72.323) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-67.947, test=-73.667) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-68.182, test=-72.573) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-69.597, test=-71.102) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-69.447, test=-70.969) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-69.513, test=-71.422) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-69.134, test=-72.643) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-69.510, test=-71.651) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.566, test=-101.706) total time=   0.5s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.576, test=-101.684) total time=   0.5s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.576, test=-101.159) total time=   0.5s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-101.477) total time=   0.5s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.104, test=-100.828) total time=   0.5s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-59.824, test=-78.432) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-59.825, test=-78.014) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-59.910, test=-77.525) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-59.480, test=-80.231) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-59.763, test=-78.657) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-64.943, test=-74.880) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-64.916, test=-74.240) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-64.869, test=-74.112) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-64.516, test=-75.816) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-64.919, test=-74.846) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-68.287, test=-71.889) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-68.093, test=-71.741) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-68.293, test=-72.323) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-67.947, test=-73.667) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-68.182, test=-72.573) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-69.597, test=-71.102) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-69.447, test=-70.969) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-69.513, test=-71.422) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-69.134, test=-72.643) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-69.510, test=-71.651) total time=   0.2s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.276, test=-75.157) total time=   0.5s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.461, test=-76.394) total time=   0.5s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.461, test=-76.053) total time=   0.5s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-77.832) total time=   0.5s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.370, test=-78.308) total time=   0.5s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-45.838, test=-59.178) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-45.874, test=-59.274) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-45.924, test=-59.288) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-45.377, test=-60.656) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-45.603, test=-61.188) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-49.875, test=-56.290) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-49.992, test=-55.926) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-49.691, test=-56.489) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-49.358, test=-58.027) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-49.501, test=-57.710) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-52.397, test=-54.309) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-52.481, test=-54.058) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-52.216, test=-55.018) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-51.874, test=-56.630) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-52.006, test=-55.917) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-53.369, test=-53.754) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-53.431, test=-53.701) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-53.182, test=-54.616) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-52.902, test=-56.200) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-53.144, test=-55.370) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.276, test=-75.470) total time=   0.5s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.461, test=-75.423) total time=   0.5s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.461, test=-75.649) total time=   0.5s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-77.801) total time=   0.5s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.370, test=-78.039) total time=   0.5s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-45.838, test=-59.179) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-45.874, test=-59.270) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-45.924, test=-59.288) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-45.377, test=-60.671) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-45.603, test=-61.188) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-49.875, test=-56.290) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-49.992, test=-55.926) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-49.691, test=-56.493) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-49.358, test=-58.027) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-49.501, test=-57.710) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-52.397, test=-54.309) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-52.481, test=-54.058) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-52.216, test=-55.018) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-51.874, test=-56.630) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-52.006, test=-55.917) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-53.369, test=-53.754) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-53.431, test=-53.701) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-53.182, test=-54.614) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-52.902, test=-56.200) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-53.144, test=-55.370) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.276, test=-75.226) total time=   0.5s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.461, test=-76.554) total time=   0.5s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.461, test=-75.831) total time=   0.5s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-77.600) total time=   0.5s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.370, test=-77.434) total time=   0.5s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-45.838, test=-59.182) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-45.874, test=-59.275) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-45.924, test=-59.294) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-45.377, test=-60.655) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-45.603, test=-61.188) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-49.875, test=-56.296) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-49.992, test=-55.926) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-49.691, test=-56.489) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-49.358, test=-58.027) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-49.501, test=-57.710) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-52.397, test=-54.309) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-52.481, test=-54.058) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-52.216, test=-55.018) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-51.874, test=-56.630) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-52.006, test=-55.917) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-53.369, test=-53.754) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-53.431, test=-53.701) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-53.182, test=-54.616) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-52.902, test=-56.200) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-53.144, test=-55.370) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.276, test=-75.251) total time=   0.5s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.461, test=-76.273) total time=   0.5s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.461, test=-75.577) total time=   0.5s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-78.381) total time=   0.5s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.370, test=-78.777) total time=   0.5s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-45.838, test=-59.181) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-45.874, test=-59.270) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-45.924, test=-59.294) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-45.377, test=-60.671) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-45.603, test=-61.188) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-49.875, test=-56.290) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-49.992, test=-55.926) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-49.691, test=-56.486) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-49.358, test=-58.027) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-49.501, test=-57.710) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-52.397, test=-54.309) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-52.481, test=-54.058) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-52.216, test=-55.018) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-51.874, test=-56.630) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-52.006, test=-55.917) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-53.369, test=-53.754) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-53.431, test=-53.701) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-53.182, test=-54.616) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-52.902, test=-56.200) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-53.144, test=-55.370) total time=   0.2s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.514, test=-130.519) total time=   0.5s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.733, test=-131.176) total time=   0.5s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.733, test=-131.391) total time=   0.5s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-132.060) total time=   0.5s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.522, test=-131.786) total time=   0.5s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-77.765, test=-101.938) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-77.765, test=-102.000) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-77.481, test=-102.383) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-77.382, test=-103.053) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-77.441, test=-102.493) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-84.537, test=-97.046) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-84.456, test=-97.506) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-83.938, test=-98.272) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-84.241, test=-98.080) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-84.379, test=-97.461) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-89.036, test=-94.028) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-88.961, test=-94.123) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-88.561, test=-94.490) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-88.687, test=-94.840) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-88.962, test=-94.107) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-90.814, test=-92.867) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-90.839, test=-93.135) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-90.491, test=-94.118) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-90.593, test=-93.891) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-90.746, test=-93.626) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.514, test=-130.034) total time=   0.5s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.733, test=-129.402) total time=   0.5s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.733, test=-131.173) total time=   0.5s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-132.617) total time=   0.5s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.522, test=-131.684) total time=   0.5s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-77.765, test=-101.932) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-77.765, test=-102.014) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-77.481, test=-102.382) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-77.382, test=-103.041) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-77.441, test=-102.486) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-84.537, test=-97.042) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-84.456, test=-97.506) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-83.938, test=-98.271) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-84.241, test=-98.080) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-84.379, test=-97.461) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-89.036, test=-94.028) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-88.961, test=-94.123) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-88.561, test=-94.490) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-88.687, test=-94.840) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-88.962, test=-94.107) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-90.814, test=-92.867) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-90.839, test=-93.135) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-90.491, test=-94.118) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-90.593, test=-93.891) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-90.746, test=-93.626) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.514, test=-130.517) total time=   0.5s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.733, test=-129.575) total time=   0.5s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.733, test=-131.854) total time=   0.5s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-132.592) total time=   0.5s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.522, test=-131.111) total time=   0.5s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-77.765, test=-101.923) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-77.765, test=-102.011) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-77.481, test=-102.417) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-77.382, test=-103.052) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-77.441, test=-102.508) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-84.537, test=-97.046) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-84.456, test=-97.506) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-83.938, test=-98.271) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-84.241, test=-98.080) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-84.379, test=-97.461) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-89.036, test=-94.028) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-88.961, test=-94.123) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-88.561, test=-94.490) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-88.687, test=-94.840) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-88.962, test=-94.107) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-90.814, test=-92.867) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-90.839, test=-93.135) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-90.491, test=-94.118) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-90.593, test=-93.891) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-90.746, test=-93.626) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.514, test=-129.196) total time=   0.5s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.733, test=-129.965) total time=   0.5s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.733, test=-131.782) total time=   0.5s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-132.550) total time=   0.5s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.522, test=-131.260) total time=   0.5s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-77.765, test=-101.917) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-77.765, test=-102.023) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-77.481, test=-102.383) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-77.382, test=-103.061) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-77.441, test=-102.486) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-84.537, test=-97.042) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-84.456, test=-97.506) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-83.938, test=-98.271) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-84.241, test=-98.080) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-84.379, test=-97.461) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-89.036, test=-94.028) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-88.961, test=-94.123) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-88.561, test=-94.490) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-88.687, test=-94.840) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-88.962, test=-94.107) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-90.814, test=-92.867) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-90.839, test=-93.135) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-90.491, test=-94.118) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-90.593, test=-93.891) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-90.746, test=-93.626) total time=   0.2s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.035, test=-196.271) total time=   0.5s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.101, test=-198.324) total time=   0.5s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.101, test=-200.070) total time=   0.5s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-202.371) total time=   0.5s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.376, test=-200.603) total time=   0.5s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-117.713, test=-153.544) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-117.738, test=-155.355) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-117.646, test=-156.205) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-117.320, test=-156.766) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-118.201, test=-152.523) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-127.896, test=-146.099) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-127.718, test=-148.913) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-127.599, test=-148.226) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-127.278, test=-149.216) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-128.595, test=-143.980) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-134.790, test=-142.021) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-134.588, test=-143.672) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-134.629, test=-143.399) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-133.876, test=-145.114) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-135.022, test=-140.138) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-137.766, test=-140.445) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-137.325, test=-142.247) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-137.171, test=-141.798) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-136.664, test=-144.477) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-137.983, test=-139.150) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.035, test=-196.060) total time=   0.5s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.101, test=-199.289) total time=   0.5s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.101, test=-200.769) total time=   0.5s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-201.914) total time=   0.5s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.376, test=-200.589) total time=   0.5s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-117.715, test=-153.554) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-117.769, test=-155.438) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-117.647, test=-156.301) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-117.305, test=-156.694) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-118.201, test=-152.479) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-127.896, test=-146.083) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-127.718, test=-148.913) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-127.599, test=-148.226) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-127.278, test=-149.205) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-128.595, test=-143.980) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-134.790, test=-142.041) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-134.588, test=-143.672) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-134.629, test=-143.399) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-133.876, test=-145.114) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-135.022, test=-140.138) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-137.766, test=-140.445) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-137.325, test=-142.247) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-137.171, test=-141.798) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-136.664, test=-144.477) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-137.983, test=-139.150) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.035, test=-196.655) total time=   0.5s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.101, test=-199.283) total time=   0.5s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.101, test=-199.800) total time=   0.4s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-201.215) total time=   0.4s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.376, test=-200.372) total time=   0.5s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-117.713, test=-153.585) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-117.769, test=-155.399) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-117.646, test=-156.274) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-117.318, test=-156.726) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-118.201, test=-152.533) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-127.896, test=-146.083) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-127.718, test=-148.913) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-127.599, test=-148.247) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-127.278, test=-149.209) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-128.595, test=-143.980) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-134.790, test=-142.041) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-134.588, test=-143.672) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-134.629, test=-143.399) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-133.876, test=-145.114) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-135.022, test=-140.138) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-137.766, test=-140.445) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-137.325, test=-142.247) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-137.171, test=-141.798) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-136.664, test=-144.477) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-137.983, test=-139.150) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.035, test=-195.518) total time=   0.5s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.101, test=-200.136) total time=   0.5s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.101, test=-198.834) total time=   0.4s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-201.832) total time=   0.4s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.376, test=-201.035) total time=   0.4s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-117.715, test=-153.530) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-117.738, test=-155.283) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-117.646, test=-156.241) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-117.320, test=-156.716) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-118.201, test=-152.541) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-127.896, test=-146.099) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-127.718, test=-148.913) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-127.596, test=-148.282) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-127.278, test=-149.209) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-128.595, test=-143.980) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-134.790, test=-142.041) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-134.588, test=-143.667) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-134.629, test=-143.399) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-133.876, test=-145.105) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-135.022, test=-140.117) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-137.766, test=-140.445) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-137.325, test=-142.247) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-137.171, test=-141.798) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-136.664, test=-144.477) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-137.983, test=-139.150) total time=   0.2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.ranking()\n",
        "model.predict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "59hTOzUXtKPK",
        "outputId": "61f528c2-18b1-491d-ee32-b81a7626b050"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chave NU_NOTA_CN estava vazia, vamos colocar o algoritmo ElasticNet\n",
            "Chave NU_NOTA_CH estava vazia, vamos colocar o algoritmo ElasticNet\n",
            "Chave NU_NOTA_LC estava vazia, vamos colocar o algoritmo ElasticNet\n",
            "Chave NU_NOTA_MT estava vazia, vamos colocar o algoritmo ElasticNet\n",
            "Chave NU_NOTA_REDACAO estava vazia, vamos colocar o algoritmo ElasticNet\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-a2407289d6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-8c19054a84de>\u001b[0m in \u001b[0;36mranking\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selecteds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgoritmo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-8c19054a84de>\u001b[0m in \u001b[0;36m_to_json\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ranking.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m       \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ranking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute '_ranking'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model._results"
      ],
      "metadata": {
        "id": "PsSQ7CidpHYD",
        "outputId": "34d88623-4929-4dad-f8d5-d4774666c89f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DecisionTree': {'NU_NOTA_CH': {'best_params': {'max_depth': 70,\n",
              "    'min_samples_leaf': 100},\n",
              "   'best_score': -71.36979527895173},\n",
              "  'NU_NOTA_CN': {'best_params': {'max_depth': 100, 'min_samples_leaf': 100},\n",
              "   'best_score': -66.06008092254851},\n",
              "  'NU_NOTA_LC': {'best_params': {'max_depth': 100, 'min_samples_leaf': 100},\n",
              "   'best_score': -54.38656482726235},\n",
              "  'NU_NOTA_MT': {'best_params': {'max_depth': 100, 'min_samples_leaf': 100},\n",
              "   'best_score': -93.01160204110991},\n",
              "  'NU_NOTA_REDACAO': {'best_params': {'max_depth': 90,\n",
              "    'min_samples_leaf': 100},\n",
              "   'best_score': -140.58504289884291}},\n",
              " 'ElasticNet': {'NU_NOTA_CH': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -69.47536198096927},\n",
              "  'NU_NOTA_CN': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -64.47326888352583},\n",
              "  'NU_NOTA_LC': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -52.89958269748065},\n",
              "  'NU_NOTA_MT': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -90.19288974586475},\n",
              "  'NU_NOTA_REDACAO': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -136.10150095423154}}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dtnvOzngsrSF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ML-Entrega2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}