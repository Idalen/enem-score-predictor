{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Idalen/enem-score-predictor/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmKTip2JOeEd"
      },
      "source": [
        "# Trabalho De ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LcGn6s_bOawi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "\n",
        "import plotly.express as px\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error as RMSE\n",
        "\n",
        "from pathlib import Path\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faX4OUlFbSNi"
      },
      "source": [
        "# Redução do uso da memória"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMpx4whrjNr1"
      },
      "source": [
        "Devido ao consumo de memória do nosso dataset, decidimos aplicar algumas estratégias para a redução do uso pelo Pandas.\n",
        "Primeiro, mudamos o tipo de dado utilizado pelas colunas para formatos que ocupam menos bytes e transformamos o arquivo para o formato *.parquet, que tem melhor suporte à compressão de dados. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLDhQx3AtAWF"
      },
      "outputs": [],
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ1FqdNpjSwM"
      },
      "source": [
        "# Leitura dos arquivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHNyqFcOOdJz",
        "outputId": "4c79dcc2-f45a-4377-fa75-6e9664051fe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content//drive\n"
          ]
        }
      ],
      "source": [
        "path = Path(\"/content/drive/MyDrive/datasets/dados-enem/\")\n",
        "drive.mount('/content//drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Stj3HCcV5Od"
      },
      "source": [
        "## Anotações:\n",
        "* Testar: se vale a pena eliminar quem está ausente plotando o gráfico pra ver a nota desse grupo de pessoas\n",
        "* Como fazer a conexão do jupyther com o SSH\n",
        "* https://python.plainenglish.io/how-to-create-a-interative-map-using-plotly-express-geojson-to-brazil-in-python-fb5527ae38fc\n",
        "\n",
        "## 1) Tratar dados\n",
        "* EDA Inicial\n",
        "* Tratar nulos (lembre-se de discutir e avaliar as melhores estratégias)\n",
        "* Mapear os valores e OneHotEncoding \n",
        "\n",
        "## 2) Preprocessamento\n",
        "* Remover colunas (correlacionadas [>80%], baixa variância, semântica)\n",
        "* (Opcional) Aplicar PCA \n",
        "* (Opcional) Feature Engineering\n",
        "* Standardize/Normalize\n",
        "* Tratar dados desbalanceados\n",
        "\n",
        "## 3) Modelo\n",
        "* Regressão linear<br>\n",
        "a. Realizar análise dos pesos<br>\n",
        "b. Aplicar técnicas de regularização<br> \n",
        "\n",
        "* Árvore de Decisão <br>\n",
        "a. Profundidade <br>\n",
        "b. Avaliar os cortes (impureza de gini / entropia) <br>\n",
        "\n",
        "* Naive Bayes <br>\n",
        "a. Quais features afetam significativamente P(nota|feature)<br>\n",
        "b. GaussianNaiveBayes x BernoulliNaiveBayes<br>\n",
        "\n",
        "* SVM<br>\n",
        "a. Avaliar o hiperplano gerado/ onde o corte é realizado <br>\n",
        "b. avaliar diferentes kernels <br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "\n",
        "\n",
        "  _algorithms = {\n",
        "      \n",
        "      'ElasticNet': {\n",
        "          'estimator':ElasticNet(),\n",
        "          'parameters':{\n",
        "              'alpha':[0.001, 0.5, 1.0],\n",
        "              'l1_ratio': [0, 0.5, 1.0]\n",
        "          }},\n",
        "\n",
        "      'DecisionTree': {\n",
        "          'estimator':DecisionTreeRegressor(),\n",
        "          'parameters':{\n",
        "              'max_depth':[100, 90, 80, 70],\n",
        "              'min_samples_leaf':[1, 10, 20, 50, 100]\n",
        "          }},\n",
        "\n",
        "      # 'RandomForest': {\n",
        "      #     'estimator':RandomForestRegressor(),\n",
        "      #     'parameters':{\n",
        "      #         'n_estimators':[11, 31, 51],\n",
        "      #         'max_depth':[100, 90, 80,],\n",
        "      #         'min_samples_leaf':[1, 20, 100],\n",
        "      #     }},\n",
        "\n",
        "      # 'KNN': {\n",
        "      #     'estimator':KNeighborsRegressor(),\n",
        "      #     'parameters':{\n",
        "      #         'n_neighbors':[5, 23, 47, 83],\n",
        "      #         'weights':['uniform', 'distance'],\n",
        "      #         'p':[1, 1.5, 2]\n",
        "      #     }},\n",
        "\n",
        "      # 'SVM': {\n",
        "      #     'estimator':SVR(),\n",
        "      #     'parameters':{\n",
        "      #         'kernel':['rbf', 'poly'],\n",
        "      #         'gamma':[0.01, 0.5, 1.0],\n",
        "      #         'C':[10, 100, 1000]\n",
        "      #     }}\n",
        "\n",
        "  }\n",
        "\n",
        "  def __init__(self, verbose=True):\n",
        "    pass\n",
        "\n",
        "  def load(self, path, verbose=True):\n",
        "\n",
        "    self.train_df = pd.read_parquet(path/'train.parquet').sample(40000)\n",
        "    self.test_df = pd.read_parquet(path/'test.parquet').sample(10000)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Quantidade inicial de elementos no treino:\", len(self.train_df))\n",
        "      print(\"Quantidade inicial de elementos no teste:\", len(self.test_df))\n",
        "        \n",
        "    self.train_df.set_index(\"NU_INSCRICAO\", inplace=True)\n",
        "    self.test_df.set_index(\"NU_INSCRICAO\", inplace=True)\n",
        "\n",
        "    self._targets = [col for col in self.train_df.columns if \"NU_NOTA\" in col]\n",
        "\n",
        "\n",
        "\n",
        "  def prepare(self,verbose=True):\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Mapeando valores...\")    \n",
        "    self._map_values(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Criando novas colunas...\")\n",
        "    self._create_features(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Eliminando colunas...\")\n",
        "    self._clear_cols(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Aplicando get dummies...\")\n",
        "    self._create_dummies(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Selecionando features mais importantes\")\n",
        "    self._feature_selection(verbose)\n",
        "\n",
        "\n",
        "  def tune(self, random_state=0, verbose=True):\n",
        "\n",
        "\n",
        "    X, Y = self.train_df.drop(columns=self._targets), self.train_df[self._targets] \n",
        "\n",
        "    self._results = {}\n",
        "\n",
        "    gscv = None\n",
        "\n",
        "    for name, algorithm in self._algorithms.items():\n",
        "      if verbose:\n",
        "        print(name)\n",
        "\n",
        "      self._results[name] = {} \n",
        "\n",
        "      for target in self._targets:\n",
        "        \n",
        "        gscv = GridSearchCV(algorithm['estimator'], algorithm['parameters'], verbose = 3,\n",
        "                             scoring='neg_root_mean_squared_error', return_train_score=True)\n",
        "        gscv.fit(X, Y[target])\n",
        "\n",
        "        self._results[name][target] = {}\n",
        "        self._results[name][target]['best_params'] = gscv.best_params_\n",
        "        self._results[name][target]['best_score'] = gscv.best_score_\n",
        "  \n",
        "    return gscv\n",
        "\n",
        "  def to_json(self):\n",
        "\n",
        "    with open('data.json', 'w') as fp:\n",
        "      json.dump(self._results, fp)\n",
        "\n",
        "  def ranking(self, verbose=True):\n",
        "\n",
        "    selecteds = {}\n",
        "\n",
        "    for name in self._results:\n",
        "\n",
        "      for target in self._targets:\n",
        "\n",
        "        if target in selecteds:\n",
        "          if self._results[name][target]['best_score'] > self._results[selecteds[target]][target]['best_score']:\n",
        "            selecteds[target] = self._results[name][target]['best_score'] \n",
        "          # Se a nota vista for > que a que está no dicionário\n",
        "          # atribui\n",
        "        else:\n",
        "          selecteds[target] = self._results[name][target]['best_score']\n",
        "\n",
        "\n",
        "  # def predict(self):\n",
        "\n",
        "  def correlation(self, save=False, plot=True):\n",
        "    \n",
        "    fig = px.imshow(self.train_df.corr())\n",
        "    \n",
        "    if plot:\n",
        "      fig.show()\n",
        "\n",
        "    if save:\n",
        "      pass\n",
        "\n",
        "\n",
        "  def plot(self, column):\n",
        "    \n",
        "    tmp = self.train_df[column].value_counts()\n",
        "    fig = px.bar(x=tmp.index, y=tmp.values)\n",
        "    fig.show()\n",
        "    \n",
        "    melted = pd.melt(self.train_df, id_vars=[column], value_vars=self._targets, var_name='TP_NOTA', value_name='NU_NOTA')\n",
        "    fig=px.box(melted.sample(1000000), x='TP_NOTA', y='NU_NOTA', color=column)\n",
        "    fig.show()\n",
        "\n",
        "  def null_analysis(self, plot=True, save=False, verbose=True):\n",
        "    \n",
        "    null_count = self.train_df.isna().apply(np.sum, axis=0)/self.train_df.shape[0]\n",
        "    null_percentage_train = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "    fig_train = px.bar(x=null_percentage_train.index, y=null_percentage_train.values, title=\"Porcentagem de valores nulos nos dados de treino\")\n",
        "\n",
        "    null_count = self.test_df.isna().apply(np.sum, axis=0)/self.test_df.shape[0]\n",
        "    null_percentage_test = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "    fig_test = px.bar(x=null_percentage_test.index, y=null_percentage_test.values, title=\"Porcentagem de valores nulos nos dados de teste\")\n",
        "\n",
        "    if plot:\n",
        "      fig_train.show()\n",
        "      fig_test.show()\n",
        "\n",
        "    if save:\n",
        "      pass\n",
        "\n",
        "  def _feature_selection(self, verbose):\n",
        "    \n",
        "    to_drop = []\n",
        "    treshold = 0.05\n",
        "    for col in self.train_df.columns[1:]:\n",
        "       if self.train_df[col].std() < treshold:\n",
        "         to_drop.append(col)\n",
        "    \n",
        "    self.train_df.drop(columns=to_drop, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop, inplace=True)\n",
        "    if verbose:\n",
        "      print(\"[VARIANCE TRESHOLD] Removendo colunas:\", to_drop)\n",
        "\n",
        "    #################################################################################\n",
        "\n",
        "    correlation = self.train_df.corr().abs()\n",
        "\n",
        "    upper_triangle = correlation.where(np.triu(np.ones(correlation.shape), k=1).astype(bool))\n",
        "\n",
        "    # Considera apenas colunas de correlação mínima de 0.85\n",
        "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\n",
        "    \n",
        "    self.train_df.drop(columns=to_drop, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print('[HIGH CORRELATION] Eliminando colunas redundantes:', to_drop)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def _clear_cols(self, verbose):\n",
        "    \n",
        "    null_count = self.train_df.isna().apply(np.sum, axis=0)/self.train_df.shape[0]\n",
        "    null_percentage_train = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "\n",
        "    null_count = self.test_df.isna().apply(np.sum, axis=0)/self.test_df.shape[0]\n",
        "    null_percentage_test = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "\n",
        "    to_drop_columns_train = list(null_percentage_train[null_percentage_train > 30].index)\n",
        "    to_drop_columns_test = list(null_percentage_test[null_percentage_test > 30].index)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"[NULLS] Colunas dropadas no treino:\", sorted(to_drop_columns_train))\n",
        "      print(\"[NULLS] Colunas dropadas no teste:\", sorted(to_drop_columns_test))\n",
        "\n",
        "    self.train_df.drop(columns=to_drop_columns_train, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop_columns_test, inplace=True)\n",
        "\n",
        "    ###################################################################################################################\n",
        "\n",
        "    to_drop = ['CO_MUNICIPIO_RESIDENCIA', 'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'CO_MUNICIPIO_NASCIMENTO', 'NO_MUNICIPIO_NASCIMENTO',\n",
        "    'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO', 'TP_ANO_CONCLUIU', 'IN_TREINEIRO', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA',\n",
        "    'SG_UF_PROVA']\n",
        "\n",
        "    self.train_df.drop(columns=to_drop, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print(f'[DROP COLUMNS] Colunas retiradas por falta de relevânica:{[to_drop]}')\n",
        "\n",
        "    ##################################################################################################################\n",
        "\n",
        "    to_drop = self.train_df[(self.train_df['TP_STATUS_REDACAO'].isna()) & (self.train_df['TP_PRESENCA_CH']=='Presente')].index\n",
        "    self.train_df.drop(to_drop, inplace=True)\n",
        "\n",
        "    to_drop = self.test_df[(self.test_df['TP_STATUS_REDACAO'].isna()) & (self.test_df['TP_PRESENCA_CH']=='Presente')].index\n",
        "    self.test_df.drop(to_drop, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print(f'[INCONSISTENCY] Removendo inconsistências.')\n",
        "\n",
        "    ##################################################################################################################\n",
        "    \n",
        "\n",
        "    to_drop = ['NU_NOTA_MT', 'NU_NOTA_CH', 'NU_NOTA_CN', 'NU_NOTA_LC', 'NU_NOTA_REDACAO', 'TP_STATUS_REDACAO']\n",
        "    self.train_df.dropna(subset=to_drop, inplace=True)\n",
        "\n",
        "    try:\n",
        "      self.test_df.dropna(subset=to_drop, inplace=True)\n",
        "    except KeyError:\n",
        "      pass #\n",
        "\n",
        "    if verbose:\n",
        "      print('[NULL TARGETS] Removendo valores nulos nas colunas-alvo')\n",
        "\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    self.train_df.drop(self.train_df[self.train_df['TP_STATUS_REDACAO'] != 'Sem problemas'].index, inplace=True)\n",
        "    self.test_df.drop(self.test_df[self.test_df['TP_STATUS_REDACAO'] != 'Sem problemas'].index, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print('[::] Removendo redações que tiraram nota 0')\n",
        "\n",
        "\n",
        "  def _create_dummies(self, verbose):\n",
        "\n",
        "    cols = [col for col in self.train_df.columns if ((self.train_df[col].dtype == 'object') or (self.train_df[col].dtype.name == 'category'))]\n",
        "\n",
        "    self.train_df = pd.get_dummies(self.train_df, columns=cols)\n",
        "    self.test_df = pd.get_dummies(self.test_df, columns=cols)\n",
        "\n",
        "    if verbose:\n",
        "      print(f\"[GET DUMMIES] Colunas categóricas convertidas: {cols}\")\n",
        "\n",
        "\n",
        "  def _create_features(self, verbose):\n",
        "\n",
        "    new_columns = []\n",
        "    filled_columns = []\n",
        "    ############################################################################################\n",
        "\n",
        "    uf_regiao = {\n",
        "      'RR':'Norte', 'AP':'Norte', 'AM':'Norte', 'PA':'Norte', 'AC':'Norte', 'RO':'Norte', 'TO':'Norte', 'MA':'Nordeste',\n",
        "      'PI':'Nordeste', 'CE':'Nordeste', 'RN':'Nordeste', 'PB':'Nordeste', 'PE':'Nordeste', 'AL':'Nordeste', 'SE':'Nordeste',\n",
        "      'BA':'Nordeste', 'MT':'Centro-oeste', 'DF':'Centro-oeste', 'GO':'Centro-oeste', 'MS':'Centro-oeste', 'MG':'Sudeste',\n",
        "      'ES':'Sudeste', 'RJ':'Sudeste', 'SP':'Sudeste', 'PR':'Sul', 'SC':'Sul', 'RS':'Sul', \n",
        "      }\n",
        "\n",
        "    self.train_df['NO_REGIAO_RESIDENCIA'] = self.train_df['SG_UF_RESIDENCIA'].map(uf_regiao)\n",
        "    self.test_df['NO_REGIAO_RESIDENCIA'] = self.test_df['SG_UF_RESIDENCIA'].map(uf_regiao)\n",
        "\n",
        "    new_columns.append('NO_REGIAO_RESIDENCIA')\n",
        "\n",
        "    ############################################################################################\n",
        "\n",
        "    mean_score_per_reg = self.train_df.groupby(\"NO_REGIAO_RESIDENCIA\")[self._targets].mean()\n",
        "    for col in self._targets:\n",
        "      self.train_df[\"REG_NOTA_\"+col.split(\"_\")[2]+\"_MEDIA\"] = self.train_df['NO_REGIAO_RESIDENCIA'].apply(\n",
        "          lambda row: mean_score_per_reg[col][row]) \n",
        "      self.test_df[\"REG_NOTA_\"+col.split(\"_\")[2]+\"_MEDIA\"] = self.test_df['NO_REGIAO_RESIDENCIA'].apply(\n",
        "          lambda row: mean_score_per_reg[col][row]) \n",
        "\n",
        "      new_columns.append(\"REG_NOTA_\"+col.split(\"_\")[2]+\"_MEDIA\")\n",
        "    ############################################################################################\n",
        "  \n",
        "    \n",
        "    self.train_df['TP_MINORIA_RACIAL'] = ((self.train_df['TP_COR_RACA'] != 'Branca').astype(int) + (self.train_df['TP_COR_RACA'] != 'Amarela').astype(int)) -1\n",
        "    self.test_df['TP_MINORIA_RACIAL'] = ((self.test_df['TP_COR_RACA'] != 'Branca').astype(int) + (self.test_df['TP_COR_RACA'] != 'Amarela').astype(int)) -1\n",
        "\n",
        "    new_columns.append('TP_MINORIA_RACIAL')\n",
        "    ############################################################################################\n",
        "\n",
        "    cols = [col for col in self.train_df.columns if ((\"IN_\" in col) and ('TREINEIRO' not in col))]\n",
        "\n",
        "    self.train_df['TP_SITUACAO_ESPECIAL'] = self.train_df[cols].any(axis=1)\n",
        "    self.test_df['TP_SITUACAO_ESPECIAL'] = self.test_df[cols].any(axis=1)\n",
        "\n",
        "    new_columns.append('TP_SITUACAO_ESPECIAL')\n",
        "\n",
        "    #############################################################################################\n",
        "\n",
        "\n",
        "    self.train_df['TP_SOLTEIRO'] = self.train_df['TP_ESTADO_CIVIL'] == 'Solteiro(a)'\n",
        "    self.test_df['TP_SOLTEIRO'] = self.test_df['TP_ESTADO_CIVIL'] == 'Solteiro(a)'\n",
        "\n",
        "    new_columns.append('TP_SOLTEIRO')\n",
        "\n",
        "    #############################################################################################\n",
        "\n",
        "    median_train = self.train_df.loc[self.train_df['NU_IDADE'].notnull(), 'NU_IDADE'].median()\n",
        "    \n",
        "    self.train_df['NU_IDADE'] = self.train_df['NU_IDADE'].fillna(median_train)\n",
        "    self.test_df['NU_IDADE'] = self.test_df['NU_IDADE'].fillna(median_train)\n",
        "  \n",
        "    filled_columns.append(\"NU_IDADE\")\n",
        "    #############################################################################################\n",
        "\n",
        "    if verbose:\n",
        "      print(f'[FEATURE ENGINEERING] Novas colunas: {new_columns}')\n",
        "      print(f'[INPUTATION] Colunas com valores nulos preenchidos: {filled_columns}')\n",
        "      \n",
        "\n",
        "\n",
        "  \n",
        "  def _map_values(self, verbose):\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"Solteiro(a)\",\n",
        "      2:\"Casado(a)/Mora com companheiro(a)\",\n",
        "      3:\"Divorciado(a)/Desquitado(a)/Separado(a)\",\n",
        "      4:\"Viúvo(a)\"}\n",
        "\n",
        "    self.train_df['TP_ESTADO_CIVIL'] = self.train_df['TP_ESTADO_CIVIL'].map(rename)\n",
        "    self.test_df['TP_ESTADO_CIVIL'] = self.test_df['TP_ESTADO_CIVIL'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"Branca\",\n",
        "      2:\"Preta\",\n",
        "      3:\"Parda\",\n",
        "      4:\"Amarela\",\n",
        "      5:\"Indígena\"}\n",
        "\n",
        "    self.train_df['TP_COR_RACA'] = self.train_df['TP_COR_RACA'].map(rename)\n",
        "    self.test_df['TP_COR_RACA'] = self.test_df['TP_COR_RACA'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"Brasileiro(a)\",\n",
        "      2:\"Brasileiro(a) Naturalizado(a)\",\n",
        "      3:\"Estrangeiro(a)\",\n",
        "      4:\"Brasileiro(a) Nato(a), nascido(a) no exterior\"\n",
        "      }\n",
        "\n",
        "    self.train_df['TP_NACIONALIDADE'] = self.train_df['TP_NACIONALIDADE'].map(rename)\n",
        "    self.test_df['TP_NACIONALIDADE'] = self.test_df['TP_NACIONALIDADE'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"Já concluí o Ensino Médio\",\n",
        "      2:\"Estou cursando e concluirei o Ensino Médio no ano corrente\",\n",
        "      3:\"Estou cursando e concluirei o Ensino Médio após o ano corrente\",\n",
        "      4:\"Não concluí e não estou cursando o Ensino Médio\"\n",
        "      }\n",
        "\n",
        "    self.train_df['TP_ST_CONCLUSAO'] = self.train_df['TP_ST_CONCLUSAO'].map(rename)\n",
        "    self.test_df['TP_ST_CONCLUSAO'] = self.test_df['TP_ST_CONCLUSAO'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"2018\",\n",
        "      2:\"2017\",\n",
        "      3:\"2016\",\n",
        "      4:\"2015\",\n",
        "      5:\"2014\",\n",
        "      6:\"2013\",\n",
        "      7:\"2012\",\n",
        "      8:\"2011\",\n",
        "      9:\"2010\",\n",
        "      10:\"2009\",\n",
        "      11:\"2008\",\n",
        "      12:\"2007\",\n",
        "      13:\"Antes de 2007\"}\n",
        "\n",
        "    self.train_df['TP_ANO_CONCLUIU'] = self.train_df['TP_ANO_CONCLUIU'].map(rename)\n",
        "    self.test_df['TP_ANO_CONCLUIU'] = self.test_df['TP_ANO_CONCLUIU'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"0\",#np.NaN,\n",
        "      2:\"Pública\",\n",
        "      3:\"Privada\",\n",
        "      4:\"Exterior\"}\n",
        "\n",
        "    self.train_df['TP_ESCOLA'] = self.train_df['TP_ESCOLA'].map(rename)\n",
        "    self.test_df['TP_ESCOLA'] = self.test_df['TP_ESCOLA'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"Federal\",\n",
        "      2:\"Estadual\",\n",
        "      3:\"Municipal\",\n",
        "      4:\"Privada\"}\n",
        "\n",
        "    self.train_df['TP_DEPENDENCIA_ADM_ESC'] = self.train_df['TP_DEPENDENCIA_ADM_ESC'].map(rename)\n",
        "    self.test_df['TP_DEPENDENCIA_ADM_ESC'] = self.test_df['TP_DEPENDENCIA_ADM_ESC'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"Ensino Regular\",\n",
        "      2:\"Educação Especial - Modalidade Substitutiva\",\n",
        "      3:\"Educação de Jovens e Adultos\"}\n",
        "\n",
        "    self.train_df['TP_ENSINO'] = self.train_df['TP_ENSINO'].map(rename)\n",
        "    self.test_df['TP_ENSINO'] = self.test_df['TP_ENSINO'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"Ausente\",\n",
        "      1:\"Presente\",\n",
        "      2:\"Eliminado\"}\n",
        "\n",
        "    for c in [col for col in self.train_df.columns if \"TP_PRESENCA\" in col]:\n",
        "      self.train_df[c] = self.train_df[c].map(rename)\n",
        "      self.test_df[c] = self.test_df[c].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        1:\"Sem problemas\",\n",
        "        2:\"Anulada\",\n",
        "        3:\"Copiou texto motivador\",\n",
        "        4:\"Em branco\",\n",
        "        6:\"Fuga ao tema\",\n",
        "        7:\"Não atende tipo textual\",\n",
        "        8:\"Texto insuficiente\",\n",
        "        9:\"Parte desconectada\"\n",
        "      }\n",
        "\n",
        "    self.train_df['TP_STATUS_REDACAO'] = self.train_df['TP_STATUS_REDACAO'].map(rename)\n",
        "    self.test_df['TP_STATUS_REDACAO'] = self.test_df['TP_STATUS_REDACAO'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':6,\n",
        "        'G':7,\n",
        "        'H':0\n",
        "    }\n",
        "\n",
        "    self.train_df['Q001'] = self.train_df['Q001'].map(rename).astype(int)\n",
        "    self.test_df['Q001'] = self.test_df['Q001'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':6,\n",
        "        'G':7,\n",
        "        'H':0\n",
        "    }\n",
        "\n",
        "    self.train_df['Q002'] = self.train_df['Q002'].map(rename).astype(int)\n",
        "    self.test_df['Q002'] = self.test_df['Q002'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':0,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q003'] = self.train_df['Q003'].map(rename).astype(int)\n",
        "    self.test_df['Q003'] = self.test_df['Q003'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':0,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q004'] = self.train_df['Q004'].map(rename).astype(int)\n",
        "    self.test_df['Q004'] = self.test_df['Q004'].map(rename).astype(int)\n",
        "\n",
        "    #Q005 já é numérica\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':6,\n",
        "        'G':7,\n",
        "        'H':8,\n",
        "        'I':9,\n",
        "        'J':10,\n",
        "        'K':11,\n",
        "        'L':12,\n",
        "        'M':13,\n",
        "        'N':14,\n",
        "        'O':15,\n",
        "        'P':16,\n",
        "        'Q':17\n",
        "    }\n",
        "\n",
        "    self.train_df['Q006'] = self.train_df['Q006'].map(rename).astype(int)\n",
        "    self.test_df['Q006'] = self.test_df['Q006'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q007'] = self.train_df['Q007'].map(rename).astype(int)\n",
        "    self.test_df['Q007'] = self.test_df['Q007'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q008'] = self.train_df['Q008'].map(rename).astype(int)\n",
        "    self.test_df['Q008'] = self.test_df['Q008'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q009'] = self.train_df['Q009'].map(rename).astype(int)\n",
        "    self.test_df['Q009'] = self.test_df['Q009'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q010'] = self.train_df['Q010'].map(rename).astype(int)\n",
        "    self.test_df['Q010'] = self.test_df['Q010'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q011'] = self.train_df['Q011'].map(rename).astype(int)\n",
        "    self.test_df['Q011'] = self.test_df['Q011'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q012'] = self.train_df['Q012'].map(rename).astype(int)\n",
        "    self.test_df['Q012'] = self.test_df['Q012'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q013'] = self.train_df['Q013'].map(rename).astype(int)\n",
        "    self.test_df['Q013'] = self.test_df['Q013'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q014'] = self.train_df['Q014'].map(rename).astype(int)\n",
        "    self.test_df['Q014'] = self.test_df['Q014'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q015'] = self.train_df['Q015'].map(rename).astype(int)\n",
        "    self.test_df['Q015'] = self.test_df['Q015'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q016'] = self.train_df['Q016'].map(rename).astype(int)\n",
        "    self.test_df['Q016'] = self.test_df['Q016'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q017'] = self.train_df['Q017'].map(rename).astype(int)\n",
        "    self.test_df['Q017'] = self.test_df['Q017'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q018'] = self.train_df['Q018'].map(rename).astype(int)\n",
        "    self.test_df['Q018'] = self.test_df['Q018'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q019'] = self.train_df['Q019'].map(rename).astype(int)\n",
        "    self.test_df['Q019'] = self.test_df['Q019'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q020'] = self.train_df['Q020'].map(rename).astype(int)\n",
        "    self.test_df['Q020'] = self.test_df['Q020'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q021'] = self.train_df['Q021'].map(rename).astype(int)\n",
        "    self.test_df['Q021'] = self.test_df['Q021'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q022'] = self.train_df['Q022'].map(rename).astype(int)\n",
        "    self.test_df['Q022'] = self.test_df['Q022'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q023'] = self.train_df['Q023'].map(rename).astype(int)\n",
        "    self.test_df['Q023'] = self.test_df['Q023'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q024'] = self.train_df['Q024'].map(rename).astype(int)\n",
        "    self.test_df['Q024'] = self.test_df['Q024'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q025'] = self.train_df['Q025'].map(rename).astype(int)\n",
        "    self.test_df['Q025'] = self.test_df['Q025'].map(rename).astype(int)"
      ],
      "metadata": {
        "id": "monL-6iYH2lL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.load(path)"
      ],
      "metadata": {
        "id": "OdCHx9nx79Rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc04b08-3897-4d0b-c400-572aba72f685"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade inicial de elementos no treino: 40000\n",
            "Quantidade inicial de elementos no teste: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.prepare()"
      ],
      "metadata": {
        "id": "tRA3Key2O2af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42498c45-7579-4841-b2d8-c82beb3a7ed4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapeando valores...\n",
            "Criando novas colunas...\n",
            "[FEATURE ENGINEERING] Novas colunas: ['NO_REGIAO_RESIDENCIA', 'REG_NOTA_CN_MEDIA', 'REG_NOTA_CH_MEDIA', 'REG_NOTA_LC_MEDIA', 'REG_NOTA_MT_MEDIA', 'REG_NOTA_REDACAO_MEDIA', 'TP_MINORIA_RACIAL', 'TP_SITUACAO_ESPECIAL', 'TP_SOLTEIRO']\n",
            "[INPUTATION] Colunas com valores nulos preenchidos: ['NU_IDADE']\n",
            "Eliminando colunas...\n",
            "[NULLS] Colunas dropadas no treino: ['CO_ESCOLA', 'CO_MUNICIPIO_ESC', 'CO_UF_ESC', 'NO_MUNICIPIO_ESC', 'SG_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC']\n",
            "[NULLS] Colunas dropadas no teste: ['CO_ESCOLA', 'CO_MUNICIPIO_ESC', 'CO_UF_ESC', 'NO_MUNICIPIO_ESC', 'SG_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC']\n",
            "[DROP COLUMNS] Colunas retiradas por falta de relevânica:[['CO_MUNICIPIO_RESIDENCIA', 'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'CO_MUNICIPIO_NASCIMENTO', 'NO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO', 'TP_ANO_CONCLUIU', 'IN_TREINEIRO', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA']]\n",
            "[INCONSISTENCY] Removendo inconsistências.\n",
            "[NULL TARGETS] Removendo valores nulos nas colunas-alvo\n",
            "[::] Removendo redações que tiraram nota 0\n",
            "Aplicando get dummies...\n",
            "[GET DUMMIES] Colunas categóricas convertidas: ['SG_UF_RESIDENCIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ESCOLA', 'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT', 'TP_STATUS_REDACAO', 'NO_REGIAO_RESIDENCIA']\n",
            "Selecionando features mais importantes\n",
            "[VARIANCE TRESHOLD] Removendo colunas: ['IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_SURDEZ', 'IN_DEFICIENCIA_AUDITIVA', 'IN_SURDO_CEGUEIRA', 'IN_DEFICIENCIA_FISICA', 'IN_DEFICIENCIA_MENTAL', 'IN_DEFICIT_ATENCAO', 'IN_DISLEXIA', 'IN_DISCALCULIA', 'IN_AUTISMO', 'IN_VISAO_MONOCULAR', 'IN_OUTRA_DEF', 'IN_GESTANTE', 'IN_LACTANTE', 'IN_IDOSO', 'IN_ESTUDA_CLASSE_HOSPITALAR', 'IN_SEM_RECURSO', 'IN_BRAILLE', 'IN_AMPLIADA_24', 'IN_AMPLIADA_18', 'IN_LEDOR', 'IN_ACESSO', 'IN_TRANSCRICAO', 'IN_LIBRAS', 'IN_LEITURA_LABIAL', 'IN_MESA_CADEIRA_RODAS', 'IN_MESA_CADEIRA_SEPARADA', 'IN_APOIO_PERNA', 'IN_GUIA_INTERPRETE', 'IN_COMPUTADOR', 'IN_CADEIRA_ESPECIAL', 'IN_CADEIRA_CANHOTO', 'IN_CADEIRA_ACOLCHOADA', 'IN_PROVA_DEITADO', 'IN_MOBILIARIO_OBESO', 'IN_LAMINA_OVERLAY', 'IN_PROTETOR_AURICULAR', 'IN_MEDIDOR_GLICOSE', 'IN_MAQUINA_BRAILE', 'IN_SOROBAN', 'IN_MARCA_PASSO', 'IN_SONDA', 'IN_MEDICAMENTOS', 'IN_SALA_INDIVIDUAL', 'IN_SALA_ESPECIAL', 'IN_SALA_ACOMPANHANTE', 'IN_MOBILIARIO_ESPECIFICO', 'IN_MATERIAL_ESPECIFICO', 'IN_NOME_SOCIAL', 'SG_UF_RESIDENCIA_RR', 'TP_ESTADO_CIVIL_Viúvo(a)', 'TP_NACIONALIDADE_0', 'TP_NACIONALIDADE_Brasileiro(a) Nato(a), nascido(a) no exterior', 'TP_NACIONALIDADE_Estrangeiro(a)', 'TP_ST_CONCLUSAO_Não concluí e não estou cursando o Ensino Médio', 'TP_PRESENCA_CN_Presente', 'TP_PRESENCA_CH_Presente', 'TP_PRESENCA_LC_Presente', 'TP_PRESENCA_MT_Presente', 'TP_STATUS_REDACAO_Sem problemas']\n",
            "[HIGH CORRELATION] Eliminando colunas redundantes: ['REG_NOTA_CH_MEDIA', 'REG_NOTA_LC_MEDIA', 'REG_NOTA_MT_MEDIA', 'REG_NOTA_REDACAO_MEDIA', 'TP_SEXO_M', 'TP_ESTADO_CIVIL_Solteiro(a)', 'TP_COR_RACA_Branca', 'TP_NACIONALIDADE_Brasileiro(a) Naturalizado(a)', 'TP_ESCOLA_0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = model.tune()"
      ],
      "metadata": {
        "id": "cdr-0BdVPAbq",
        "outputId": "db525f15-3557-44a4-c184-b44b02083605",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ElasticNet\n",
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.779e+07, tolerance: 1.320e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.845, test=-64.429) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.759e+07, tolerance: 1.316e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.705, test=-65.003) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.770e+07, tolerance: 1.313e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.783, test=-64.706) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.753e+07, tolerance: 1.314e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.664, test=-65.142) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.748e+07, tolerance: 1.314e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.630, test=-65.314) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.002e+07, tolerance: 1.320e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.841, test=-64.429) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 1.316e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.701, test=-65.008) total time=   2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.050e+06, tolerance: 1.313e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.780, test=-64.706) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.791e+07, tolerance: 1.314e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.661, test=-65.141) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.803e+07, tolerance: 1.314e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.626, test=-65.313) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e+07, tolerance: 1.320e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.837, test=-64.430) total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.130e+07, tolerance: 1.316e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.695, test=-65.020) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.641e+07, tolerance: 1.313e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.775, test=-64.708) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+07, tolerance: 1.314e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.658, test=-65.138) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.959e+07, tolerance: 1.314e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.622, test=-65.313) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.061e+07, tolerance: 1.320e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-66.004, test=-65.586) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.046e+07, tolerance: 1.316e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.897, test=-66.004) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.057e+07, tolerance: 1.313e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.991, test=-65.712) total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.035e+07, tolerance: 1.314e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.833, test=-66.280) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.038e+07, tolerance: 1.314e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.834, test=-66.217) total time=   2.5s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.771, test=-65.372) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.669, test=-65.762) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.763, test=-65.448) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.599, test=-66.078) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.593, test=-66.019) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.310, test=-64.933) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.207, test=-65.257) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.290, test=-64.963) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.135, test=-65.633) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.109, test=-65.668) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.146e+07, tolerance: 1.320e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.440, test=-66.001) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.130e+07, tolerance: 1.316e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.337, test=-66.415) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.140e+07, tolerance: 1.313e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.425, test=-66.185) total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.119e+07, tolerance: 1.314e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.272, test=-66.705) total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.123e+07, tolerance: 1.314e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.285, test=-66.614) total time=   2.6s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-66.252, test=-65.824) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-66.157, test=-66.219) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-66.249, test=-65.964) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-66.083, test=-66.559) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-66.090, test=-66.449) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.658, test=-65.295) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.589, test=-65.601) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.650, test=-65.269) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.508, test=-66.042) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.481, test=-65.961) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.956e+07, tolerance: 1.644e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.455e+07, tolerance: 1.462e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.282, test=-69.466) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.443e+07, tolerance: 1.454e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.205, test=-69.778) total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.460e+07, tolerance: 1.454e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.312, test=-69.378) total time=   3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.459e+07, tolerance: 1.459e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.303, test=-69.390) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.458e+07, tolerance: 1.458e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.301, test=-69.446) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e+07, tolerance: 1.462e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.278, test=-69.469) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.648e+05, tolerance: 1.454e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.202, test=-69.779) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.528e+05, tolerance: 1.454e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.308, test=-69.379) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.558e+05, tolerance: 1.459e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.301, test=-69.392) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.992e+05, tolerance: 1.458e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.299, test=-69.446) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+07, tolerance: 1.462e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.272, test=-69.480) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+07, tolerance: 1.454e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.198, test=-69.779) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+07, tolerance: 1.454e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.302, test=-69.390) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.354e+07, tolerance: 1.459e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.298, test=-69.391) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+07, tolerance: 1.458e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.296, test=-69.442) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.733e+07, tolerance: 1.462e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.351, test=-70.297) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.715e+07, tolerance: 1.454e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.257, test=-70.752) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.734e+07, tolerance: 1.454e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.377, test=-70.288) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.734e+07, tolerance: 1.459e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.366, test=-70.275) total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.731e+07, tolerance: 1.458e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.355, test=-70.376) total time=   2.5s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.145, test=-70.116) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.054, test=-70.539) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.177, test=-70.057) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.161, test=-70.082) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.152, test=-70.195) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.761, test=-69.827) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.657, test=-70.127) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.781, test=-69.660) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.774, test=-69.686) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.754, test=-69.847) total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.817e+07, tolerance: 1.462e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-70.750, test=-70.641) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.797e+07, tolerance: 1.454e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-70.645, test=-71.140) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.816e+07, tolerance: 1.454e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-70.767, test=-70.691) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.817e+07, tolerance: 1.459e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-70.759, test=-70.637) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.813e+07, tolerance: 1.458e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-70.745, test=-70.758) total time=   2.4s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.574, test=-70.495) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.475, test=-70.953) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.603, test=-70.487) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.584, test=-70.474) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.566, test=-70.604) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.076, test=-70.144) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.014, test=-70.427) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.131, test=-69.975) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.116, test=-70.034) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.091, test=-70.181) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.823e+07, tolerance: 1.821e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.155e+07, tolerance: 8.686e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.684, test=-53.099) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.193e+07, tolerance: 8.762e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-53.000, test=-51.831) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.105e+07, tolerance: 8.571e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.260, test=-54.779) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.194e+07, tolerance: 8.767e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-53.007, test=-51.822) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.160e+07, tolerance: 8.716e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.730, test=-52.960) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+05, tolerance: 8.686e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.681, test=-53.103) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.706e+05, tolerance: 8.762e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.998, test=-51.831) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.957e+04, tolerance: 8.571e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.257, test=-54.785) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e+06, tolerance: 8.767e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-53.006, test=-51.824) total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.899e+05, tolerance: 8.716e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.729, test=-52.959) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.308e+06, tolerance: 8.686e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.677, test=-53.114) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.419e+06, tolerance: 8.762e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.994, test=-51.834) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e+07, tolerance: 8.571e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.253, test=-54.798) total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.509e+07, tolerance: 8.767e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-53.005, test=-51.824) total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.679e+04, tolerance: 8.716e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.727, test=-52.954) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.351e+07, tolerance: 8.686e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.683, test=-53.895) total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.384e+07, tolerance: 8.762e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.962, test=-52.821) total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.300e+07, tolerance: 8.571e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.279, test=-55.534) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.388e+07, tolerance: 8.767e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-54.001, test=-52.669) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.352e+07, tolerance: 8.716e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.706, test=-53.890) total time=   2.4s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.517, test=-53.744) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.805, test=-52.645) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.112, test=-55.379) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.844, test=-52.499) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.547, test=-53.741) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-53.177, test=-53.475) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-53.474, test=-52.272) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-52.768, test=-55.090) total time=   0.4s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-53.519, test=-52.163) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-53.227, test=-53.394) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.408e+07, tolerance: 8.686e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-54.067, test=-54.237) total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.440e+07, tolerance: 8.762e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-54.334, test=-53.195) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.356e+07, tolerance: 8.571e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-53.661, test=-55.900) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.445e+07, tolerance: 8.767e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-54.374, test=-53.043) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.408e+07, tolerance: 8.716e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-54.077, test=-54.256) total time=   2.5s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.947, test=-54.124) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-54.221, test=-53.062) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.543, test=-55.780) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-54.260, test=-52.927) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.961, test=-54.163) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.490, test=-53.745) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.800, test=-52.579) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.089, test=-55.393) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.820, test=-52.460) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.540, test=-53.747) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.954e+07, tolerance: 1.088e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.247e+07, tolerance: 2.729e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-90.196, test=-88.788) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.177e+07, tolerance: 2.711e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-89.849, test=-90.205) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.144e+07, tolerance: 2.699e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-89.689, test=-90.859) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.147e+07, tolerance: 2.704e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-89.706, test=-90.764) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.179e+07, tolerance: 2.709e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-89.861, test=-90.225) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.947e+07, tolerance: 2.729e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-90.193, test=-88.792) total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.883e+07, tolerance: 2.711e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-89.845, test=-90.210) total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.722e+07, tolerance: 2.699e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-89.687, test=-90.858) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.071e+07, tolerance: 2.704e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-89.702, test=-90.767) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.833e+07, tolerance: 2.709e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-89.858, test=-90.222) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.116e+07, tolerance: 2.729e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-90.190, test=-88.799) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.371e+07, tolerance: 2.711e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-89.841, test=-90.223) total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.340e+07, tolerance: 2.699e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-89.684, test=-90.856) total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.726e+07, tolerance: 2.704e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-89.698, test=-90.778) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.254e+07, tolerance: 2.709e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-89.856, test=-90.220) total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.921e+07, tolerance: 2.729e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-92.240, test=-90.599) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.857e+07, tolerance: 2.711e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-91.913, test=-91.836) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.821e+07, tolerance: 2.699e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-91.758, test=-92.546) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.808e+07, tolerance: 2.704e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-91.707, test=-92.800) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.843e+07, tolerance: 2.709e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-91.871, test=-92.150) total time=   2.6s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-91.728, test=-90.058) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-91.391, test=-91.349) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-91.231, test=-92.058) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-91.199, test=-92.295) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-91.354, test=-91.660) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-90.696, test=-89.091) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-90.374, test=-90.472) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-90.184, test=-91.222) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-90.237, test=-91.225) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-90.363, test=-90.724) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+08, tolerance: 2.729e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-92.969, test=-91.317) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+08, tolerance: 2.711e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-92.658, test=-92.503) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+08, tolerance: 2.699e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-92.497, test=-93.269) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.997e+07, tolerance: 2.704e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-92.434, test=-93.514) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+08, tolerance: 2.709e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-92.604, test=-92.889) total time=   2.4s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-92.530, test=-90.845) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-92.207, test=-92.086) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-92.041, test=-92.822) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-91.987, test=-93.083) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-92.152, test=-92.456) total time=   0.4s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-91.171, test=-89.408) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-90.852, test=-90.830) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-90.672, test=-91.617) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-90.719, test=-91.814) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-90.856, test=-91.278) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+08, tolerance: 3.388e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+08, tolerance: 5.488e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-135.775, test=-136.457) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.105e+08, tolerance: 5.481e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-136.060, test=-135.262) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.094e+08, tolerance: 5.479e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-135.713, test=-136.727) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+08, tolerance: 5.491e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-135.785, test=-136.356) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e+08, tolerance: 5.474e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-135.746, test=-136.593) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+08, tolerance: 5.488e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-135.766, test=-136.451) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+08, tolerance: 5.481e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-136.049, test=-135.270) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.006e+08, tolerance: 5.479e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-135.705, test=-136.741) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e+08, tolerance: 5.491e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-135.776, test=-136.361) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.987e+08, tolerance: 5.474e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-135.738, test=-136.588) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.344e+08, tolerance: 5.488e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-135.755, test=-136.459) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.350e+08, tolerance: 5.481e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-136.039, test=-135.297) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.764e+07, tolerance: 5.479e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-135.696, test=-136.761) total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.465e+08, tolerance: 5.491e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-135.768, test=-136.375) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.618e+07, tolerance: 5.474e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-135.731, test=-136.580) total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.245e+08, tolerance: 5.488e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-139.139, test=-139.381) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.249e+08, tolerance: 5.481e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-139.338, test=-138.867) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+08, tolerance: 5.479e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-139.228, test=-139.141) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.248e+08, tolerance: 5.491e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-139.246, test=-139.016) total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.240e+08, tolerance: 5.474e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-139.042, test=-140.141) total time=   2.5s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-138.329, test=-138.706) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-138.586, test=-138.028) total time=   0.3s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-138.420, test=-138.376) total time=   0.3s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-138.441, test=-138.308) total time=   0.3s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-138.284, test=-139.321) total time=   0.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-136.344, test=-137.030) total time=   0.3s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-136.679, test=-135.742) total time=   0.4s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-136.327, test=-136.801) total time=   0.4s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-136.421, test=-136.618) total time=   0.4s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-136.358, test=-137.168) total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.277e+08, tolerance: 5.488e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-140.114, test=-140.208) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.281e+08, tolerance: 5.481e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-140.258, test=-139.829) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.279e+08, tolerance: 5.479e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-140.188, test=-140.068) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+08, tolerance: 5.491e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-140.213, test=-139.893) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.270e+08, tolerance: 5.474e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-139.956, test=-141.127) total time=   2.5s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-139.470, test=-139.659) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-139.667, test=-139.195) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-139.569, test=-139.436) total time=   0.3s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-139.580, test=-139.332) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-139.366, test=-140.518) total time=   0.3s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-136.955, test=-137.531) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-137.317, test=-136.420) total time=   0.3s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-137.024, test=-137.249) total time=   0.4s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-137.091, test=-137.184) total time=   0.3s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-137.012, test=-137.957) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.623e+08, tolerance: 6.853e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to_json()"
      ],
      "metadata": {
        "id": "0RTKQh_sGT1d",
        "outputId": "b3aa1752-9c12-438b-bfdb-6e87f6af779f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ElasticNet': {'NU_NOTA_CN': {'best_params': {'alpha': 0.001, 'l1_ratio': 0}, 'best_score': -64.91882274435655}, 'NU_NOTA_CH': {'best_params': {'alpha': 0.001, 'l1_ratio': 0}, 'best_score': -69.49150686115085}, 'NU_NOTA_LC': {'best_params': {'alpha': 0.001, 'l1_ratio': 0}, 'best_score': -52.89826607389468}, 'NU_NOTA_MT': {'best_params': {'alpha': 0.001, 'l1_ratio': 0}, 'best_score': -90.16801902070017}, 'NU_NOTA_REDACAO': {'best_params': {'alpha': 0.001, 'l1_ratio': 0}, 'best_score': -136.27887211821962}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model._results"
      ],
      "metadata": {
        "id": "PsSQ7CidpHYD",
        "outputId": "22a357ce-3328-47e5-8800-35efbdaff496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DecisionTree': {'NU_NOTA_CH': {'best_params': {'max_depth': 100,\n",
              "    'min_samples_leaf': 100},\n",
              "   'best_score': -71.08253881261814},\n",
              "  'NU_NOTA_CN': {'best_params': {'max_depth': 100, 'min_samples_leaf': 100},\n",
              "   'best_score': -65.99895521648882},\n",
              "  'NU_NOTA_LC': {'best_params': {'max_depth': 100, 'min_samples_leaf': 100},\n",
              "   'best_score': -53.9850017077484},\n",
              "  'NU_NOTA_MT': {'best_params': {'max_depth': 90, 'min_samples_leaf': 100},\n",
              "   'best_score': -91.47403800860884},\n",
              "  'NU_NOTA_REDACAO': {'best_params': {'max_depth': 100,\n",
              "    'min_samples_leaf': 100},\n",
              "   'best_score': -139.43192844405368}},\n",
              " 'ElasticNet': {'NU_NOTA_CH': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -69.52599774588066},\n",
              "  'NU_NOTA_CN': {'best_params': {'alpha': 0.001, 'l1_ratio': 0.5},\n",
              "   'best_score': -64.54731145502434},\n",
              "  'NU_NOTA_LC': {'best_params': {'alpha': 0.001, 'l1_ratio': 0.5},\n",
              "   'best_score': -52.51027994884307},\n",
              "  'NU_NOTA_MT': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -88.67783724185077},\n",
              "  'NU_NOTA_REDACAO': {'best_params': {'alpha': 0.001, 'l1_ratio': 0.5},\n",
              "   'best_score': -135.14015106817183}}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dtnvOzngsrSF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ML-Entrega2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}