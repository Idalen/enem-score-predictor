{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Idalen/enem-score-predictor/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmKTip2JOeEd"
      },
      "source": [
        "# Trabalho De ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LcGn6s_bOawi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import plotly.express as px\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error as RMSE\n",
        "\n",
        "from pathlib import Path\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faX4OUlFbSNi"
      },
      "source": [
        "# Redução do uso da memória"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMpx4whrjNr1"
      },
      "source": [
        "Devido ao consumo de memória do nosso dataset, decidimos aplicar algumas estratégias para a redução do uso pelo Pandas.\n",
        "Primeiro, mudamos o tipo de dado utilizado pelas colunas para formatos que ocupam menos bytes e transformamos o arquivo para o formato *.parquet, que tem melhor suporte à compressão de dados. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dLDhQx3AtAWF"
      },
      "outputs": [],
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ1FqdNpjSwM"
      },
      "source": [
        "# Leitura dos arquivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHNyqFcOOdJz",
        "outputId": "1c71646c-9744-4474-c154-27c5f4deede4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content//drive; to attempt to forcibly remount, call drive.mount(\"/content//drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "path = Path(\"/content/drive/MyDrive/datasets/dados-enem/\")\n",
        "drive.mount('/content//drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Stj3HCcV5Od"
      },
      "source": [
        "## Anotações:\n",
        "* Testar: se vale a pena eliminar quem está ausente plotando o gráfico pra ver a nota desse grupo de pessoas\n",
        "* Como fazer a conexão do jupyther com o SSH\n",
        "* https://python.plainenglish.io/how-to-create-a-interative-map-using-plotly-express-geojson-to-brazil-in-python-fb5527ae38fc\n",
        "\n",
        "## 1) Tratar dados\n",
        "* EDA Inicial\n",
        "* Tratar nulos (lembre-se de discutir e avaliar as melhores estratégias)\n",
        "* Mapear os valores e OneHotEncoding \n",
        "\n",
        "## 2) Preprocessamento\n",
        "* Remover colunas (correlacionadas [>80%], baixa variância, semântica)\n",
        "* (Opcional) Aplicar PCA \n",
        "* (Opcional) Feature Engineering\n",
        "* Standardize/Normalize\n",
        "* Tratar dados desbalanceados\n",
        "\n",
        "## 3) Modelo\n",
        "* Regressão linear<br>\n",
        "a. Realizar análise dos pesos<br>\n",
        "b. Aplicar técnicas de regularização<br> \n",
        "\n",
        "* Árvore de Decisão <br>\n",
        "a. Profundidade <br>\n",
        "b. Avaliar os cortes (impureza de gini / entropia) <br>\n",
        "\n",
        "* Naive Bayes <br>\n",
        "a. Quais features afetam significativamente P(nota|feature)<br>\n",
        "b. GaussianNaiveBayes x BernoulliNaiveBayes<br>\n",
        "\n",
        "* SVM<br>\n",
        "a. Avaliar o hiperplano gerado/ onde o corte é realizado <br>\n",
        "b. avaliar diferentes kernels <br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "\n",
        "\n",
        "  _algorithms = {\n",
        "      \n",
        "      'ElasticNet': {\n",
        "          'estimator':ElasticNet(),\n",
        "          'parameters':{\n",
        "              'alpha':[0.001, 0.5, 1.0],\n",
        "              'l1_ratio': [0, 0.5, 1.0]\n",
        "          }},\n",
        "\n",
        "      'DecisionTree': {\n",
        "          'estimator':DecisionTreeRegressor(),\n",
        "          'parameters':{\n",
        "              'max_depth':[100, 90, 80, 70],\n",
        "              'min_samples_leaf':[1, 10, 20, 50, 100]\n",
        "          }},\n",
        "\n",
        "      # 'RandomForest': {\n",
        "      #     'estimator':RandomForestRegressor(),\n",
        "      #     'parameters':{\n",
        "      #         'n_estimators':[11, 31, 51],\n",
        "      #         'max_depth':[100, 90, 80,],\n",
        "      #         'min_samples_leaf':[1, 20, 100],\n",
        "      #     }},\n",
        "\n",
        "      # 'KNN': {\n",
        "      #     'estimator':KNeighborsRegressor(),\n",
        "      #     'parameters':{\n",
        "      #         'n_neighbors':[5, 23, 47, 83],\n",
        "      #         'weights':['uniform', 'distance'],\n",
        "      #         'p':[1, 1.5, 2]\n",
        "      #     }},\n",
        "\n",
        "      # 'SVM': {\n",
        "      #     'estimator':SVR(),\n",
        "      #     'parameters':{\n",
        "      #         'kernel':['rbf', 'poly'],\n",
        "      #         'gamma':[0.01, 0.5, 1.0],\n",
        "      #         'C':[10, 100, 1000]\n",
        "      #     }}\n",
        "\n",
        "  }\n",
        "\n",
        "  def __init__(self, verbose=True):\n",
        "    pass\n",
        "\n",
        "  def load(self, path, verbose=True):\n",
        "\n",
        "    self.train_df = pd.read_parquet(path/'train.parquet').sample(40000)\n",
        "    self.test_df = pd.read_parquet(path/'test.parquet').sample(10000)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Quantidade inicial de elementos no treino:\", len(self.train_df))\n",
        "      print(\"Quantidade inicial de elementos no teste:\", len(self.test_df))\n",
        "        \n",
        "    self.train_df.set_index(\"NU_INSCRICAO\", inplace=True)\n",
        "    self.test_df.set_index(\"NU_INSCRICAO\", inplace=True)\n",
        "\n",
        "    self._targets = [col for col in self.train_df.columns if \"NU_NOTA\" in col]\n",
        "\n",
        "\n",
        "\n",
        "  def prepare(self,verbose=True):\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Mapeando valores...\")    \n",
        "    self._map_values(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Criando novas colunas...\")\n",
        "    self._create_features(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Eliminando colunas...\")\n",
        "    self._clear_cols(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Aplicando get dummies...\")\n",
        "    self._create_dummies(verbose)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Selecionando features mais importantes\")\n",
        "    self._feature_selection(verbose)\n",
        "\n",
        "  def tune(self, random_state=0, verbose=True):\n",
        "\n",
        "\n",
        "    X, Y = self.train_df.drop(columns=self._targets), self.train_df[self._targets] \n",
        "\n",
        "    self._results = {}\n",
        "\n",
        "    gscv = None\n",
        "\n",
        "    for name, algorithm in self._algorithms.items():\n",
        "      if verbose:\n",
        "        print(name)\n",
        "\n",
        "      self._results[name] = {} \n",
        "\n",
        "      for target in self._targets:\n",
        "        \n",
        "        gscv = GridSearchCV(algorithm['estimator'], algorithm['parameters'], verbose = 3,\n",
        "                             scoring='neg_root_mean_squared_error', return_train_score=True)\n",
        "        gscv.fit(X, Y[target])\n",
        "\n",
        "        self._results[name][target] = {}\n",
        "        self._results[name][target]['best_params'] = gscv.best_params_\n",
        "        self._results[name][target]['best_score'] = gscv.best_score_\n",
        "  \n",
        "    return gscv\n",
        "\n",
        "  def predict(self, model=''):\n",
        "\n",
        "    for\n",
        "\n",
        "\n",
        "\n",
        "  def correlation(self, save=False, plot=True):\n",
        "    \n",
        "    fig = px.imshow(self.train_df.corr())\n",
        "    \n",
        "    if plot:\n",
        "      fig.show()\n",
        "\n",
        "    if save:\n",
        "      pass\n",
        "\n",
        "\n",
        "  def plot(self, column):\n",
        "    \n",
        "    tmp = self.train_df[column].value_counts()\n",
        "    fig = px.bar(x=tmp.index, y=tmp.values)\n",
        "    fig.show()\n",
        "    \n",
        "    melted = pd.melt(self.train_df, id_vars=[column], value_vars=self._targets, var_name='TP_NOTA', value_name='NU_NOTA')\n",
        "    fig=px.box(melted.sample(1000000), x='TP_NOTA', y='NU_NOTA', color=column)\n",
        "    fig.show()\n",
        "\n",
        "  def null_analysis(self, plot=True, save=False, verbose=True):\n",
        "    \n",
        "    null_count = self.train_df.isna().apply(np.sum, axis=0)/self.train_df.shape[0]\n",
        "    null_percentage_train = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "    fig_train = px.bar(x=null_percentage_train.index, y=null_percentage_train.values, title=\"Porcentagem de valores nulos nos dados de treino\")\n",
        "\n",
        "    null_count = self.test_df.isna().apply(np.sum, axis=0)/self.test_df.shape[0]\n",
        "    null_percentage_test = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "    fig_test = px.bar(x=null_percentage_test.index, y=null_percentage_test.values, title=\"Porcentagem de valores nulos nos dados de teste\")\n",
        "\n",
        "    if plot:\n",
        "      fig_train.show()\n",
        "      fig_test.show()\n",
        "\n",
        "    if save:\n",
        "      pass\n",
        "\n",
        "  def _feature_selection(self, verbose):\n",
        "    \n",
        "    to_drop = []\n",
        "    treshold = 0.05\n",
        "    for col in self.train_df.columns[1:]:\n",
        "       if self.train_df[col].std() < treshold:\n",
        "         to_drop.append(col)\n",
        "    \n",
        "    self.train_df.drop(columns=to_drop, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop, inplace=True)\n",
        "    if verbose:\n",
        "      print(\"[VARIANCE TRESHOLD] Removendo colunas:\", to_drop)\n",
        "\n",
        "    #################################################################################\n",
        "\n",
        "    correlation = self.train_df.corr().abs()\n",
        "\n",
        "    upper_triangle = correlation.where(np.triu(np.ones(correlation.shape), k=1).astype(bool))\n",
        "\n",
        "    # Considera apenas colunas de correlação mínima de 0.85\n",
        "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\n",
        "    \n",
        "    self.train_df.drop(columns=to_drop, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print('[HIGH CORRELATION] Eliminando colunas redundantes:', to_drop)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def _clear_cols(self, verbose):\n",
        "    \n",
        "    null_count = self.train_df.isna().apply(np.sum, axis=0)/self.train_df.shape[0]\n",
        "    null_percentage_train = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "\n",
        "    null_count = self.test_df.isna().apply(np.sum, axis=0)/self.test_df.shape[0]\n",
        "    null_percentage_test = (null_count.loc[null_count!=0]*100).sort_values()\n",
        "\n",
        "    to_drop_columns_train = list(null_percentage_train[null_percentage_train > 30].index)\n",
        "    to_drop_columns_test = list(null_percentage_test[null_percentage_test > 30].index)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"[NULLS] Colunas dropadas no treino:\", sorted(to_drop_columns_train))\n",
        "      print(\"[NULLS] Colunas dropadas no teste:\", sorted(to_drop_columns_test))\n",
        "\n",
        "    self.train_df.drop(columns=to_drop_columns_train, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop_columns_test, inplace=True)\n",
        "\n",
        "    ###################################################################################################################\n",
        "\n",
        "    to_drop = ['CO_MUNICIPIO_RESIDENCIA', 'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'CO_MUNICIPIO_NASCIMENTO', 'NO_MUNICIPIO_NASCIMENTO',\n",
        "    'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO', 'TP_ANO_CONCLUIU', 'IN_TREINEIRO', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA',\n",
        "    'SG_UF_PROVA']\n",
        "\n",
        "    self.train_df.drop(columns=to_drop, inplace=True)\n",
        "    self.test_df.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print(f'[DROP COLUMNS] Colunas retiradas por falta de relevânica:{[to_drop]}')\n",
        "\n",
        "    ##################################################################################################################\n",
        "\n",
        "    to_drop = self.train_df[(self.train_df['TP_STATUS_REDACAO'].isna()) & (self.train_df['TP_PRESENCA_CH']=='Presente')].index\n",
        "    self.train_df.drop(to_drop, inplace=True)\n",
        "\n",
        "    to_drop = self.test_df[(self.test_df['TP_STATUS_REDACAO'].isna()) & (self.test_df['TP_PRESENCA_CH']=='Presente')].index\n",
        "    self.test_df.drop(to_drop, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print(f'[INCONSISTENCY] Removendo inconsistências.')\n",
        "\n",
        "    ##################################################################################################################\n",
        "    \n",
        "\n",
        "    to_drop = ['NU_NOTA_MT', 'NU_NOTA_CH', 'NU_NOTA_CN', 'NU_NOTA_LC', 'NU_NOTA_REDACAO', 'TP_STATUS_REDACAO']\n",
        "    self.train_df.dropna(subset=to_drop, inplace=True)\n",
        "\n",
        "    try:\n",
        "      self.test_df.dropna(subset=to_drop, inplace=True)\n",
        "    except KeyError:\n",
        "      pass #\n",
        "\n",
        "    if verbose:\n",
        "      print('[NULL TARGETS] Removendo valores nulos nas colunas-alvo')\n",
        "\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    self.train_df.drop(self.train_df[self.train_df['TP_STATUS_REDACAO'] != 'Sem problemas'].index, inplace=True)\n",
        "    self.test_df.drop(self.test_df[self.test_df['TP_STATUS_REDACAO'] != 'Sem problemas'].index, inplace=True)\n",
        "\n",
        "    if verbose:\n",
        "      print('[::] Removendo redações que tiraram nota 0')\n",
        "\n",
        "\n",
        "  def _create_dummies(self, verbose):\n",
        "\n",
        "    cols = [col for col in self.train_df.columns if ((self.train_df[col].dtype == 'object') or (self.train_df[col].dtype.name == 'category'))]\n",
        "\n",
        "    self.train_df = pd.get_dummies(self.train_df, columns=cols)\n",
        "    self.test_df = pd.get_dummies(self.test_df, columns=cols)\n",
        "\n",
        "    if verbose:\n",
        "      print(f\"[GET DUMMIES] Colunas categóricas convertidas: {cols}\")\n",
        "\n",
        "\n",
        "  def _create_features(self, verbose):\n",
        "\n",
        "    new_columns = []\n",
        "    filled_columns = []\n",
        "    ############################################################################################\n",
        "\n",
        "    uf_regiao = {\n",
        "      'RR':'Norte', 'AP':'Norte', 'AM':'Norte', 'PA':'Norte', 'AC':'Norte', 'RO':'Norte', 'TO':'Norte', 'MA':'Nordeste',\n",
        "      'PI':'Nordeste', 'CE':'Nordeste', 'RN':'Nordeste', 'PB':'Nordeste', 'PE':'Nordeste', 'AL':'Nordeste', 'SE':'Nordeste',\n",
        "      'BA':'Nordeste', 'MT':'Centro-oeste', 'DF':'Centro-oeste', 'GO':'Centro-oeste', 'MS':'Centro-oeste', 'MG':'Sudeste',\n",
        "      'ES':'Sudeste', 'RJ':'Sudeste', 'SP':'Sudeste', 'PR':'Sul', 'SC':'Sul', 'RS':'Sul', \n",
        "      }\n",
        "\n",
        "    self.train_df['NO_REGIAO_RESIDENCIA'] = self.train_df['SG_UF_RESIDENCIA'].map(uf_regiao)\n",
        "    self.test_df['NO_REGIAO_RESIDENCIA'] = self.test_df['SG_UF_RESIDENCIA'].map(uf_regiao)\n",
        "\n",
        "    new_columns.append('NO_REGIAO_RESIDENCIA')\n",
        "\n",
        "    ############################################################################################\n",
        "\n",
        "    mean_score_per_reg = self.train_df.groupby(\"NO_REGIAO_RESIDENCIA\")[self._targets].mean()\n",
        "    for col in self._targets:\n",
        "      self.train_df[\"REG_NOTA_\"+col.split(\"_\")[2]+\"_MEDIA\"] = self.train_df['NO_REGIAO_RESIDENCIA'].apply(\n",
        "          lambda row: mean_score_per_reg[col][row]) \n",
        "      self.test_df[\"REG_NOTA_\"+col.split(\"_\")[2]+\"_MEDIA\"] = self.test_df['NO_REGIAO_RESIDENCIA'].apply(\n",
        "          lambda row: mean_score_per_reg[col][row]) \n",
        "\n",
        "      new_columns.append(\"REG_NOTA_\"+col.split(\"_\")[2]+\"_MEDIA\")\n",
        "    ############################################################################################\n",
        "  \n",
        "    \n",
        "    self.train_df['TP_MINORIA_RACIAL'] = ((self.train_df['TP_COR_RACA'] != 'Branca').astype(int) + (self.train_df['TP_COR_RACA'] != 'Amarela').astype(int)) -1\n",
        "    self.test_df['TP_MINORIA_RACIAL'] = ((self.test_df['TP_COR_RACA'] != 'Branca').astype(int) + (self.test_df['TP_COR_RACA'] != 'Amarela').astype(int)) -1\n",
        "\n",
        "    new_columns.append('TP_MINORIA_RACIAL')\n",
        "    ############################################################################################\n",
        "\n",
        "    cols = [col for col in self.train_df.columns if ((\"IN_\" in col) and ('TREINEIRO' not in col))]\n",
        "\n",
        "    self.train_df['TP_SITUACAO_ESPECIAL'] = self.train_df[cols].any(axis=1)\n",
        "    self.test_df['TP_SITUACAO_ESPECIAL'] = self.test_df[cols].any(axis=1)\n",
        "\n",
        "    new_columns.append('TP_SITUACAO_ESPECIAL')\n",
        "\n",
        "    #############################################################################################\n",
        "\n",
        "\n",
        "    self.train_df['TP_SOLTEIRO'] = self.train_df['TP_ESTADO_CIVIL'] == 'Solteiro(a)'\n",
        "    self.test_df['TP_SOLTEIRO'] = self.test_df['TP_ESTADO_CIVIL'] == 'Solteiro(a)'\n",
        "\n",
        "    new_columns.append('TP_SOLTEIRO')\n",
        "\n",
        "    #############################################################################################\n",
        "\n",
        "    median_train = self.train_df.loc[self.train_df['NU_IDADE'].notnull(), 'NU_IDADE'].median()\n",
        "    \n",
        "    self.train_df['NU_IDADE'] = self.train_df['NU_IDADE'].fillna(median_train)\n",
        "    self.test_df['NU_IDADE'] = self.test_df['NU_IDADE'].fillna(median_train)\n",
        "  \n",
        "    filled_columns.append(\"NU_IDADE\")\n",
        "    #############################################################################################\n",
        "\n",
        "    if verbose:\n",
        "      print(f'[FEATURE ENGINEERING] Novas colunas: {new_columns}')\n",
        "      print(f'[INPUTATION] Colunas com valores nulos preenchidos: {filled_columns}')\n",
        "      \n",
        "\n",
        "\n",
        "  \n",
        "  def _map_values(self, verbose):\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"Solteiro(a)\",\n",
        "      2:\"Casado(a)/Mora com companheiro(a)\",\n",
        "      3:\"Divorciado(a)/Desquitado(a)/Separado(a)\",\n",
        "      4:\"Viúvo(a)\"}\n",
        "\n",
        "    self.train_df['TP_ESTADO_CIVIL'] = self.train_df['TP_ESTADO_CIVIL'].map(rename)\n",
        "    self.test_df['TP_ESTADO_CIVIL'] = self.test_df['TP_ESTADO_CIVIL'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"Branca\",\n",
        "      2:\"Preta\",\n",
        "      3:\"Parda\",\n",
        "      4:\"Amarela\",\n",
        "      5:\"Indígena\"}\n",
        "\n",
        "    self.train_df['TP_COR_RACA'] = self.train_df['TP_COR_RACA'].map(rename)\n",
        "    self.test_df['TP_COR_RACA'] = self.test_df['TP_COR_RACA'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"Brasileiro(a)\",\n",
        "      2:\"Brasileiro(a) Naturalizado(a)\",\n",
        "      3:\"Estrangeiro(a)\",\n",
        "      4:\"Brasileiro(a) Nato(a), nascido(a) no exterior\"\n",
        "      }\n",
        "\n",
        "    self.train_df['TP_NACIONALIDADE'] = self.train_df['TP_NACIONALIDADE'].map(rename)\n",
        "    self.test_df['TP_NACIONALIDADE'] = self.test_df['TP_NACIONALIDADE'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"Já concluí o Ensino Médio\",\n",
        "      2:\"Estou cursando e concluirei o Ensino Médio no ano corrente\",\n",
        "      3:\"Estou cursando e concluirei o Ensino Médio após o ano corrente\",\n",
        "      4:\"Não concluí e não estou cursando o Ensino Médio\"\n",
        "      }\n",
        "\n",
        "    self.train_df['TP_ST_CONCLUSAO'] = self.train_df['TP_ST_CONCLUSAO'].map(rename)\n",
        "    self.test_df['TP_ST_CONCLUSAO'] = self.test_df['TP_ST_CONCLUSAO'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"0\",#np.NaN,\n",
        "      1:\"2018\",\n",
        "      2:\"2017\",\n",
        "      3:\"2016\",\n",
        "      4:\"2015\",\n",
        "      5:\"2014\",\n",
        "      6:\"2013\",\n",
        "      7:\"2012\",\n",
        "      8:\"2011\",\n",
        "      9:\"2010\",\n",
        "      10:\"2009\",\n",
        "      11:\"2008\",\n",
        "      12:\"2007\",\n",
        "      13:\"Antes de 2007\"}\n",
        "\n",
        "    self.train_df['TP_ANO_CONCLUIU'] = self.train_df['TP_ANO_CONCLUIU'].map(rename)\n",
        "    self.test_df['TP_ANO_CONCLUIU'] = self.test_df['TP_ANO_CONCLUIU'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"0\",#np.NaN,\n",
        "      2:\"Pública\",\n",
        "      3:\"Privada\",\n",
        "      4:\"Exterior\"}\n",
        "\n",
        "    self.train_df['TP_ESCOLA'] = self.train_df['TP_ESCOLA'].map(rename)\n",
        "    self.test_df['TP_ESCOLA'] = self.test_df['TP_ESCOLA'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"Federal\",\n",
        "      2:\"Estadual\",\n",
        "      3:\"Municipal\",\n",
        "      4:\"Privada\"}\n",
        "\n",
        "    self.train_df['TP_DEPENDENCIA_ADM_ESC'] = self.train_df['TP_DEPENDENCIA_ADM_ESC'].map(rename)\n",
        "    self.test_df['TP_DEPENDENCIA_ADM_ESC'] = self.test_df['TP_DEPENDENCIA_ADM_ESC'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {1:\"Ensino Regular\",\n",
        "      2:\"Educação Especial - Modalidade Substitutiva\",\n",
        "      3:\"Educação de Jovens e Adultos\"}\n",
        "\n",
        "    self.train_df['TP_ENSINO'] = self.train_df['TP_ENSINO'].map(rename)\n",
        "    self.test_df['TP_ENSINO'] = self.test_df['TP_ENSINO'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {0:\"Ausente\",\n",
        "      1:\"Presente\",\n",
        "      2:\"Eliminado\"}\n",
        "\n",
        "    for c in [col for col in self.train_df.columns if \"TP_PRESENCA\" in col]:\n",
        "      self.train_df[c] = self.train_df[c].map(rename)\n",
        "      self.test_df[c] = self.test_df[c].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        1:\"Sem problemas\",\n",
        "        2:\"Anulada\",\n",
        "        3:\"Copiou texto motivador\",\n",
        "        4:\"Em branco\",\n",
        "        6:\"Fuga ao tema\",\n",
        "        7:\"Não atende tipo textual\",\n",
        "        8:\"Texto insuficiente\",\n",
        "        9:\"Parte desconectada\"\n",
        "      }\n",
        "\n",
        "    self.train_df['TP_STATUS_REDACAO'] = self.train_df['TP_STATUS_REDACAO'].map(rename)\n",
        "    self.test_df['TP_STATUS_REDACAO'] = self.test_df['TP_STATUS_REDACAO'].map(rename)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':6,\n",
        "        'G':7,\n",
        "        'H':0\n",
        "    }\n",
        "\n",
        "    self.train_df['Q001'] = self.train_df['Q001'].map(rename).astype(int)\n",
        "    self.test_df['Q001'] = self.test_df['Q001'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':6,\n",
        "        'G':7,\n",
        "        'H':0\n",
        "    }\n",
        "\n",
        "    self.train_df['Q002'] = self.train_df['Q002'].map(rename).astype(int)\n",
        "    self.test_df['Q002'] = self.test_df['Q002'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':0,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q003'] = self.train_df['Q003'].map(rename).astype(int)\n",
        "    self.test_df['Q003'] = self.test_df['Q003'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':0,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q004'] = self.train_df['Q004'].map(rename).astype(int)\n",
        "    self.test_df['Q004'] = self.test_df['Q004'].map(rename).astype(int)\n",
        "\n",
        "    #Q005 já é numérica\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5,\n",
        "        'F':6,\n",
        "        'G':7,\n",
        "        'H':8,\n",
        "        'I':9,\n",
        "        'J':10,\n",
        "        'K':11,\n",
        "        'L':12,\n",
        "        'M':13,\n",
        "        'N':14,\n",
        "        'O':15,\n",
        "        'P':16,\n",
        "        'Q':17\n",
        "    }\n",
        "\n",
        "    self.train_df['Q006'] = self.train_df['Q006'].map(rename).astype(int)\n",
        "    self.test_df['Q006'] = self.test_df['Q006'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q007'] = self.train_df['Q007'].map(rename).astype(int)\n",
        "    self.test_df['Q007'] = self.test_df['Q007'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q008'] = self.train_df['Q008'].map(rename).astype(int)\n",
        "    self.test_df['Q008'] = self.test_df['Q008'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q009'] = self.train_df['Q009'].map(rename).astype(int)\n",
        "    self.test_df['Q009'] = self.test_df['Q009'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q010'] = self.train_df['Q010'].map(rename).astype(int)\n",
        "    self.test_df['Q010'] = self.test_df['Q010'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q011'] = self.train_df['Q011'].map(rename).astype(int)\n",
        "    self.test_df['Q011'] = self.test_df['Q011'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q012'] = self.train_df['Q012'].map(rename).astype(int)\n",
        "    self.test_df['Q012'] = self.test_df['Q012'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q013'] = self.train_df['Q013'].map(rename).astype(int)\n",
        "    self.test_df['Q013'] = self.test_df['Q013'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q014'] = self.train_df['Q014'].map(rename).astype(int)\n",
        "    self.test_df['Q014'] = self.test_df['Q014'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q015'] = self.train_df['Q015'].map(rename).astype(int)\n",
        "    self.test_df['Q015'] = self.test_df['Q015'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q016'] = self.train_df['Q016'].map(rename).astype(int)\n",
        "    self.test_df['Q016'] = self.test_df['Q016'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q017'] = self.train_df['Q017'].map(rename).astype(int)\n",
        "    self.test_df['Q017'] = self.test_df['Q017'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q018'] = self.train_df['Q018'].map(rename).astype(int)\n",
        "    self.test_df['Q018'] = self.test_df['Q018'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q019'] = self.train_df['Q019'].map(rename).astype(int)\n",
        "    self.test_df['Q019'] = self.test_df['Q019'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q020'] = self.train_df['Q020'].map(rename).astype(int)\n",
        "    self.test_df['Q020'] = self.test_df['Q020'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q021'] = self.train_df['Q021'].map(rename).astype(int)\n",
        "    self.test_df['Q021'] = self.test_df['Q021'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q022'] = self.train_df['Q022'].map(rename).astype(int)\n",
        "    self.test_df['Q022'] = self.test_df['Q022'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q023'] = self.train_df['Q023'].map(rename).astype(int)\n",
        "    self.test_df['Q023'] = self.test_df['Q023'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':1,\n",
        "        'B':2,\n",
        "        'C':3,\n",
        "        'D':4,\n",
        "        'E':5\n",
        "    }\n",
        "\n",
        "    self.train_df['Q024'] = self.train_df['Q024'].map(rename).astype(int)\n",
        "    self.test_df['Q024'] = self.test_df['Q024'].map(rename).astype(int)\n",
        "\n",
        "    #################################################################\n",
        "    rename = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "    }\n",
        "\n",
        "    self.train_df['Q025'] = self.train_df['Q025'].map(rename).astype(int)\n",
        "    self.test_df['Q025'] = self.test_df['Q025'].map(rename).astype(int)"
      ],
      "metadata": {
        "id": "monL-6iYH2lL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.load(path)"
      ],
      "metadata": {
        "id": "OdCHx9nx79Rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12bb4008-52c4-443f-a1de-6df7acfe2b1c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade inicial de elementos no treino: 40000\n",
            "Quantidade inicial de elementos no teste: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.prepare()"
      ],
      "metadata": {
        "id": "tRA3Key2O2af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5640d0fd-b60c-491b-e0d9-bb461d5bd90d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapeando valores...\n",
            "Criando novas colunas...\n",
            "[FEATURE ENGINEERING] Novas colunas: ['NO_REGIAO_RESIDENCIA', 'REG_NOTA_CN_MEDIA', 'REG_NOTA_CH_MEDIA', 'REG_NOTA_LC_MEDIA', 'REG_NOTA_MT_MEDIA', 'REG_NOTA_REDACAO_MEDIA', 'TP_MINORIA_RACIAL', 'TP_SITUACAO_ESPECIAL', 'TP_SOLTEIRO']\n",
            "[INPUTATION] Colunas com valores nulos preenchidos: ['NU_IDADE']\n",
            "Eliminando colunas...\n",
            "[NULLS] Colunas dropadas no treino: ['CO_ESCOLA', 'CO_MUNICIPIO_ESC', 'CO_UF_ESC', 'NO_MUNICIPIO_ESC', 'SG_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC']\n",
            "[NULLS] Colunas dropadas no teste: ['CO_ESCOLA', 'CO_MUNICIPIO_ESC', 'CO_UF_ESC', 'NO_MUNICIPIO_ESC', 'SG_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC']\n",
            "[DROP COLUMNS] Colunas retiradas por falta de relevânica:[['CO_MUNICIPIO_RESIDENCIA', 'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'CO_MUNICIPIO_NASCIMENTO', 'NO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO', 'TP_ANO_CONCLUIU', 'IN_TREINEIRO', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA']]\n",
            "[INCONSISTENCY] Removendo inconsistências.\n",
            "[NULL TARGETS] Removendo valores nulos nas colunas-alvo\n",
            "[::] Removendo redações que tiraram nota 0\n",
            "Aplicando get dummies...\n",
            "[GET DUMMIES] Colunas categóricas convertidas: ['SG_UF_RESIDENCIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ESCOLA', 'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT', 'TP_STATUS_REDACAO', 'NO_REGIAO_RESIDENCIA']\n",
            "Selecionando features mais importantes\n",
            "[VARIANCE TRESHOLD] Removendo colunas: ['IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_SURDEZ', 'IN_DEFICIENCIA_AUDITIVA', 'IN_SURDO_CEGUEIRA', 'IN_DEFICIENCIA_FISICA', 'IN_DEFICIENCIA_MENTAL', 'IN_DEFICIT_ATENCAO', 'IN_DISLEXIA', 'IN_DISCALCULIA', 'IN_AUTISMO', 'IN_VISAO_MONOCULAR', 'IN_OUTRA_DEF', 'IN_GESTANTE', 'IN_LACTANTE', 'IN_IDOSO', 'IN_ESTUDA_CLASSE_HOSPITALAR', 'IN_SEM_RECURSO', 'IN_BRAILLE', 'IN_AMPLIADA_24', 'IN_AMPLIADA_18', 'IN_LEDOR', 'IN_ACESSO', 'IN_TRANSCRICAO', 'IN_LIBRAS', 'IN_TEMPO_ADICIONAL', 'IN_LEITURA_LABIAL', 'IN_MESA_CADEIRA_RODAS', 'IN_MESA_CADEIRA_SEPARADA', 'IN_APOIO_PERNA', 'IN_GUIA_INTERPRETE', 'IN_COMPUTADOR', 'IN_CADEIRA_ESPECIAL', 'IN_CADEIRA_CANHOTO', 'IN_CADEIRA_ACOLCHOADA', 'IN_PROVA_DEITADO', 'IN_MOBILIARIO_OBESO', 'IN_LAMINA_OVERLAY', 'IN_PROTETOR_AURICULAR', 'IN_MEDIDOR_GLICOSE', 'IN_MAQUINA_BRAILE', 'IN_SOROBAN', 'IN_MARCA_PASSO', 'IN_SONDA', 'IN_MEDICAMENTOS', 'IN_SALA_INDIVIDUAL', 'IN_SALA_ESPECIAL', 'IN_SALA_ACOMPANHANTE', 'IN_MOBILIARIO_ESPECIFICO', 'IN_MATERIAL_ESPECIFICO', 'IN_NOME_SOCIAL', 'SG_UF_RESIDENCIA_RR', 'TP_ESTADO_CIVIL_Viúvo(a)', 'TP_NACIONALIDADE_0', 'TP_NACIONALIDADE_Brasileiro(a) Nato(a), nascido(a) no exterior', 'TP_NACIONALIDADE_Estrangeiro(a)', 'TP_ST_CONCLUSAO_Não concluí e não estou cursando o Ensino Médio', 'TP_PRESENCA_CN_Presente', 'TP_PRESENCA_CH_Presente', 'TP_PRESENCA_LC_Presente', 'TP_PRESENCA_MT_Presente', 'TP_STATUS_REDACAO_Sem problemas']\n",
            "[HIGH CORRELATION] Eliminando colunas redundantes: ['REG_NOTA_CH_MEDIA', 'REG_NOTA_LC_MEDIA', 'REG_NOTA_MT_MEDIA', 'REG_NOTA_REDACAO_MEDIA', 'TP_SEXO_M', 'TP_ESTADO_CIVIL_Solteiro(a)', 'TP_COR_RACA_Branca', 'TP_NACIONALIDADE_Brasileiro(a) Naturalizado(a)', 'TP_ESCOLA_0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = model.tune()"
      ],
      "metadata": {
        "id": "cdr-0BdVPAbq",
        "outputId": "f06d55e2-f4c8-47aa-9e3d-10662898c9dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ElasticNet\n",
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.671e+07, tolerance: 1.307e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.185, test=-65.202) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.698e+07, tolerance: 1.320e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.376, test=-64.505) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.685e+07, tolerance: 1.306e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.284, test=-64.815) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+07, tolerance: 1.315e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.554, test=-63.745) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.699e+07, tolerance: 1.308e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-64.380, test=-64.478) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.298e+07, tolerance: 1.307e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.179, test=-65.205) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e+07, tolerance: 1.320e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.372, test=-64.496) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.137e+07, tolerance: 1.306e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.278, test=-64.822) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.155e+07, tolerance: 1.315e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.550, test=-63.744) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.248e+07, tolerance: 1.308e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-64.376, test=-64.469) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.142e+07, tolerance: 1.307e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.172, test=-65.221) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.403e+07, tolerance: 1.320e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.369, test=-64.482) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.155e+07, tolerance: 1.306e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.272, test=-64.838) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.306e+07, tolerance: 1.315e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.546, test=-63.741) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.170e+07, tolerance: 1.308e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-64.372, test=-64.459) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.976e+07, tolerance: 1.307e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.499, test=-66.286) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.004e+07, tolerance: 1.320e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.659, test=-65.559) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.993e+07, tolerance: 1.306e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.604, test=-65.819) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.023e+07, tolerance: 1.315e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.819, test=-65.058) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.995e+07, tolerance: 1.308e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-65.633, test=-65.795) total time=   1.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.261, test=-66.031) total time=   0.2s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.406, test=-65.383) total time=   0.2s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.358, test=-65.582) total time=   0.2s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.584, test=-64.799) total time=   0.2s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-65.389, test=-65.545) total time=   0.2s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-64.774, test=-65.529) total time=   0.2s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-64.908, test=-65.009) total time=   0.2s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-64.880, test=-65.153) total time=   0.2s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-65.104, test=-64.236) total time=   0.2s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-64.889, test=-65.046) total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.063e+07, tolerance: 1.307e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-65.962, test=-66.741) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.093e+07, tolerance: 1.320e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.134, test=-65.942) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e+07, tolerance: 1.306e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.077, test=-66.261) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.108e+07, tolerance: 1.315e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.273, test=-65.544) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e+07, tolerance: 1.308e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-66.093, test=-66.280) total time=   1.1s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-65.771, test=-66.538) total time=   0.2s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-65.918, test=-65.807) total time=   0.2s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-65.875, test=-66.050) total time=   0.2s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-66.079, test=-65.326) total time=   0.2s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-65.895, test=-66.062) total time=   0.2s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.156, test=-65.894) total time=   0.2s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.287, test=-65.340) total time=   0.2s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.257, test=-65.500) total time=   0.2s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.493, test=-64.646) total time=   0.2s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-65.275, test=-65.389) total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.099e+07, tolerance: 1.639e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.438e+07, tolerance: 1.473e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.260, test=-69.706) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.394e+07, tolerance: 1.465e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-68.982, test=-70.812) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.462e+07, tolerance: 1.470e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.410, test=-69.087) total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.473e+07, tolerance: 1.484e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.480, test=-68.792) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.457e+07, tolerance: 1.474e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-69.382, test=-69.233) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.908e+07, tolerance: 1.473e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.257, test=-69.704) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.795e+05, tolerance: 1.465e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-68.981, test=-70.805) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.845e+07, tolerance: 1.470e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.405, test=-69.094) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.998e+05, tolerance: 1.484e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.476, test=-68.794) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.814e+07, tolerance: 1.474e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-69.378, test=-69.233) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.151e+07, tolerance: 1.473e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.254, test=-69.702) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.120e+07, tolerance: 1.465e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-68.979, test=-70.793) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.616e+07, tolerance: 1.470e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.401, test=-69.111) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.631e+07, tolerance: 1.484e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.473, test=-68.799) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.796e+07, tolerance: 1.474e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-69.375, test=-69.236) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.744e+07, tolerance: 1.473e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.480, test=-70.865) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.700e+07, tolerance: 1.465e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.188, test=-71.961) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.777e+07, tolerance: 1.470e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.671, test=-70.033) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.787e+07, tolerance: 1.484e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.728, test=-69.757) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.764e+07, tolerance: 1.474e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-70.596, test=-70.360) total time=   1.2s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.252, test=-70.618) total time=   0.2s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-69.952, test=-71.747) total time=   0.2s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.435, test=-69.792) total time=   0.2s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.491, test=-69.540) total time=   0.2s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-70.365, test=-70.140) total time=   0.2s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.820, test=-70.145) total time=   0.2s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.480, test=-71.277) total time=   0.2s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.980, test=-69.356) total time=   0.2s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-70.014, test=-69.128) total time=   0.2s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-69.909, test=-69.720) total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+07, tolerance: 1.473e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-70.906, test=-71.301) total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.789e+07, tolerance: 1.465e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-70.622, test=-72.356) total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.866e+07, tolerance: 1.470e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-71.111, test=-70.465) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.878e+07, tolerance: 1.484e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-71.166, test=-70.149) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.853e+07, tolerance: 1.474e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-71.029, test=-70.790) total time=   1.2s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.716, test=-71.106) total time=   0.2s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.417, test=-72.171) total time=   0.2s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.912, test=-70.249) total time=   0.2s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.960, test=-69.954) total time=   0.2s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-70.825, test=-70.597) total time=   0.2s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.147, test=-70.527) total time=   0.2s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-69.863, test=-71.606) total time=   0.2s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.329, test=-69.646) total time=   0.2s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.402, test=-69.432) total time=   0.2s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-70.247, test=-70.043) total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.810e+07, tolerance: 1.842e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.096e+07, tolerance: 8.648e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.256, test=-52.880) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.104e+07, tolerance: 8.672e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.320, test=-52.620) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.099e+07, tolerance: 8.618e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.281, test=-52.757) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.134e+07, tolerance: 8.724e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.575, test=-51.589) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.102e+07, tolerance: 8.637e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-52.307, test=-52.706) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.609e+04, tolerance: 8.648e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.254, test=-52.879) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+05, tolerance: 8.672e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.318, test=-52.623) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.333e+07, tolerance: 8.618e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.279, test=-52.758) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.165e+06, tolerance: 8.724e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.574, test=-51.588) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.837e+04, tolerance: 8.637e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-52.305, test=-52.703) total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.469e+07, tolerance: 8.648e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.252, test=-52.879) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+07, tolerance: 8.672e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.316, test=-52.628) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.059e+07, tolerance: 8.618e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.276, test=-52.768) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e+07, tolerance: 8.724e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.572, test=-51.586) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.211e+06, tolerance: 8.637e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-52.304, test=-52.698) total time=   1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.304e+07, tolerance: 8.648e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.358, test=-53.895) total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.314e+07, tolerance: 8.672e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.437, test=-53.555) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.308e+07, tolerance: 8.618e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.382, test=-53.767) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.343e+07, tolerance: 8.724e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.677, test=-52.605) total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.311e+07, tolerance: 8.637e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-53.412, test=-53.676) total time=   1.2s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.172, test=-53.716) total time=   0.2s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.250, test=-53.364) total time=   0.2s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.195, test=-53.587) total time=   0.2s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.499, test=-52.410) total time=   0.2s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-53.220, test=-53.502) total time=   0.2s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-52.789, test=-53.312) total time=   0.2s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-52.874, test=-52.976) total time=   0.2s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-52.814, test=-53.237) total time=   0.2s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-53.120, test=-51.988) total time=   0.2s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-52.819, test=-53.189) total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.362e+07, tolerance: 8.648e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-53.753, test=-54.278) total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.373e+07, tolerance: 8.672e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-53.836, test=-53.928) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+07, tolerance: 8.618e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-53.784, test=-54.148) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.401e+07, tolerance: 8.724e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-54.071, test=-53.002) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.369e+07, tolerance: 8.637e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-53.815, test=-54.067) total time=   1.1s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.616, test=-54.150) total time=   0.2s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.699, test=-53.784) total time=   0.2s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.645, test=-54.014) total time=   0.2s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.938, test=-52.861) total time=   0.2s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-53.672, test=-53.928) total time=   0.2s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.137, test=-53.636) total time=   0.2s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.205, test=-53.287) total time=   0.2s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.139, test=-53.555) total time=   0.2s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.450, test=-52.327) total time=   0.2s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-53.162, test=-53.489) total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.584e+06, tolerance: 1.082e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.845e+07, tolerance: 2.643e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-88.331, test=-88.965) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.865e+07, tolerance: 2.661e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-88.432, test=-88.535) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.859e+07, tolerance: 2.640e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-88.400, test=-88.690) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.886e+07, tolerance: 2.660e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-88.533, test=-88.200) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.844e+07, tolerance: 2.652e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-88.327, test=-88.999) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.026e+07, tolerance: 2.643e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-88.327, test=-88.966) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.625e+07, tolerance: 2.661e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-88.429, test=-88.538) total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.237e+07, tolerance: 2.640e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-88.396, test=-88.690) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.091e+07, tolerance: 2.660e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-88.531, test=-88.205) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.127e+07, tolerance: 2.652e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-88.324, test=-88.998) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.360e+07, tolerance: 2.643e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-88.322, test=-88.976) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.225e+07, tolerance: 2.661e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-88.425, test=-88.544) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.461e+07, tolerance: 2.640e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-88.389, test=-88.707) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.032e+07, tolerance: 2.660e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-88.529, test=-88.209) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.989e+07, tolerance: 2.652e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-88.321, test=-88.999) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.545e+07, tolerance: 2.643e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-90.463, test=-90.963) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.577e+07, tolerance: 2.661e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-90.609, test=-90.321) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.549e+07, tolerance: 2.640e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-90.494, test=-90.905) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.595e+07, tolerance: 2.660e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-90.711, test=-89.999) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.548e+07, tolerance: 2.652e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-90.476, test=-90.926) total time=   1.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-89.880, test=-90.423) total time=   0.2s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-90.022, test=-89.770) total time=   0.2s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-89.922, test=-90.328) total time=   0.2s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-90.143, test=-89.393) total time=   0.2s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-89.892, test=-90.361) total time=   0.2s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-88.864, test=-89.474) total time=   0.2s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-88.952, test=-88.827) total time=   0.2s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-88.878, test=-89.252) total time=   0.2s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-89.089, test=-88.269) total time=   0.2s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-88.834, test=-89.368) total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.746e+07, tolerance: 2.643e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-91.277, test=-91.745) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.780e+07, tolerance: 2.661e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-91.429, test=-91.083) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.747e+07, tolerance: 2.640e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-91.300, test=-91.734) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.796e+07, tolerance: 2.660e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-91.520, test=-90.798) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.748e+07, tolerance: 2.652e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-91.293, test=-91.726) total time=   1.2s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-90.744, test=-91.258) total time=   0.2s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-90.895, test=-90.577) total time=   0.2s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-90.775, test=-91.211) total time=   0.2s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-91.002, test=-90.242) total time=   0.2s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-90.762, test=-91.194) total time=   0.2s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-89.278, test=-89.951) total time=   0.2s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-89.406, test=-89.209) total time=   0.2s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-89.349, test=-89.754) total time=   0.2s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-89.577, test=-88.639) total time=   0.2s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-89.296, test=-89.712) total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+08, tolerance: 3.314e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+08, tolerance: 5.362e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0;, score=(train=-134.632, test=-135.540) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.067e+08, tolerance: 5.408e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0;, score=(train=-135.028, test=-134.011) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.056e+08, tolerance: 5.329e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0;, score=(train=-134.645, test=-135.478) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.059e+08, tolerance: 5.371e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0;, score=(train=-134.744, test=-135.115) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.056e+08, tolerance: 5.374e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0;, score=(train=-134.638, test=-135.575) total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.937e+08, tolerance: 5.362e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-134.623, test=-135.523) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.969e+08, tolerance: 5.408e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-135.018, test=-134.000) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e+08, tolerance: 5.329e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-134.629, test=-135.498) total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.952e+08, tolerance: 5.371e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-134.735, test=-135.104) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.951e+08, tolerance: 5.374e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-134.626, test=-135.576) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.286e+07, tolerance: 5.362e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-134.613, test=-135.504) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.770e+07, tolerance: 5.408e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-135.008, test=-133.986) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+08, tolerance: 5.329e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-134.613, test=-135.560) total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.280e+08, tolerance: 5.371e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-134.728, test=-135.079) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+08, tolerance: 5.374e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.001, l1_ratio=1.0;, score=(train=-134.616, test=-135.582) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e+08, tolerance: 5.362e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.5, l1_ratio=0;, score=(train=-137.683, test=-138.802) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+08, tolerance: 5.408e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.5, l1_ratio=0;, score=(train=-138.214, test=-136.441) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.192e+08, tolerance: 5.329e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.5, l1_ratio=0;, score=(train=-137.777, test=-138.477) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+08, tolerance: 5.371e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.5, l1_ratio=0;, score=(train=-137.917, test=-137.691) total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.191e+08, tolerance: 5.374e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.5, l1_ratio=0;, score=(train=-137.748, test=-138.541) total time=   1.3s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-137.000, test=-138.121) total time=   0.2s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-137.489, test=-135.817) total time=   0.2s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-137.089, test=-137.741) total time=   0.2s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-137.209, test=-137.064) total time=   0.2s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=0.5;, score=(train=-137.065, test=-137.837) total time=   0.2s\n",
            "[CV 1/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-135.217, test=-136.301) total time=   0.2s\n",
            "[CV 2/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-135.583, test=-134.361) total time=   0.2s\n",
            "[CV 3/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-135.274, test=-135.859) total time=   0.2s\n",
            "[CV 4/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-135.390, test=-135.412) total time=   0.2s\n",
            "[CV 5/5] END alpha=0.5, l1_ratio=1.0;, score=(train=-135.272, test=-136.000) total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+08, tolerance: 5.362e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1.0, l1_ratio=0;, score=(train=-138.537, test=-139.657) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.237e+08, tolerance: 5.408e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=1.0, l1_ratio=0;, score=(train=-139.111, test=-137.219) total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+08, tolerance: 5.329e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1.0, l1_ratio=0;, score=(train=-138.637, test=-139.403) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+08, tolerance: 5.371e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=1.0, l1_ratio=0;, score=(train=-138.808, test=-138.501) total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+08, tolerance: 5.374e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1.0, l1_ratio=0;, score=(train=-138.606, test=-139.388) total time=   1.2s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-137.985, test=-139.128) total time=   0.2s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-138.531, test=-136.694) total time=   0.2s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-138.090, test=-138.783) total time=   0.2s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-138.230, test=-137.988) total time=   0.2s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=0.5;, score=(train=-138.062, test=-138.845) total time=   0.2s\n",
            "[CV 1/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-135.865, test=-137.024) total time=   0.3s\n",
            "[CV 2/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-136.275, test=-134.784) total time=   0.2s\n",
            "[CV 3/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-135.934, test=-136.423) total time=   0.2s\n",
            "[CV 4/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-136.041, test=-136.044) total time=   0.2s\n",
            "[CV 5/5] END alpha=1.0, l1_ratio=1.0;, score=(train=-135.932, test=-136.671) total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.452e+08, tolerance: 6.711e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTree\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.606, test=-92.067) total time=   0.4s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.152, test=-92.275) total time=   0.4s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.606, test=-91.470) total time=   0.4s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.606, test=-92.380) total time=   0.4s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-90.951) total time=   0.4s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-54.861, test=-72.898) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-54.807, test=-72.059) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-54.969, test=-72.160) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-55.000, test=-71.612) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-54.834, test=-71.573) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-59.693, test=-69.393) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-59.709, test=-68.677) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-59.778, test=-69.105) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-59.853, test=-68.218) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-59.733, test=-68.005) total time=   0.2s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-62.857, test=-67.272) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-62.937, test=-66.558) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-63.008, test=-66.723) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-63.096, test=-65.853) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-62.976, test=-66.045) total time=   0.2s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.111, test=-66.776) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.194, test=-66.181) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.211, test=-66.096) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.339, test=-65.227) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-64.221, test=-65.715) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.606, test=-92.309) total time=   0.4s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.152, test=-92.834) total time=   0.4s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.606, test=-91.369) total time=   0.4s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.606, test=-92.381) total time=   0.4s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-90.571) total time=   0.4s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-54.861, test=-72.900) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-54.807, test=-72.058) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-54.969, test=-72.139) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-55.000, test=-71.619) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-54.834, test=-71.576) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-59.693, test=-69.393) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-59.709, test=-68.670) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-59.778, test=-69.105) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-59.853, test=-68.215) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-59.733, test=-68.011) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-62.857, test=-67.272) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-62.937, test=-66.558) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-63.008, test=-66.723) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-63.096, test=-65.853) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-62.976, test=-66.045) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.111, test=-66.776) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.194, test=-66.181) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.211, test=-66.096) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.339, test=-65.227) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-64.221, test=-65.715) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.606, test=-92.142) total time=   0.4s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.152, test=-92.698) total time=   0.4s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.606, test=-91.679) total time=   0.4s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.606, test=-92.473) total time=   0.4s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-90.927) total time=   0.4s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-54.861, test=-72.880) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-54.807, test=-72.059) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-54.969, test=-72.142) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-55.000, test=-71.622) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-54.834, test=-71.575) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-59.693, test=-69.393) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-59.709, test=-68.670) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-59.778, test=-69.105) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-59.853, test=-68.215) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-59.733, test=-68.005) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-62.857, test=-67.272) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-62.937, test=-66.558) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-63.008, test=-66.723) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-63.096, test=-65.853) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-62.976, test=-66.045) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.111, test=-66.776) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.194, test=-66.181) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.211, test=-66.096) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.339, test=-65.227) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-64.221, test=-65.715) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.606, test=-92.214) total time=   0.4s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.152, test=-93.040) total time=   0.4s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.606, test=-90.906) total time=   0.4s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.606, test=-91.786) total time=   0.4s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-90.824) total time=   0.4s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-54.861, test=-72.898) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-54.807, test=-72.067) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-54.969, test=-72.138) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-55.000, test=-71.622) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-54.834, test=-71.573) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-59.693, test=-69.393) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-59.709, test=-68.677) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-59.778, test=-69.104) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-59.853, test=-68.215) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-59.733, test=-68.005) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-62.857, test=-67.272) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-62.937, test=-66.558) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-63.008, test=-66.723) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-63.096, test=-65.853) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-62.976, test=-66.045) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.111, test=-66.776) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.194, test=-66.181) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.211, test=-66.096) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.339, test=-65.227) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-64.221, test=-65.715) total time=   0.2s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.034, test=-98.910) total time=   0.4s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.949, test=-99.949) total time=   0.4s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.034, test=-99.534) total time=   0.4s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.034, test=-99.419) total time=   0.4s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-99.609) total time=   0.4s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-59.247, test=-77.387) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-59.258, test=-79.761) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-59.355, test=-77.576) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-59.487, test=-77.470) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-59.508, test=-78.232) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-64.355, test=-73.834) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-64.229, test=-75.026) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-64.694, test=-73.392) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-64.586, test=-73.471) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-64.621, test=-73.831) total time=   0.2s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-67.670, test=-72.448) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-67.513, test=-72.777) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-67.989, test=-71.104) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-68.105, test=-70.834) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-67.764, test=-71.636) total time=   0.2s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-68.961, test=-71.419) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-68.813, test=-72.394) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-69.297, test=-70.462) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-69.364, test=-70.153) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-69.156, test=-70.984) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.034, test=-99.346) total time=   0.4s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.949, test=-100.724) total time=   0.4s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.034, test=-99.500) total time=   0.4s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.034, test=-98.855) total time=   0.4s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-98.984) total time=   0.4s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-59.247, test=-77.387) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-59.258, test=-79.738) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-59.355, test=-77.576) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-59.487, test=-77.441) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-59.508, test=-78.224) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-64.355, test=-73.834) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-64.229, test=-75.033) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-64.694, test=-73.392) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-64.586, test=-73.469) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-64.621, test=-73.831) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-67.670, test=-72.448) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-67.513, test=-72.777) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-67.989, test=-71.104) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-68.105, test=-70.834) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-67.764, test=-71.636) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-68.961, test=-71.419) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-68.813, test=-72.394) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-69.297, test=-70.462) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-69.364, test=-70.158) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-69.156, test=-70.984) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.034, test=-98.633) total time=   0.4s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.949, test=-100.927) total time=   0.4s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.034, test=-100.262) total time=   0.4s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.034, test=-98.641) total time=   0.4s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-98.919) total time=   0.4s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-59.247, test=-77.390) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-59.258, test=-79.759) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-59.355, test=-77.547) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-59.487, test=-77.421) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-59.508, test=-78.232) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-64.355, test=-73.834) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-64.229, test=-75.044) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-64.694, test=-73.392) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-64.586, test=-73.469) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-64.621, test=-73.831) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-67.670, test=-72.448) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-67.513, test=-72.777) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-67.989, test=-71.104) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-68.105, test=-70.834) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-67.764, test=-71.636) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-68.961, test=-71.419) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-68.813, test=-72.394) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-69.297, test=-70.462) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-69.364, test=-70.153) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-69.156, test=-70.984) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.034, test=-99.306) total time=   0.4s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.949, test=-99.715) total time=   0.4s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.034, test=-99.833) total time=   0.4s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.034, test=-99.427) total time=   0.4s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-98.966) total time=   0.4s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-59.247, test=-77.390) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-59.258, test=-79.769) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-59.355, test=-77.558) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-59.487, test=-77.429) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-59.508, test=-78.232) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-64.355, test=-73.832) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-64.229, test=-75.026) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-64.694, test=-73.392) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-64.586, test=-73.469) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-64.621, test=-73.829) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-67.670, test=-72.448) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-67.513, test=-72.777) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-67.989, test=-71.104) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-68.105, test=-70.834) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-67.764, test=-71.636) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-68.961, test=-71.419) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-68.813, test=-72.394) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-69.297, test=-70.462) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-69.364, test=-70.158) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-69.156, test=-70.984) total time=   0.2s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.693, test=-76.720) total time=   0.4s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.682, test=-76.511) total time=   0.4s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.693, test=-75.862) total time=   0.4s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.693, test=-74.853) total time=   0.4s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-75.047) total time=   0.4s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-44.954, test=-59.239) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-45.123, test=-58.768) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-44.819, test=-58.914) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-45.217, test=-59.021) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-45.017, test=-59.310) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-48.629, test=-56.886) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-48.835, test=-55.926) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-48.710, test=-56.539) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-49.073, test=-55.832) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-48.920, test=-55.969) total time=   0.2s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-51.173, test=-54.836) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-51.286, test=-54.533) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-51.295, test=-54.533) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-51.540, test=-53.804) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-51.270, test=-54.689) total time=   0.2s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-52.244, test=-54.240) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-52.289, test=-53.951) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-52.312, test=-54.305) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-52.575, test=-53.287) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-52.354, test=-54.142) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.693, test=-77.577) total time=   0.4s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.682, test=-75.600) total time=   0.4s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.693, test=-75.603) total time=   0.4s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.693, test=-75.261) total time=   0.4s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-75.514) total time=   0.4s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-44.954, test=-59.239) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-45.123, test=-58.760) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-44.819, test=-58.908) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-45.217, test=-59.028) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-45.017, test=-59.310) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-48.629, test=-56.887) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-48.835, test=-55.926) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-48.710, test=-56.527) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-49.073, test=-55.832) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-48.920, test=-55.969) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-51.173, test=-54.836) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-51.286, test=-54.530) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-51.295, test=-54.531) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-51.540, test=-53.804) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-51.270, test=-54.689) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-52.244, test=-54.240) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-52.289, test=-53.951) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-52.312, test=-54.305) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-52.575, test=-53.287) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-52.354, test=-54.142) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.693, test=-77.391) total time=   0.4s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.682, test=-76.808) total time=   0.4s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.693, test=-76.730) total time=   0.4s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.693, test=-74.513) total time=   0.4s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-75.136) total time=   0.4s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-44.954, test=-59.235) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-45.123, test=-58.769) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-44.819, test=-58.913) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-45.217, test=-59.009) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-45.017, test=-59.310) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-48.629, test=-56.887) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-48.835, test=-55.926) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-48.710, test=-56.525) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-49.073, test=-55.833) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-48.920, test=-55.969) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-51.173, test=-54.836) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-51.286, test=-54.530) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-51.295, test=-54.533) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-51.540, test=-53.804) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-51.270, test=-54.689) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-52.244, test=-54.240) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-52.289, test=-53.951) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-52.312, test=-54.305) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-52.575, test=-53.287) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-52.354, test=-54.142) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.693, test=-76.197) total time=   0.4s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.682, test=-76.122) total time=   0.4s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.693, test=-76.926) total time=   0.4s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.693, test=-74.602) total time=   0.4s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-75.675) total time=   0.4s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-44.954, test=-59.235) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-45.123, test=-58.773) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-44.819, test=-58.919) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-45.217, test=-59.028) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-45.017, test=-59.310) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-48.629, test=-56.887) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-48.835, test=-55.926) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-48.710, test=-56.527) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-49.073, test=-55.833) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-48.920, test=-55.969) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-51.173, test=-54.836) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-51.286, test=-54.530) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-51.295, test=-54.531) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-51.540, test=-53.804) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-51.270, test=-54.689) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-52.244, test=-54.240) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-52.289, test=-53.951) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-52.312, test=-54.305) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-52.575, test=-53.287) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-52.354, test=-54.142) total time=   0.2s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.249, test=-125.544) total time=   0.4s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.009, test=-128.180) total time=   0.4s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.249, test=-127.218) total time=   0.4s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.249, test=-128.750) total time=   0.4s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-128.907) total time=   0.4s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-75.715, test=-100.867) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-75.625, test=-100.643) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-75.775, test=-100.839) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-75.878, test=-99.849) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-75.723, test=-99.916) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-82.371, test=-95.164) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-82.666, test=-94.997) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-82.543, test=-95.401) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-82.603, test=-94.677) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-82.588, test=-94.542) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-86.933, test=-92.291) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-87.069, test=-92.342) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-87.171, test=-92.215) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-87.193, test=-91.731) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-87.136, test=-91.810) total time=   0.2s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-88.814, test=-91.764) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-88.834, test=-91.755) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-88.829, test=-91.634) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-88.954, test=-91.308) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-88.866, test=-90.916) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.249, test=-124.908) total time=   0.4s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.009, test=-127.941) total time=   0.4s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.249, test=-126.965) total time=   0.4s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.249, test=-129.017) total time=   0.4s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-128.326) total time=   0.4s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-75.715, test=-100.875) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-75.625, test=-100.672) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-75.775, test=-100.837) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-75.878, test=-99.869) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-75.723, test=-99.911) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-82.371, test=-95.167) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-82.666, test=-94.997) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-82.543, test=-95.379) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-82.603, test=-94.677) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-82.588, test=-94.542) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-86.933, test=-92.291) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-87.069, test=-92.342) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-87.171, test=-92.215) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-87.193, test=-91.731) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-87.136, test=-91.810) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-88.814, test=-91.764) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-88.834, test=-91.755) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-88.829, test=-91.634) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-88.954, test=-91.302) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-88.866, test=-90.916) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.249, test=-125.307) total time=   0.4s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.009, test=-127.033) total time=   0.4s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.249, test=-126.595) total time=   0.4s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.249, test=-128.829) total time=   0.4s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-128.552) total time=   0.4s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-75.715, test=-100.869) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-75.625, test=-100.674) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-75.775, test=-100.838) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-75.878, test=-99.849) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-75.723, test=-99.919) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-82.371, test=-95.167) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-82.666, test=-94.998) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-82.543, test=-95.387) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-82.603, test=-94.677) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-82.588, test=-94.542) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-86.933, test=-92.291) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-87.069, test=-92.342) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-87.171, test=-92.215) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-87.193, test=-91.731) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-87.136, test=-91.810) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-88.814, test=-91.764) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-88.834, test=-91.755) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-88.829, test=-91.634) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-88.954, test=-91.302) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-88.866, test=-90.916) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.249, test=-125.808) total time=   0.4s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.009, test=-127.667) total time=   0.4s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.249, test=-126.854) total time=   0.4s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.249, test=-128.848) total time=   0.4s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-128.131) total time=   0.4s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-75.715, test=-100.873) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-75.625, test=-100.643) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-75.775, test=-100.840) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-75.878, test=-99.873) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-75.723, test=-99.904) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-82.371, test=-95.167) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-82.666, test=-94.998) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-82.543, test=-95.401) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-82.603, test=-94.677) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-82.588, test=-94.532) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-86.933, test=-92.291) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-87.069, test=-92.342) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-87.171, test=-92.215) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-87.193, test=-91.731) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-87.136, test=-91.810) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-88.814, test=-91.764) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-88.834, test=-91.755) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-88.829, test=-91.634) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-88.954, test=-91.302) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-88.866, test=-90.916) total time=   0.2s\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.434, test=-193.814) total time=   0.4s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.222, test=-196.031) total time=   0.4s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.434, test=-194.191) total time=   0.4s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=1;, score=(train=-1.434, test=-193.696) total time=   0.4s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=1;, score=(train=-0.000, test=-194.761) total time=   0.4s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=10;, score=(train=-115.490, test=-152.242) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=10;, score=(train=-116.033, test=-153.008) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=10;, score=(train=-115.638, test=-152.419) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=10;, score=(train=-115.671, test=-152.426) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=10;, score=(train=-115.941, test=-152.768) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=20;, score=(train=-125.845, test=-145.580) total time=   0.3s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=20;, score=(train=-126.094, test=-144.512) total time=   0.3s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=20;, score=(train=-125.661, test=-144.712) total time=   0.3s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=20;, score=(train=-125.911, test=-145.837) total time=   0.3s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=20;, score=(train=-126.090, test=-144.039) total time=   0.3s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=50;, score=(train=-132.277, test=-140.765) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=50;, score=(train=-132.771, test=-138.865) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=50;, score=(train=-132.110, test=-140.697) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=50;, score=(train=-132.052, test=-140.540) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=50;, score=(train=-132.527, test=-140.470) total time=   0.2s\n",
            "[CV 1/5] END max_depth=100, min_samples_leaf=100;, score=(train=-134.725, test=-139.840) total time=   0.2s\n",
            "[CV 2/5] END max_depth=100, min_samples_leaf=100;, score=(train=-135.542, test=-138.505) total time=   0.2s\n",
            "[CV 3/5] END max_depth=100, min_samples_leaf=100;, score=(train=-135.103, test=-139.166) total time=   0.2s\n",
            "[CV 4/5] END max_depth=100, min_samples_leaf=100;, score=(train=-135.040, test=-139.856) total time=   0.2s\n",
            "[CV 5/5] END max_depth=100, min_samples_leaf=100;, score=(train=-135.379, test=-139.793) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.434, test=-193.868) total time=   0.4s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.222, test=-195.982) total time=   0.4s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.434, test=-195.255) total time=   0.4s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=1;, score=(train=-1.434, test=-196.571) total time=   0.4s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=1;, score=(train=-0.000, test=-195.717) total time=   0.4s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=10;, score=(train=-115.484, test=-152.241) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=10;, score=(train=-116.026, test=-152.961) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=10;, score=(train=-115.638, test=-152.497) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=10;, score=(train=-115.671, test=-152.384) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=10;, score=(train=-115.941, test=-152.806) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=20;, score=(train=-125.845, test=-145.576) total time=   0.3s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=20;, score=(train=-126.094, test=-144.512) total time=   0.3s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=20;, score=(train=-125.661, test=-144.696) total time=   0.3s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=20;, score=(train=-125.911, test=-145.833) total time=   0.3s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=20;, score=(train=-126.090, test=-144.039) total time=   0.3s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=50;, score=(train=-132.277, test=-140.765) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=50;, score=(train=-132.771, test=-138.865) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=50;, score=(train=-132.110, test=-140.697) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=50;, score=(train=-132.052, test=-140.540) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=50;, score=(train=-132.527, test=-140.470) total time=   0.2s\n",
            "[CV 1/5] END max_depth=90, min_samples_leaf=100;, score=(train=-134.725, test=-139.840) total time=   0.2s\n",
            "[CV 2/5] END max_depth=90, min_samples_leaf=100;, score=(train=-135.542, test=-138.505) total time=   0.2s\n",
            "[CV 3/5] END max_depth=90, min_samples_leaf=100;, score=(train=-135.103, test=-139.166) total time=   0.2s\n",
            "[CV 4/5] END max_depth=90, min_samples_leaf=100;, score=(train=-135.040, test=-139.856) total time=   0.2s\n",
            "[CV 5/5] END max_depth=90, min_samples_leaf=100;, score=(train=-135.379, test=-139.793) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.434, test=-194.603) total time=   0.4s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.222, test=-196.295) total time=   0.4s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.434, test=-193.829) total time=   0.4s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=1;, score=(train=-1.434, test=-195.739) total time=   0.4s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=1;, score=(train=-0.000, test=-195.241) total time=   0.4s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=10;, score=(train=-115.490, test=-152.218) total time=   0.3s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=10;, score=(train=-116.038, test=-152.969) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=10;, score=(train=-115.638, test=-152.511) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=10;, score=(train=-115.671, test=-152.454) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=10;, score=(train=-115.941, test=-152.786) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=20;, score=(train=-125.845, test=-145.583) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=20;, score=(train=-126.094, test=-144.512) total time=   0.3s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=20;, score=(train=-125.661, test=-144.715) total time=   0.3s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=20;, score=(train=-125.911, test=-145.816) total time=   0.3s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=20;, score=(train=-126.090, test=-144.031) total time=   0.3s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=50;, score=(train=-132.277, test=-140.765) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=50;, score=(train=-132.771, test=-138.876) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=50;, score=(train=-132.110, test=-140.697) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=50;, score=(train=-132.052, test=-140.540) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=50;, score=(train=-132.527, test=-140.470) total time=   0.2s\n",
            "[CV 1/5] END max_depth=80, min_samples_leaf=100;, score=(train=-134.725, test=-139.840) total time=   0.2s\n",
            "[CV 2/5] END max_depth=80, min_samples_leaf=100;, score=(train=-135.542, test=-138.505) total time=   0.2s\n",
            "[CV 3/5] END max_depth=80, min_samples_leaf=100;, score=(train=-135.103, test=-139.166) total time=   0.2s\n",
            "[CV 4/5] END max_depth=80, min_samples_leaf=100;, score=(train=-135.040, test=-139.856) total time=   0.2s\n",
            "[CV 5/5] END max_depth=80, min_samples_leaf=100;, score=(train=-135.379, test=-139.793) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.434, test=-194.073) total time=   0.4s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.222, test=-196.631) total time=   0.4s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.434, test=-194.672) total time=   0.4s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=1;, score=(train=-1.434, test=-195.254) total time=   0.4s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=1;, score=(train=-0.000, test=-195.419) total time=   0.4s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=10;, score=(train=-115.484, test=-152.203) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=10;, score=(train=-116.038, test=-152.960) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=10;, score=(train=-115.638, test=-152.539) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=10;, score=(train=-115.671, test=-152.454) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=10;, score=(train=-115.941, test=-152.765) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=20;, score=(train=-125.845, test=-145.583) total time=   0.3s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=20;, score=(train=-126.096, test=-144.532) total time=   0.3s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=20;, score=(train=-125.661, test=-144.687) total time=   0.3s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=20;, score=(train=-125.912, test=-145.757) total time=   0.3s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=20;, score=(train=-126.090, test=-144.039) total time=   0.3s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=50;, score=(train=-132.277, test=-140.765) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=50;, score=(train=-132.771, test=-138.876) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=50;, score=(train=-132.110, test=-140.697) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=50;, score=(train=-132.052, test=-140.540) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=50;, score=(train=-132.527, test=-140.470) total time=   0.2s\n",
            "[CV 1/5] END max_depth=70, min_samples_leaf=100;, score=(train=-134.725, test=-139.840) total time=   0.2s\n",
            "[CV 2/5] END max_depth=70, min_samples_leaf=100;, score=(train=-135.542, test=-138.505) total time=   0.2s\n",
            "[CV 3/5] END max_depth=70, min_samples_leaf=100;, score=(train=-135.103, test=-139.166) total time=   0.2s\n",
            "[CV 4/5] END max_depth=70, min_samples_leaf=100;, score=(train=-135.040, test=-139.856) total time=   0.2s\n",
            "[CV 5/5] END max_depth=70, min_samples_leaf=100;, score=(train=-135.379, test=-139.793) total time=   0.2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model._results"
      ],
      "metadata": {
        "id": "PsSQ7CidpHYD",
        "outputId": "22a357ce-3328-47e5-8800-35efbdaff496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DecisionTree': {'NU_NOTA_CH': {'best_params': {'max_depth': 100,\n",
              "    'min_samples_leaf': 100},\n",
              "   'best_score': -71.08253881261814},\n",
              "  'NU_NOTA_CN': {'best_params': {'max_depth': 100, 'min_samples_leaf': 100},\n",
              "   'best_score': -65.99895521648882},\n",
              "  'NU_NOTA_LC': {'best_params': {'max_depth': 100, 'min_samples_leaf': 100},\n",
              "   'best_score': -53.9850017077484},\n",
              "  'NU_NOTA_MT': {'best_params': {'max_depth': 90, 'min_samples_leaf': 100},\n",
              "   'best_score': -91.47403800860884},\n",
              "  'NU_NOTA_REDACAO': {'best_params': {'max_depth': 100,\n",
              "    'min_samples_leaf': 100},\n",
              "   'best_score': -139.43192844405368}},\n",
              " 'ElasticNet': {'NU_NOTA_CH': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -69.52599774588066},\n",
              "  'NU_NOTA_CN': {'best_params': {'alpha': 0.001, 'l1_ratio': 0.5},\n",
              "   'best_score': -64.54731145502434},\n",
              "  'NU_NOTA_LC': {'best_params': {'alpha': 0.001, 'l1_ratio': 0.5},\n",
              "   'best_score': -52.51027994884307},\n",
              "  'NU_NOTA_MT': {'best_params': {'alpha': 0.001, 'l1_ratio': 0},\n",
              "   'best_score': -88.67783724185077},\n",
              "  'NU_NOTA_REDACAO': {'best_params': {'alpha': 0.001, 'l1_ratio': 0.5},\n",
              "   'best_score': -135.14015106817183}}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dtnvOzngsrSF"
      },
      "execution_count": 8,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ML-Entrega2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}